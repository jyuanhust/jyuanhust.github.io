<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="深度学习,深度学习框架"><link rel="canonical" href="https://jyuanhust.github.io/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/"><title>pytorch入门 - pytorch - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">pytorch入门</h1><div class="meta"><span class="item" title="创建时间：2022-07-22 10:21:48"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-07-22T10:21:48+08:00">2022-07-22</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>51k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>46 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(12).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(20).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(42).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(94).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(91).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(3).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/pytorch/" itemprop="item" rel="index" title="分类于 pytorch"><span itemprop="name">pytorch</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h3 id="初始"><a class="anchor" href="#初始">#</a> 初始</h3><h4 id="前言"><a class="anchor" href="#前言">#</a> 前言</h4><p>使用 conda 安装时不用另外装 cuda 和 cudnn，它自己会去装</p><p>查看 cuda 版本 <code>nvidia-smi</code></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1666491480042.png" alt="1666491480042"></p><p>conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch</p><p>pip3 install torch torchvision torchaudio --extra-index-url <span class="exturl" data-url="aHR0cHM6Ly9kb3dubG9hZC5weXRvcmNoLm9yZy93aGwvY3UxMTA=">https://download.pytorch.org/whl/cu110</span></p><p>实测 cuda11.0 可以 cuda10.2 的</p><h4 id="换源"><a class="anchor" href="#换源">#</a> 换源</h4><p>conda config --add channels <span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL2Nsb3VkL2NvbmRhLWZvcmdlLw==">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span></p><p>conda config --add channels <span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL2Nsb3VkL3B5dG9yY2gv">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span></p><p>conda config --add channels <span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL3BrZ3MvbWFpbi8=">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span></p><p>conda config --add channels <span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2FuYWNvbmRhL3BrZ3MvZnJlZS8=">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span></p><p>conda config --add channels</p><h4 id="安装"><a class="anchor" href="#安装">#</a> 安装</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615170928.png" alt="1660615170928"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615187691.png" alt="1660615187691"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615197665.png" alt="1660615197665"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615236813.png" alt="1660615236813"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615312892.png" alt="1660615312892"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615320212.png" alt="1660615320212"></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/1660615339935.png" alt="1660615339935"></p><h4 id="什么是pytorch"><a class="anchor" href="#什么是pytorch">#</a> 什么是 pytorch?</h4><p>pytorch 是一个基于 Python 的科学计算包，它主要有两个用途：</p><ul><li>类似于 Numpy 但是能利用 GPU 加速</li><li>一个非常灵活和快速用于深度学习的研究平台。</li></ul><h4 id="检查gpu是否可用"><a class="anchor" href="#检查gpu是否可用">#</a> 检查 GPU 是否可用</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># True 为可用</span></pre></td></tr></table></figure><h4 id="两个法宝函数"><a class="anchor" href="#两个法宝函数">#</a> 两个法宝函数</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-22-17-11-05.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-22-17-11-56.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token builtin">dir</span><span class="token punctuation">(</span>torch<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token builtin">dir</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token builtin">help</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-00-02-24.png" alt></p><h4 id="dataset"><a class="anchor" href="#dataset">#</a> Dataset</h4><p>创建类来加载数据集，</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> os</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">MyData</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root_dir<span class="token punctuation">,</span> label_dir<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir</pre></td></tr><tr><td data-num="9"></td><td><pre>        self<span class="token punctuation">.</span>label_dir <span class="token operator">=</span> label_dir</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> label_dir<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        img_item_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span> self<span class="token punctuation">.</span>label_dir<span class="token punctuation">,</span> img_name<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_item_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>label_dir</pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> img<span class="token punctuation">,</span> label</pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    root_dir <span class="token operator">=</span> <span class="token string">"../dataset/train"</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    ants_label_dir <span class="token operator">=</span> <span class="token string">"ants"</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    ants_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> ants_label_dir<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    bees_label_dir <span class="token operator">=</span> <span class="token string">"bees"</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    bees_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> bees_label_dir<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>    train_dataset <span class="token operator">=</span> ants_dataset <span class="token operator">+</span> bees_dataset</pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-00-49-23.png" alt></p><h3 id="tensorboard"><a class="anchor" href="#tensorboard">#</a> tensorboard</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span> <span class="token comment"># 文件名称</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># y = x</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y = x"</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>打开终端<br><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-01-00-07.png" alt></p><p>在终端输入<br><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-01-01-24.png" alt></p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda activate pytorch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>tensorboard <span class="token parameter variable">--logdir</span><span class="token operator">=</span>logs <span class="token comment">#事件文件所在文件夹</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>tensorboard <span class="token parameter variable">--logdir</span><span class="token operator">=</span>logs <span class="token parameter variable">--port</span><span class="token operator">=</span><span class="token number">6007</span> <span class="token comment"># 指定端口</span></pre></td></tr></table></figure><h4 id="transform"><a class="anchor" href="#transform">#</a> Transform</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-19-03.png" alt></p><p>在 transforms.py 中有很多的类，相当于一个一个的工具</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-36-11.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-46-01.png" alt></p><h5 id="totensor"><a class="anchor" href="#totensor">#</a> Totensor</h5><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-31-05.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>img_path <span class="token operator">=</span> <span class="token string">"D:\\Projects\\pytorch-learn\\dataset\\train\\ants\\0013035.jpg"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 从 transforms 中返回类 ToTensor</span></pre></td></tr><tr><td data-num="10"></td><td><pre>tensor_img <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># 使用该类，调用的__call__方法</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tensor_img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tensor_img<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor_img<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'logs'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"Tensor_img"</span><span class="token punctuation">,</span> tensor_img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="normalize"><a class="anchor" href="#normalize">#</a> Normalize</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-49-04.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-56-30.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>img_path <span class="token operator">=</span> <span class="token string">"D:\\Projects\\pytorch-learn\\dataset\\train\\ants\\0013035.jpg"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># ToTensor</span></pre></td></tr><tr><td data-num="10"></td><td><pre>tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 从 transforms 中返回类 ToTensor</span></pre></td></tr><tr><td data-num="11"></td><td><pre>tensor_img <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># 使用该类，调用的__call__方法</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># Normalize</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tensor_img<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>trans_norm <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>img_norm <span class="token operator">=</span> trans_norm<span class="token punctuation">(</span>tensor_img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>img_norm<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="resize"><a class="anchor" href="#resize">#</a> Resize</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-10-01-04.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>img_path <span class="token operator">=</span> <span class="token string">"D:\\Projects\\pytorch-learn\\dataset\\train\\ants\\0013035.jpg"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># ToTensor</span></pre></td></tr><tr><td data-num="10"></td><td><pre>tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'logs'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment"># Resize</span></pre></td></tr><tr><td data-num="15"></td><td><pre>trans_resize <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 指定图片的宽高，是对图片进行操作，不是对张量</span></pre></td></tr><tr><td data-num="16"></td><td><pre>img_resize <span class="token operator">=</span> trans_resize<span class="token punctuation">(</span>img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>img_resize <span class="token operator">=</span> tensor_trans<span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span> <span class="token comment"># 最后再转为张量</span></pre></td></tr><tr><td data-num="18"></td><td><pre>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"resize"</span><span class="token punctuation">,</span> img_resize<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>img_resize<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="compose"><a class="anchor" href="#compose">#</a> Compose</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-10-12-11.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>img_path <span class="token operator">=</span> <span class="token string">"D:\\Projects\\pytorch-learn\\dataset\\train\\ants\\0013035.jpg"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># ToTensor</span></pre></td></tr><tr><td data-num="10"></td><td><pre>tensor_trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'logs'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment"># Resize</span></pre></td></tr><tr><td data-num="15"></td><td><pre>trans_resize_2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span> <span class="token comment"># 图片等比例缩放</span></pre></td></tr><tr><td data-num="16"></td><td><pre>trans_compose <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>trans_resize_2<span class="token punctuation">,</span> tensor_trans<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 注意前后参数类型的匹配</span></pre></td></tr><tr><td data-num="17"></td><td><pre>img_resize_2 <span class="token operator">=</span> trans_compose<span class="token punctuation">(</span>img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"resize"</span><span class="token punctuation">,</span> img_resize_2<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>img_resize_2<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="torchvision数据集使用"><a class="anchor" href="#torchvision数据集使用">#</a> torchvision 数据集使用</h4><p>官方文档</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-09-12-33.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>test_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 返回图片和类别（这里的类别是编号，编号和类别名称是对应的）</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>test_set<span class="token punctuation">.</span>classes<span class="token punctuation">)</span> <span class="token comment"># 类别的名称</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>img<span class="token punctuation">,</span> target <span class="token operator">=</span> test_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>test_set<span class="token punctuation">.</span>classes<span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>img<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>test_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>dataset_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># 对每张图片进行 transform</span></pre></td></tr><tr><td data-num="9"></td><td><pre>train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>dataset_transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    img<span class="token punctuation">,</span> target <span class="token operator">=</span> test_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"test_set"</span><span class="token punctuation">,</span> img<span class="token punctuation">,</span> i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="dataloader"><a class="anchor" href="#dataloader">#</a> dataloader</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 准备的测试数据集</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 测试数据集中第一张图片及 target</span></pre></td></tr><tr><td data-num="12"></td><td><pre>img<span class="token punctuation">,</span> target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([3, 32, 32])</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>  <span class="token comment"># 3</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="22"></td><td><pre>torch.Size([64, 3, 32, 32])</pre></td></tr><tr><td data-num="23"></td><td><pre>tensor([3, 2, 9, 2, 7, 3, 0, 8, 7, 2, 8, 3, 0, 7, 7, 1, 7, 0, 5, 5, 5, 0, 4, 4,</pre></td></tr><tr><td data-num="24"></td><td><pre>        3, 1, 0, 3, 0, 5, 8, 7, 1, 1, 4, 8, 1, 5, 4, 7, 9, 8, 9, 1, 3, 2, 6, 0,</pre></td></tr><tr><td data-num="25"></td><td><pre>        2, 2, 1, 0, 4, 9, 5, 3, 8, 2, 6, 2, 0, 7, 4, 1])</pre></td></tr><tr><td data-num="26"></td><td><pre>'''</pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"dataloader"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token comment"># print(imgs.shape)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        <span class="token comment"># print(targets)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"Epoch: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>        step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="nn"><a class="anchor" href="#nn">#</a> nn</h3><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-06-31.png" alt></p><h4 id="简单例子"><a class="anchor" href="#简单例子">#</a> 简单例子</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        output <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="卷积"><a class="anchor" href="#卷积">#</a> 卷积</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-15-23.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-15-35.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-16-17.png" alt></p><p>对应位相乘后最终再相加</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-17-04.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-11-18-57.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                      <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>                      <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>                      <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                      <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>                       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>                       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>kernel<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>kernel<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>output <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>output2 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>output3 <span class="token operator">=</span> F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output3<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="30"></td><td><pre>torch.Size([1, 1, 5, 5])</pre></td></tr><tr><td data-num="31"></td><td><pre>torch.Size([1, 1, 3, 3])</pre></td></tr><tr><td data-num="32"></td><td><pre>tensor([[[[10, 12, 12],</pre></td></tr><tr><td data-num="33"></td><td><pre>          [18, 16, 16],</pre></td></tr><tr><td data-num="34"></td><td><pre>          [13,  9,  3]]]])</pre></td></tr><tr><td data-num="35"></td><td><pre>tensor([[[[10, 12],</pre></td></tr><tr><td data-num="36"></td><td><pre>          [13,  3]]]])</pre></td></tr><tr><td data-num="37"></td><td><pre>tensor([[[[ 1,  3,  4, 10,  8],</pre></td></tr><tr><td data-num="38"></td><td><pre>          [ 5, 10, 12, 12,  6],</pre></td></tr><tr><td data-num="39"></td><td><pre>          [ 7, 18, 16, 16,  8],</pre></td></tr><tr><td data-num="40"></td><td><pre>          [11, 13,  9,  3,  4],</pre></td></tr><tr><td data-num="41"></td><td><pre>          [14, 13,  9,  7,  4]]]])</pre></td></tr><tr><td data-num="42"></td><td><pre>'''</pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-12-21-36.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-12-29-35.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="27"></td><td><pre>Tudui(</pre></td></tr><tr><td data-num="28"></td><td><pre>  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))</pre></td></tr><tr><td data-num="29"></td><td><pre>)</pre></td></tr><tr><td data-num="30"></td><td><pre>'''</pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"../logs"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="35"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="37"></td><td><pre>    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token comment"># torch.Size([64, 3, 32, 32])</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token comment"># torch.Size([64, 6, 30, 30])  -> [xxx, 3, 30, 30]</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre></pre></td></tr><tr><td data-num="47"></td><td><pre>    step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="48"></td><td><pre></pre></td></tr><tr><td data-num="49"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="最大池化"><a class="anchor" href="#最大池化">#</a> 最大池化</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-12-53-00.png" alt></p><p>注意池化核和卷积核在图像上的移动方式不同。</p><p>池化的目的是保留输入的特征，但同时把数据量减小。像把 1080p 的视频变成 720p 的</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../data"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                                       transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"../logs_maxpool"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="29"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="非线性激活"><a class="anchor" href="#非线性激活">#</a> 非线性激活</h4><ul><li>relu</li><li>sigmoid</li></ul><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-05-39.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-07-30.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token punctuation">,</span> Sigmoid</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="31"></td><td><pre>torch.Size([1, 1, 2, 2])</pre></td></tr><tr><td data-num="32"></td><td><pre>tensor([[[[1., 0.],</pre></td></tr><tr><td data-num="33"></td><td><pre>          [0., 3.]]]])</pre></td></tr><tr><td data-num="34"></td><td><pre>'''</pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-12-38.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU<span class="token punctuation">,</span> Sigmoid</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>                                       transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        self<span class="token punctuation">.</span>sigmoid1 <span class="token operator">=</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs_relu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="30"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> global_step<span class="token operator">=</span>step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    step <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="34"></td><td><pre></pre></td></tr><tr><td data-num="35"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>非线性变换的目的主要是为网络引入非线性特征，非线性越多，才能训练出符合各种曲线，符合各种特征的模型，加强模型的泛化能力。</p><h3 id="线性层及其他层"><a class="anchor" href="#线性层及其他层">#</a> 线性层及其他层</h3><h4 id="正则化层"><a class="anchor" href="#正则化层">#</a> 正则化层</h4><p>加快网络的训练速度</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-22-16.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-22-55.png" alt></p><h4 id="线性层"><a class="anchor" href="#线性层">#</a> 线性层</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-28-16.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-30-48.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="32"></td><td><pre>torch.Size([64, 3, 32, 32])</pre></td></tr><tr><td data-num="33"></td><td><pre>torch.Size([1, 1, 1, 196608])</pre></td></tr><tr><td data-num="34"></td><td><pre>torch.Size([1, 1, 1, 10])</pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>线性层</pre></td></tr><tr><td data-num="37"></td><td><pre>'''</pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-44-39.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Linear</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> output</pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    output <span class="token operator">=</span> tudui<span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre><span class="token triple-quoted-string string">'''</span></pre></td></tr><tr><td data-num="32"></td><td><pre>torch.Size([64, 3, 32, 32])</pre></td></tr><tr><td data-num="33"></td><td><pre>torch.Size([196608])</pre></td></tr><tr><td data-num="34"></td><td><pre>torch.Size([10])</pre></td></tr><tr><td data-num="35"></td><td><pre>'''</pre></td></tr></table></figure><h4 id="sequential"><a class="anchor" href="#sequential">#</a> Sequential</h4><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-49-21.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-19-54-28.png" alt></p><p>求取卷积时候的是 padding 和 stride<br><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-01-28.png" alt></p><p>dilation 默认值是 1</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-00-41.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="11"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="18"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="19"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>output <span class="token operator">=</span> tudui<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"./logs_seq"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="损失函数和反向传播"><a class="anchor" href="#损失函数和反向传播">#</a> 损失函数和反向传播</h3><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-17-15.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-18-25.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-19-21.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-19-51.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-23-04.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-24-03.png" alt></p><p>针对分类问题<br><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-25-11.png" alt></p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-29-47.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>loss <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>result <span class="token operator">=</span> loss<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>loss_mse <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>result_mse <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>result_mse<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>loss_cross <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>result_cross <span class="token operator">=</span> loss_cross<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>result_cross<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="18"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="19"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre><span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="35"></td><td><pre>    outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>result_loss<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="优化器"><a class="anchor" href="#优化器">#</a> 优化器</h4><h5 id="基本使用"><a class="anchor" href="#基本使用">#</a> 基本使用</h5><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/2022-07-23-20-49-33.png" alt></p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> StepLR</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="18"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="19"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>            Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>tudui<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="38"></td><td><pre>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="41"></td><td><pre>        outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 把模型中可被调节的参数的梯度设置为 0</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 得到可被调节的参数的梯度</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 对参数调优</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>        running_loss <span class="token operator">=</span> running_loss <span class="token operator">+</span> result_loss</pre></td></tr><tr><td data-num="49"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span></pre></td></tr></table></figure><p>理解：在优化器的创建中传入了网络模型的参数，根据后文优化器能够对模型的参数进行修改可以推测，在创建中传入的参数是引用参数，所以在反向传播计算出梯度之后，优化器能够直接修改到模型的参数。</p><h5 id="优化器的选择"><a class="anchor" href="#优化器的选择">#</a> 优化器的选择</h5><p>Pytorch 中有四种常用的优化器，SGD、Momentum、RMSProp、Adam，那我们该如何选择呢。</p><h2 id="1sgd"><a class="anchor" href="#1sgd">#</a> <strong>1.SGD</strong></h2><p>参数介绍：</p><blockquote><p>--lr (float) : 学习率</p></blockquote><blockquote><p>--momentum (float，可选）：动量因子（默认为 0）</p></blockquote><blockquote><p>--weight_decay (float，可选）：权重衰减（L2 惩罚，默认为 0）</p></blockquote><blockquote><p>--dampening (float，可选）：动量的抑制因子（默认为 0）</p></blockquote><blockquote><p>--nesterov (bool，可选）：使用 Nesterov 动量（默认为 false）</p></blockquote><p>示例代码：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>优缺点：</p><blockquote><p>优点：使用 mini-batch 的时候，模型可以收敛的更快</p></blockquote><blockquote><p>缺点：在随机选择梯度的时候会引入噪声，使得权重更新的方向不一定正确。</p></blockquote><blockquote><p>不能解决局部最优解的问题。</p></blockquote><p>推荐指数： 0 星</p><h2 id="2rmsproproot-mean-square-prop均方根传递"><a class="anchor" href="#2rmsproproot-mean-square-prop均方根传递">#</a> <strong>2.RMSProp (Root Mean Square Prop，均方根传递）</strong></h2><p>RMSProp 是 RProp 的改进版，同时也是 Adagard 的改进版，它的思想上：在梯度震动较大的项，在下降时，减小其下降速度；对于震动幅度较小的项，在下降时，加速其下降速度。同时 RMSProp 采用均方根作为分母，可以缓解 Adagard 学习率下降过快的问题。</p><p><strong>其对于 RNN 具有很好的效果。</strong></p><p>参数介绍：</p><blockquote><p>--lr (float) : 学习率</p></blockquote><blockquote><p>--momentum (float，可选）：动量因子（默认为 0）</p></blockquote><blockquote><p>--alpha（float，可选）：平滑常数（默认：0.99）</p></blockquote><blockquote><p>--eps (float, 可选)：为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）</p></blockquote><blockquote><p>--centered (bool, 可选)：如果为 True，计算中心化的 RMSProp，并且用它的方差预测值对梯度进行归一化</p></blockquote><blockquote><p>--weight_decay (float，可选）：权重衰减（L2 惩罚，默认为 0）</p></blockquote><p>示例代码：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>优缺点：</p><blockquote><p>优点：可缓解 Adagrad 学习率下降较快的问题，并且引入均方根，可以减少摆动，适合处理非平稳目标，对于 RNN 效果很好。</p></blockquote><blockquote><p>缺点：依然依赖于全局学习率。</p></blockquote><p>推荐程度：四星半 RMSProp 算法已被证明是一种有效且实用的深度神经网络优化算法。目前它是深度学习从业者经常采用的优化算法之一。</p><h2 id="3adamamsgrad"><a class="anchor" href="#3adamamsgrad">#</a> <strong>3.Adam(AMSGrad)</strong></h2><p>它是一种将 Momentum 算法和 RMSProp 算法结合起来而使用的一种算法，既使用动量来累计梯度，又使得收敛速度更快同时使得波动的幅度更小，并进行偏差修正。</p><p>参数介绍：</p><blockquote><p>--lr (float) : 学习率</p></blockquote><blockquote><p>--betas (Tuple [float,float], 可选)：用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999）</p></blockquote><blockquote><p>--eps (float, 可选)：为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）</p></blockquote><blockquote><p>--weight_decay (float，可选）：权重衰减（L2 惩罚，默认为 0）</p></blockquote><p>示例代码：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>优点：</p><blockquote><p>对目标函数没有平稳要求，即 loss function 可以随着时间变化。</p></blockquote><blockquote><p>参数的更新不受梯度的伸缩变换影响。</p></blockquote><blockquote><p>更新的步长能够被限制在大致的范围内（初始学习率）。</p></blockquote><blockquote><p>能较好的处理噪音样本，能天然地实现步长退火过程（自动调整学习率）。</p></blockquote><blockquote><p>很适合应用于大规模的数据及参数的场景、不稳定目标函数、梯度稀疏或梯度存在很大噪声的问题。</p></blockquote><p>推荐程度：五星。 非常推荐，基本上是目前最常用的优化方法。</p><p>四种常用优化器 Loss 函数比较图</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/f8f1302fd1a742879feb241c6e1cba51.png" alt="图 1"></p><p>对于重要参数学习率，这里推荐设置 1e-3 或者 1e-2.</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/041626bd0dad4968965af5afca6644f4.png" alt="图 2"></p><h3 id="现有模型的修改和使用"><a class="anchor" href="#现有模型的修改和使用">#</a> 现有模型的修改和使用</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># train_data = torchvision.datasets.ImageNet("../data_image_net", split='train', download=True,</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">#                                            transform=torchvision.transforms.ToTensor())</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>vgg16_false <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>vgg16_true <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'../data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># vgg16_true.add_module('add_linear', nn.Linear(1000, 10))</span></pre></td></tr><tr><td data-num="17"></td><td><pre>vgg16_true<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'add_linear'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_false<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>vgg16_false<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>vgg16_false<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="网络模型保存与读取"><a class="anchor" href="#网络模型保存与读取">#</a> 网络模型保存与读取</h3><h4 id="保存"><a class="anchor" href="#保存">#</a> 保存</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># -*- coding: utf-8 -*-</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 作者：小土堆</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 公众号：土堆碎念</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># 保存方式 1, 模型结构 + 模型参数</span></pre></td></tr><tr><td data-num="10"></td><td><pre>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span> <span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 保存方式 2，模型参数（官方推荐） 以字典的形式保存模型参数</span></pre></td></tr><tr><td data-num="13"></td><td><pre>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># 陷阱</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> <span class="token string">"tudui_method1.pth"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="读取"><a class="anchor" href="#读取">#</a> 读取</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># -*- coding: utf-8 -*-</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 作者：小土堆</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 公众号：土堆碎念</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> model_save <span class="token keyword">import</span> <span class="token operator">*</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 方式 1-》保存方式 1，加载模型</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># print(model)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># 方式 2，加载模型</span></pre></td></tr><tr><td data-num="14"></td><td><pre>vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>vgg16<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># model = torch.load("vgg16_method2.pth")</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># print(vgg16)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment"># 陷阱 1</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment"># class Tudui(nn.Module):</span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token comment">#     def __init__(self):</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment">#         super(Tudui, self).__init__()</span></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token comment">#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3)</span></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token comment">#</span></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token comment">#     def forward(self, x):</span></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token comment">#         x = self.conv1(x)</span></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token comment">#         return x</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tudui_method1.pth'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="利用gpu进行训练"><a class="anchor" href="#利用gpu进行训练">#</a> 利用 GPU 进行训练</h3><p>找到网络模型、数据（输入、标注）和标注、损失函数， <code>.cuda()</code> 后返回即可。</p><h4 id="方式一"><a class="anchor" href="#方式一">#</a> 方式一</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 准备数据集</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                                         download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># length 长度</span></pre></td></tr><tr><td data-num="16"></td><td><pre>train_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>test_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token comment"># 如果 train_data_size=10, 训练数据集的长度为：10</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集的长度为：&#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集的长度为：&#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token comment"># 利用 DataLoader 来加载数据集</span></pre></td></tr><tr><td data-num="24"></td><td><pre>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token comment"># 创建网络模型</span></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="32"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="33"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="35"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="36"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="37"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="38"></td><td><pre>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="39"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="40"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="46"></td><td><pre></pre></td></tr><tr><td data-num="47"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre></pre></td></tr><tr><td data-num="49"></td><td><pre><span class="token comment"># 先检测 GPU 是否可用</span></pre></td></tr><tr><td data-num="50"></td><td><pre><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    tudui <span class="token operator">=</span> tudui<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre><span class="token comment"># 损失函数</span></pre></td></tr><tr><td data-num="54"></td><td><pre>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="55"></td><td><pre></pre></td></tr><tr><td data-num="56"></td><td><pre><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="57"></td><td><pre>    loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre><span class="token comment"># 优化器</span></pre></td></tr><tr><td data-num="59"></td><td><pre><span class="token comment"># learning_rate = 0.01</span></pre></td></tr><tr><td data-num="60"></td><td><pre><span class="token comment"># 1e-2=1 x (10)^(-2) = 1 /100 = 0.01</span></pre></td></tr><tr><td data-num="61"></td><td><pre>learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span></pre></td></tr><tr><td data-num="62"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>tudui<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre><span class="token comment"># 设置训练网络的一些参数</span></pre></td></tr><tr><td data-num="65"></td><td><pre><span class="token comment"># 记录训练的次数</span></pre></td></tr><tr><td data-num="66"></td><td><pre>total_train_step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="67"></td><td><pre><span class="token comment"># 记录测试的次数</span></pre></td></tr><tr><td data-num="68"></td><td><pre>total_test_step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="69"></td><td><pre><span class="token comment"># 训练的轮数</span></pre></td></tr><tr><td data-num="70"></td><td><pre>epoch <span class="token operator">=</span> <span class="token number">10</span></pre></td></tr><tr><td data-num="71"></td><td><pre></pre></td></tr><tr><td data-num="72"></td><td><pre><span class="token comment"># 添加 tensorboard</span></pre></td></tr><tr><td data-num="73"></td><td><pre><span class="token comment"># writer = SummaryWriter("../logs_train")</span></pre></td></tr><tr><td data-num="74"></td><td><pre></pre></td></tr><tr><td data-num="75"></td><td><pre><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="76"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-------第 &#123;&#125; 轮训练开始-------"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="77"></td><td><pre></pre></td></tr><tr><td data-num="78"></td><td><pre>    <span class="token comment"># 训练步骤开始</span></pre></td></tr><tr><td data-num="79"></td><td><pre>    tudui<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="80"></td><td><pre>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="81"></td><td><pre>        imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="82"></td><td><pre>        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="83"></td><td><pre>            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="84"></td><td><pre>            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="85"></td><td><pre>        outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="86"></td><td><pre>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="87"></td><td><pre></pre></td></tr><tr><td data-num="88"></td><td><pre>        <span class="token comment"># 优化器优化模型</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="90"></td><td><pre>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="91"></td><td><pre>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="92"></td><td><pre></pre></td></tr><tr><td data-num="93"></td><td><pre>        total_train_step <span class="token operator">=</span> total_train_step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="94"></td><td><pre>        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="95"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数：&#123;&#125;, Loss: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="96"></td><td><pre>            <span class="token comment"># writer.add_scalar("train_loss", loss.item(), total_train_step)</span></pre></td></tr><tr><td data-num="97"></td><td><pre></pre></td></tr><tr><td data-num="98"></td><td><pre>    <span class="token comment"># 测试步骤开始</span></pre></td></tr><tr><td data-num="99"></td><td><pre>    tudui<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="100"></td><td><pre>    total_test_loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="101"></td><td><pre>    total_accuracy <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="102"></td><td><pre>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="103"></td><td><pre>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="104"></td><td><pre>            imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="105"></td><td><pre>            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="106"></td><td><pre>                imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="107"></td><td><pre>                targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="108"></td><td><pre>            outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="109"></td><td><pre>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="110"></td><td><pre>            total_test_loss <span class="token operator">=</span> total_test_loss <span class="token operator">+</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="111"></td><td><pre>            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="112"></td><td><pre>            total_accuracy <span class="token operator">=</span> total_accuracy <span class="token operator">+</span> accuracy</pre></td></tr><tr><td data-num="113"></td><td><pre></pre></td></tr><tr><td data-num="114"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的Loss: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="115"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="116"></td><td><pre>    <span class="token comment"># writer.add_scalar("test_loss", total_test_loss, total_test_step)</span></pre></td></tr><tr><td data-num="117"></td><td><pre>    <span class="token comment"># writer.add_scalar("test_accuracy", total_accuracy/test_data_size, total_test_step)</span></pre></td></tr><tr><td data-num="118"></td><td><pre>    total_test_step <span class="token operator">=</span> total_test_step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="119"></td><td><pre></pre></td></tr><tr><td data-num="120"></td><td><pre>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> <span class="token string">"tudui_&#123;&#125;.pth"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="121"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型已保存"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="122"></td><td><pre></pre></td></tr><tr><td data-num="123"></td><td><pre><span class="token comment"># writer.close()</span></pre></td></tr></table></figure><h4 id="方式二"><a class="anchor" href="#方式二">#</a> 方式二</h4><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 准备数据集</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># 定义训练的设备</span></pre></td></tr><tr><td data-num="10"></td><td><pre>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                                          download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"../dataset"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                                         download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># length 长度</span></pre></td></tr><tr><td data-num="18"></td><td><pre>train_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>test_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment"># 如果 train_data_size=10, 训练数据集的长度为：10</span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集的长度为：&#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集的长度为：&#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token comment"># 利用 DataLoader 来加载数据集</span></pre></td></tr><tr><td data-num="26"></td><td><pre>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre><span class="token comment"># 创建网络模型</span></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="35"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="36"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="37"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="38"></td><td><pre>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="39"></td><td><pre>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="40"></td><td><pre>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="41"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="42"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="47"></td><td><pre>        <span class="token keyword">return</span> x</pre></td></tr><tr><td data-num="48"></td><td><pre>tudui <span class="token operator">=</span> Tudui<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>tudui <span class="token operator">=</span> tudui<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre><span class="token comment"># 损失函数</span></pre></td></tr><tr><td data-num="52"></td><td><pre>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre>loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="54"></td><td><pre><span class="token comment"># 优化器</span></pre></td></tr><tr><td data-num="55"></td><td><pre><span class="token comment"># learning_rate = 0.01</span></pre></td></tr><tr><td data-num="56"></td><td><pre><span class="token comment"># 1e-2=1 x (10)^(-2) = 1 /100 = 0.01</span></pre></td></tr><tr><td data-num="57"></td><td><pre>learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span></pre></td></tr><tr><td data-num="58"></td><td><pre>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>tudui<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="59"></td><td><pre></pre></td></tr><tr><td data-num="60"></td><td><pre><span class="token comment"># 设置训练网络的一些参数</span></pre></td></tr><tr><td data-num="61"></td><td><pre><span class="token comment"># 记录训练的次数</span></pre></td></tr><tr><td data-num="62"></td><td><pre>total_train_step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="63"></td><td><pre><span class="token comment"># 记录测试的次数</span></pre></td></tr><tr><td data-num="64"></td><td><pre>total_test_step <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="65"></td><td><pre><span class="token comment"># 训练的轮数</span></pre></td></tr><tr><td data-num="66"></td><td><pre>epoch <span class="token operator">=</span> <span class="token number">10</span></pre></td></tr><tr><td data-num="67"></td><td><pre></pre></td></tr><tr><td data-num="68"></td><td><pre><span class="token comment"># 添加 tensorboard</span></pre></td></tr><tr><td data-num="69"></td><td><pre><span class="token comment"># writer = SummaryWriter("../logs_train")</span></pre></td></tr><tr><td data-num="70"></td><td><pre></pre></td></tr><tr><td data-num="71"></td><td><pre><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="72"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-------第 &#123;&#125; 轮训练开始-------"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="73"></td><td><pre></pre></td></tr><tr><td data-num="74"></td><td><pre>    <span class="token comment"># 训练步骤开始</span></pre></td></tr><tr><td data-num="75"></td><td><pre>    tudui<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="76"></td><td><pre>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="77"></td><td><pre>        imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="78"></td><td><pre>        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="79"></td><td><pre>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="80"></td><td><pre>        outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="81"></td><td><pre>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="82"></td><td><pre></pre></td></tr><tr><td data-num="83"></td><td><pre>        <span class="token comment"># 优化器优化模型</span></pre></td></tr><tr><td data-num="84"></td><td><pre>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="85"></td><td><pre>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="86"></td><td><pre>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="87"></td><td><pre></pre></td></tr><tr><td data-num="88"></td><td><pre>        total_train_step <span class="token operator">=</span> total_train_step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="90"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数：&#123;&#125;, Loss: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="91"></td><td><pre>            <span class="token comment"># writer.add_scalar("train_loss", loss.item(), total_train_step)</span></pre></td></tr><tr><td data-num="92"></td><td><pre></pre></td></tr><tr><td data-num="93"></td><td><pre>    <span class="token comment"># 测试步骤开始</span></pre></td></tr><tr><td data-num="94"></td><td><pre>    tudui<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="95"></td><td><pre>    total_test_loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="96"></td><td><pre>    total_accuracy <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="97"></td><td><pre>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="98"></td><td><pre>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="99"></td><td><pre>            imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="100"></td><td><pre>            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="101"></td><td><pre>            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="102"></td><td><pre>            outputs <span class="token operator">=</span> tudui<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="103"></td><td><pre>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="104"></td><td><pre>            total_test_loss <span class="token operator">=</span> total_test_loss <span class="token operator">+</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="105"></td><td><pre>            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="106"></td><td><pre>            total_accuracy <span class="token operator">=</span> total_accuracy <span class="token operator">+</span> accuracy</pre></td></tr><tr><td data-num="107"></td><td><pre></pre></td></tr><tr><td data-num="108"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的Loss: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="109"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_accuracy<span class="token operator">/</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="110"></td><td><pre>    <span class="token comment"># writer.add_scalar("test_loss", total_test_loss, total_test_step)</span></pre></td></tr><tr><td data-num="111"></td><td><pre>    <span class="token comment"># writer.add_scalar("test_accuracy", total_accuracy/test_data_size, total_test_step)</span></pre></td></tr><tr><td data-num="112"></td><td><pre>    total_test_step <span class="token operator">=</span> total_test_step <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="113"></td><td><pre></pre></td></tr><tr><td data-num="114"></td><td><pre>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> <span class="token string">"tudui_&#123;&#125;.pth"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="115"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型已保存"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="116"></td><td><pre></pre></td></tr><tr><td data-num="117"></td><td><pre><span class="token comment"># writer.close()</span></pre></td></tr></table></figure><h1 id="下面是原博客内容"><a class="anchor" href="#下面是原博客内容">#</a> 下面是原博客内容</h1><h4 id="tensor"><a class="anchor" href="#tensor">#</a> Tensor</h4><p>Tensor 类似于 Numpy 的 ndarray，但是可以用 GPU 加速，使用前我们需要导入 torch 包。</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 下面代码构建一个 5x3 的未初始化的矩阵</span></pre></td></tr><tr><td data-num="3"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 输出</span></pre></td></tr><tr><td data-num="6"></td><td><pre>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9.9184e-39</span><span class="token punctuation">,</span> <span class="token number">8.7245e-39</span><span class="token punctuation">,</span> <span class="token number">9.2755e-39</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">8.9082e-39</span><span class="token punctuation">,</span> <span class="token number">9.9184e-39</span><span class="token punctuation">,</span> <span class="token number">8.4490e-39</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">9.6429e-39</span><span class="token punctuation">,</span> <span class="token number">1.0653e-38</span><span class="token punctuation">,</span> <span class="token number">1.0469e-38</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">4.2246e-39</span><span class="token punctuation">,</span> <span class="token number">1.0378e-38</span><span class="token punctuation">,</span> <span class="token number">9.6429e-39</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">9.2755e-39</span><span class="token punctuation">,</span> <span class="token number">9.7346e-39</span><span class="token punctuation">,</span> <span class="token number">1.0745e-38</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>下面代码分别构造一个零初始化的矩阵，它的类型 (dtype) 是 long：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 输出</span></pre></td></tr><tr><td data-num="4"></td><td><pre>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们可以从已有的 tensor 信息 (size 和 dtype) 来构造 tensor。但也可以用不同的 dtype 来构造。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> x.new_ones<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token number">3</span>, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>torch.double<span class="token punctuation">)</span>      <span class="token comment"># new_* methods take in sizes</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>x <span class="token operator">=</span> torch.randn_like<span class="token punctuation">(</span>x, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>torch.float<span class="token punctuation">)</span>    <span class="token comment"># override dtype!</span></pre></td></tr><tr><td data-num="5"></td><td><pre>print<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们可以是用 size 函数来看它的 shape：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>x.size<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">#输出：</span></pre></td></tr><tr><td data-num="3"></td><td><pre>torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span>, <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>注意 torch.Size 其实是一个 tuple，因此它支持所有的 tuple 操作。</p><h4 id="operation"><a class="anchor" href="#operation">#</a> Operation</h4><p>接下来我们来学习一些 PyTorch 的 Operation。Operation 一般可以使用函数的方式使用，但是为了方便使用，PyTorch 重载了一些常见的运算符，因此我们可以这样来进行 Tensor 的加法：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>y <span class="token operator">=</span> torch.rand<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>x + y<span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们也可以用 add 函数来实现加法：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>torch.add<span class="token punctuation">(</span>x, y<span class="token punctuation">))</span></pre></td></tr></table></figure><p>我们也可以给加法提供返回值 (而不是生成一个新的返回值)：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>result <span class="token operator">=</span> torch.empty<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token number">3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>torch.add<span class="token punctuation">(</span>x, y, <span class="token assign-left variable">out</span><span class="token operator">=</span>result<span class="token punctuation">)</span> <span class="token comment"># x + y 的结果放到 result 里。</span></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span>result<span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们也可以把相加的结果直接修改第一个被加数：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 把 x 加到 y</span></pre></td></tr><tr><td data-num="2"></td><td><pre>y.add_<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span>y<span class="token punctuation">)</span></pre></td></tr></table></figure><p>注意：就地修改 tensor 的 operation 以下划线结尾。比如： x.copy_(y), x.t_(), 都会修改 x。</p><h4 id="tensor的变换"><a class="anchor" href="#tensor的变换">#</a> Tensor 的变换</h4><p>我们也可以使用类似 numpy 的下标运算来操作 PyTorch 的 Tensor：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#打印 x 的第一列</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>x<span class="token punctuation">[</span>:, <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>如果想 resize 或者 reshape 一个 Tensor，我们可以使用 torch.view：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span><span class="token number">4</span>, <span class="token number">4</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>y <span class="token operator">=</span> x.view<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>z <span class="token operator">=</span> x.view<span class="token punctuation">(</span>-1, <span class="token number">8</span><span class="token punctuation">)</span>  <span class="token comment"># -1 的意思是让 PyTorch 自己推断出第一维的大小。</span></pre></td></tr><tr><td data-num="4"></td><td><pre>print<span class="token punctuation">(</span>x.size<span class="token punctuation">(</span><span class="token punctuation">)</span>, y.size<span class="token punctuation">(</span><span class="token punctuation">)</span>, z.size<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr></table></figure><p>如果一个 tensor 只有一个元素，可以使用 item () 函数来把它变成一个 Python number：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">#输出的是一个 Tensor</span></pre></td></tr><tr><td data-num="4"></td><td><pre>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>-0.6966<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>print<span class="token punctuation">(</span>x.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">#输出的是一个数</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token parameter variable">-0.6966081857681274</span></pre></td></tr></table></figure><h4 id="tensor与numpy的互相转换"><a class="anchor" href="#tensor与numpy的互相转换">#</a> Tensor 与 Numpy 的互相转换</h4><p>Torch Tensor 和 NumPy 数组的转换非常容易。它们会共享内存地址，因此修改一方会影响另一方。把一个 Torch Tensor 转换成 NumPy 数组的代码示例为：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>a <span class="token operator">=</span> torch.ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">#tensor([ 1.,  1.,  1.,  1.,  1.])</span></pre></td></tr><tr><td data-num="4"></td><td><pre>b <span class="token operator">=</span> a.numpy<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>print<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">#[1. 1. 1. 1. 1.]</span></pre></td></tr></table></figure><p>修改一个会影响另外一个：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>a.add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># tensor([ 2.,  2.,  2.,  2.,  2.])</span></pre></td></tr><tr><td data-num="4"></td><td><pre>print<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># [2. 2. 2. 2. 2.]</span></pre></td></tr></table></figure><p>把把 NumPy 数组转成 Torch Tensor 的代码示例为：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> numpy as np</pre></td></tr><tr><td data-num="2"></td><td><pre>a <span class="token operator">=</span> np.ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>b <span class="token operator">=</span> torch.from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>np.add<span class="token punctuation">(</span>a, <span class="token number">1</span>, <span class="token assign-left variable">out</span><span class="token operator">=</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>print<span class="token punctuation">(</span>a<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># [2. 2. 2. 2. 2.]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>print<span class="token punctuation">(</span>b<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)</span></pre></td></tr></table></figure><p>CPU 上的所有类型的 Tensor (除了 CharTensor) 都可以和 Numpy 数组来回转换。</p><h4 id="cuda-tensor"><a class="anchor" href="#cuda-tensor">#</a> CUDA Tensor</h4><p>Tensor 可以使用 to () 方法来移到任意设备上：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 如果有 CUDA</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 我们会使用 ``torch.device`` 来把 tensors 放到 GPU 上</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">if</span> torch.cuda.is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="4"></td><td><pre>	device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>          <span class="token comment"># 一个 CUDA device 对象。</span></pre></td></tr><tr><td data-num="5"></td><td><pre>	y <span class="token operator">=</span> torch.ones_like<span class="token punctuation">(</span>x, <span class="token assign-left variable">device</span><span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment"># 直接在 GPU 上创建 tensor</span></pre></td></tr><tr><td data-num="6"></td><td><pre>	x <span class="token operator">=</span> x.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                       <span class="token comment"># 也可以使用 ``.to ("cuda")`` 把一个 tensor 从 CPU 移到 GPU 上</span></pre></td></tr><tr><td data-num="7"></td><td><pre>	z <span class="token operator">=</span> x + y</pre></td></tr><tr><td data-num="8"></td><td><pre>	print<span class="token punctuation">(</span>z<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>	print<span class="token punctuation">(</span>z.to<span class="token punctuation">(</span><span class="token string">"cpu"</span>, torch.double<span class="token punctuation">))</span>       <span class="token comment"># ``.to`` 也可以在移动的过程中修改 dtype</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 输出：</span></pre></td></tr><tr><td data-num="12"></td><td><pre>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3034</span><span class="token punctuation">]</span>, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3034</span><span class="token punctuation">]</span>, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>torch.float64<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="autograd-自动求导"><a class="anchor" href="#autograd-自动求导">#</a> Autograd: 自动求导</h3><p>PyTorch 的核心是 autograd 包。 我们首先简单的了解一些，然后用 PyTorch 开始训练第一个神经网络。autograd 为所有用于 Tensor 的 operation 提供自动求导的功能。我们通过一些简单的例子来学习它基本用法。</p><h4 id="从自动求导看tensor"><a class="anchor" href="#从自动求导看tensor">#</a> 从自动求导看 Tensor</h4><p>torch.Tensor 是这个包的核心类。如果它的属性 requires_grad 是 True，那么 PyTorch 就会追踪所有与之相关的 operation。当完成 (正向) 计算之后， 我们可以调用 backward ()，PyTorch 会自动的把所有的梯度都计算好。与这个 tensor 相关的梯度都会累加到它的 grad 属性里。</p><p>如果不想计算这个 tensor 的梯度，我们可以调用 detach ()，这样它就不会参与梯度的计算了。为了阻止 PyTorch 记录用于梯度计算相关的信息 (从而节约内存)，我们可以使用 with torch.no_grad ()。这在模型的预测时非常有用，因为预测的时候我们不需要计算梯度，否则我们就得一个个的修改 Tensor 的 requires_grad 属性，这会非常麻烦。</p><p>关于 autograd 的实现还有一个很重要的 Function 类。Tensor 和 Function 相互连接从而形成一个有向无环图，这个图记录了计算的完整历史。每个 tensor 有一个 grad_fn 属性来引用创建这个 tensor 的 Function (用户直接创建的 Tensor，这些 Tensor 的 grad_fn 是 None)。</p><p>如果你想计算梯度，可以对一个 Tensor 调用它的 backward () 方法。如果这个 Tensor 是一个 scalar (只有一个数)，那么调用时不需要传任何参数。如果 Tensor 多于一个数，那么需要传入和它的 shape 一样的参数，表示反向传播过来的梯度。</p><p>创建 tensor 时设置属性 requires_grad=True，PyTorch 就会记录用于反向梯度计算的信息：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> torch.ones<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">2</span>, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr></table></figure><p>然后我们通过 operation 产生新的 tensor：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>y <span class="token operator">=</span> x + <span class="token number">2</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>y<span class="token punctuation">)</span></pre></td></tr></table></figure><p>是通过 operation 产生的 tensor，因此它的 grad_fn 不是 None。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>y.grad_fn<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># &lt;AddBackward0 object at 0x7f35409a68d0></span></pre></td></tr></table></figure><p>再通过 y 得到 z 和 out</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>z <span class="token operator">=</span> y * y * <span class="token number">3</span></pre></td></tr><tr><td data-num="2"></td><td><pre>out <span class="token operator">=</span> z.mean<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>print<span class="token punctuation">(</span>z, out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># z = tensor([[ 27.,  27.],[ 27.,  27.]]) </span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># out = tensor(27.)</span></pre></td></tr></table></figure><p>requires_grad_() 函数会修改一个 Tensor 的 requires_grad。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>a <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>a <span class="token operator">=</span> <span class="token variable"><span class="token punctuation">((</span>a <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>a <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">))</span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span>a.requires_grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>a.requires_grad_<span class="token punctuation">(</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>print<span class="token punctuation">(</span>a.requires_grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>b <span class="token operator">=</span> <span class="token punctuation">(</span>a * a<span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>print<span class="token punctuation">(</span>b.grad_fn<span class="token punctuation">)</span></pre></td></tr></table></figure><p>输出是：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>False</pre></td></tr><tr><td data-num="2"></td><td><pre>True</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">&lt;</span>SumBackward0 object at 0x7f35766827f<span class="token operator"><span class="token file-descriptor important">0</span>></span></pre></td></tr></table></figure><h4 id="梯度"><a class="anchor" href="#梯度">#</a> 梯度</h4><p>现在我们里反向计算梯度。因为 out 是一个 scalar，因此 out.backward () 等价于 out.backward (torch.tensor (1))。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>out.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们可以打印梯度 d (out)/dx：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>x.grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># tensor([[ 4.5000,  4.5000],</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">[</span> <span class="token number">4.5000</span>,  <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们手动计算验证一下。为了简单，我们把 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">out</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span></span></span></span> 记为 o。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">o=\frac{1}{4}\sum_iz_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16195399999999993em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">z_i=3(x_i+2)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">3</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-.25em"></span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>，并且<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><msub><mi mathvariant="normal">∣</mi><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow></msub><mo>=</mo><mn>27</mn></mrow><annotation encoding="application/x-tex">z_i|_{x_i=1}=27</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-.2501em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.04398em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2501em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span><span class="mord">7</span></span></span></span>。</p><p>因此，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>o</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{∂o}{∂x_i}=\frac{3}{2}(x_i+2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325208em;vertical-align:-.44509999999999994em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801079999999999em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.44509999999999994em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">2</span><span class="mclose">)</span></span></span></span>， 因此，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>o</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfrac><msub><mi mathvariant="normal">∣</mi><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow></msub><mo>=</mo><mfrac><mn>9</mn><mn>2</mn></mfrac><mo>=</mo><mn>4.5</mn></mrow><annotation encoding="application/x-tex">\frac{∂o}{∂x_i}|_{x_i=1}=\frac{9}{2}=4.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325208em;vertical-align:-.44509999999999994em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801079999999999em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.44509999999999994em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2501em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span><span class="mord">.</span><span class="mord">5</span></span></span></span>。</p><p>我们也可以用 autograd 做一些很奇怪的事情！比如 y 和 x 的关系是 while 循环的关系 (似乎很难用一个函数直接表示 y 和 x 的关系？对 x 不断平方直到超过 1000，这是什么函数？)</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>y <span class="token operator">=</span> x * <span class="token number">2</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">while</span> y.data.norm<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1000</span>:</pre></td></tr><tr><td data-num="5"></td><td><pre>	y <span class="token operator">=</span> y * <span class="token number">2</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>print<span class="token punctuation">(</span>y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># tensor([ -692.4808,  1686.1211,   667.7313])</span></pre></td></tr><tr><td data-num="9"></td><td><pre>gradients <span class="token operator">=</span> torch.tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span>, <span class="token number">1.0</span>, <span class="token number">0.0001</span><span class="token punctuation">]</span>, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>torch.float<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>y.backward<span class="token punctuation">(</span>gradients<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>print<span class="token punctuation">(</span>x.grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># tensor([  102.4000,  1024.0000,     0.1024])</span></pre></td></tr></table></figure><p>我们可以使用”with torch.no_grad ()” 来停止梯度的计算：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>x.requires_grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">((</span>x ** <span class="token number">2</span><span class="token punctuation">)</span>.requires_grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="5"></td><td><pre>	print<span class="token punctuation">((</span>x ** <span class="token number">2</span><span class="token punctuation">)</span>.requires_grad<span class="token punctuation">)</span></pre></td></tr></table></figure><p>输出为：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>True</pre></td></tr><tr><td data-num="2"></td><td><pre>True</pre></td></tr><tr><td data-num="3"></td><td><pre>False</pre></td></tr></table></figure><h3 id="pytorch神经网络简介"><a class="anchor" href="#pytorch神经网络简介">#</a> PyTorch 神经网络简介</h3><p>神经网络可以通过 torch.nn 包来创建。我们之前简单的了解了 autograd，而 nn 会使用 autograd 来定义模型以及求梯度。一个 nn.Module 对象包括了许多网络层 (layer)，并且有一个 forward (input) 方法来返回 output。如下图所示，我们会定义一个卷积网络来识别 mnist 图片。</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/7252839afabe441e2744a7a5f78629bc.png" alt="图 1"><br><em>图：识别 MNIST 数据的神经网络</em></p><p>训练一个神经网络通常需要如下步骤：</p><ul><li>定义一个神经网络，它通常有一些可以训练的参数</li><li>迭代一个数据集 (dataset)</li><li>处理网络的输入</li><li>计算 loss (会调用 Module 对象的 forward 方法)</li><li>计算 loss 对参数的梯度</li><li>更新参数，通常使用如下的梯度下降方法来更新： weight = weight - learning_rate * gradient</li></ul><h4 id="定义网络"><a class="anchor" href="#定义网络">#</a> 定义网络</h4><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> torch.nn as nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token function">import</span> torch.nn.functional as F</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>class Net<span class="token punctuation">(</span>nn.Module<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>	def __init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="9"></td><td><pre>		super<span class="token punctuation">(</span>Net, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>		<span class="token comment"># 输入是 1 个通道的灰度图，输出 6 个通道 (feature map)，使用 5x5 的卷积核</span></pre></td></tr><tr><td data-num="11"></td><td><pre>		self.conv1 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">6</span>, <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>		<span class="token comment"># 第二个卷积层也是 5x5，有 16 个通道</span></pre></td></tr><tr><td data-num="13"></td><td><pre>		self.conv2 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">6</span>, <span class="token number">16</span>, <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>		<span class="token comment"># 全连接层</span></pre></td></tr><tr><td data-num="15"></td><td><pre>		self.fc1 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">16</span> * <span class="token number">5</span> * <span class="token number">5</span>, <span class="token number">120</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>		self.fc2 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">120</span>, <span class="token number">84</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>		self.fc3 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">84</span>, <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>	def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="20"></td><td><pre>		<span class="token comment"># 32x32 -> 28x28 -> 14x14 </span></pre></td></tr><tr><td data-num="21"></td><td><pre>		x <span class="token operator">=</span> F.max_pool2d<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv1<span class="token punctuation">(</span>x<span class="token punctuation">))</span>, <span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">2</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="22"></td><td><pre>		<span class="token comment"># 14x14 -> 10x10 -> 5x5</span></pre></td></tr><tr><td data-num="23"></td><td><pre>		x <span class="token operator">=</span> F.max_pool2d<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv2<span class="token punctuation">(</span>x<span class="token punctuation">))</span>, <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>		x <span class="token operator">=</span> x.view<span class="token punctuation">(</span>-1, self.num_flat_features<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="25"></td><td><pre>		x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc1<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="26"></td><td><pre>		x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc2<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="27"></td><td><pre>		x <span class="token operator">=</span> self.fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>		<span class="token builtin class-name">return</span> x</pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>	def num_flat_features<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="31"></td><td><pre>		size <span class="token operator">=</span> x.size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span>:<span class="token punctuation">]</span>  <span class="token comment"># 除了 batch 维度之外的其它维度。</span></pre></td></tr><tr><td data-num="32"></td><td><pre>		num_features <span class="token operator">=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="33"></td><td><pre>		<span class="token keyword">for</span> <span class="token for-or-select variable">s</span> <span class="token keyword">in</span> size:</pre></td></tr><tr><td data-num="34"></td><td><pre>		num_features *<span class="token operator">=</span> s</pre></td></tr><tr><td data-num="35"></td><td><pre>		<span class="token builtin class-name">return</span> num_features</pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>print<span class="token punctuation">(</span>net<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre><span class="token comment"># Net(</span></pre></td></tr><tr><td data-num="41"></td><td><pre><span class="token punctuation">(</span>conv1<span class="token punctuation">)</span>: Conv2d<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">6</span>, <span class="token assign-left variable">kernel_size</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span>, <span class="token number">5</span><span class="token punctuation">)</span>, <span class="token assign-left variable">stride</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="42"></td><td><pre><span class="token punctuation">(</span>conv2<span class="token punctuation">)</span>: Conv2d<span class="token punctuation">(</span><span class="token number">6</span>, <span class="token number">16</span>, <span class="token assign-left variable">kernel_size</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span>, <span class="token number">5</span><span class="token punctuation">)</span>, <span class="token assign-left variable">stride</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="43"></td><td><pre><span class="token punctuation">(</span>fc1<span class="token punctuation">)</span>: Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">400</span>, <span class="token assign-left variable">out_features</span><span class="token operator">=</span><span class="token number">120</span>, <span class="token assign-left variable">bias</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre><span class="token punctuation">(</span>fc2<span class="token punctuation">)</span>: Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span>, <span class="token assign-left variable">out_features</span><span class="token operator">=</span><span class="token number">84</span>, <span class="token assign-left variable">bias</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre><span class="token punctuation">(</span>fc3<span class="token punctuation">)</span>: Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span>, <span class="token assign-left variable">out_features</span><span class="token operator">=</span><span class="token number">10</span>, <span class="token assign-left variable">bias</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们只需要定义 forward 函数，而 backward 函数会自动通过 autograd 创建。在 forward 函数里可以使用任何处理 Tensor 的函数。我们可以使用函数 net.parameters () 来得到模型所有的参数。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>params <span class="token operator">=</span> list<span class="token punctuation">(</span>net.parameters<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>len<span class="token punctuation">(</span>params<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 10</span></pre></td></tr><tr><td data-num="4"></td><td><pre>print<span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.size<span class="token punctuation">(</span><span class="token punctuation">))</span>  <span class="token comment"># conv1 的 weight</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># torch.Size([6, 1, 5, 5])</span></pre></td></tr></table></figure><h4 id="测试网络"><a class="anchor" href="#测试网络">#</a> 测试网络</h4><p>接着我们尝试一个随机的 32x32 的输入来检验 (sanity check) 网络定义没有问题。注意：这个网络 (LeNet) 期望的输入大小是 32x32。如果使用 MNIST 数据集 (28x28)，我们需要缩放到 32x32。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>input <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">32</span>, <span class="token number">32</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>out <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span>out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># tensor([[-0.0198,  0.0438,  0.0930, -0.0267, -0.0344,  0.0330,  0.0664,</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">0.1244</span>, -0.0379,  <span class="token number">0.0890</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>默认的梯度会累加，因此我们通常在 backward 之前清除掉之前的梯度值：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>net.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>out.backward<span class="token punctuation">(</span>torch.randn<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">10</span><span class="token punctuation">))</span></pre></td></tr></table></figure><p>注意：torch.nn 只支持 mini-batches 的输入。整个 torch.nn 包的输入都必须第一维是 batch，即使只有一个样本也要弄成 batch 是 1 的输入。</p><p>比如，nn.Conv2d 的输入是一个 4D 的 Tensor，shape 是 nSamples x nChannels x Height x Width。如果你只有一个样本 (nChannels x Height x Width)，那么可以使用 input.unsqueeze (0) 来增加一个 batch 维。</p><h4 id="损失函数"><a class="anchor" href="#损失函数">#</a> 损失函数</h4><p>损失函数的参数是 (output, target) 对，output 是模型的预测，target 是实际的值。损失函数会计算预测值和真实值的差别，损失越小说明预测的越准。</p><p>PyTorch 提供了这里有许多不同的损失函数： <span class="exturl" data-url="aHR0cDovL3B5dG9yY2gub3JnL2RvY3Mvbm4uaHRtbCNsb3NzLWZ1bmN0aW9ucyVFMyU4MCU4MiVFNiU5QyU4MCVFNyVBRSU4MCVFNSU4RCU5NSVFNyU5QSU4NCVFNCVCOCU4MCVFNCVCOCVBQSVFNiU4RCU5RiVFNSVBNCVCMSVFNSU4NyVCRCVFNiU5NSVCMCVFNiU5OCVBRiVFRiVCQyU5QW5uLk1TRUxvc3MlRUYlQkMlOEMlRTUlQUUlODMlRTQlQkMlOUElRTglQUUlQTElRTclQUUlOTclRTklQTIlODQlRTYlQjUlOEIlRTUlODAlQkMlRTUlOTIlOEMlRTclOUMlOUYlRTUlQUUlOUUlRTUlODAlQkMlRTclOUElODQlRTUlOUQlODclRTYlOTYlQjklRTglQUYlQUYlRTUlQjclQUUlRTMlODAlODIlRTYlQUYlOTQlRTUlQTYlODIlRUYlQkMlOUE=">http://pytorch.org/docs/nn.html#loss-functions。最简单的一个损失函数是：nn.MSELoss，它会计算预测值和真实值的均方误差。比如：</span></p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>target <span class="token operator">=</span> torch.arange<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">11</span><span class="token punctuation">)</span>  <span class="token comment"># 随便伪造的一个 “真实值” </span></pre></td></tr><tr><td data-num="3"></td><td><pre>target <span class="token operator">=</span> target.view<span class="token punctuation">(</span><span class="token number">1</span>, -1<span class="token punctuation">)</span>  <span class="token comment"># 把它变成 output 的 shape (1, 10) </span></pre></td></tr><tr><td data-num="4"></td><td><pre>criterion <span class="token operator">=</span> nn.MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output, target<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>print<span class="token punctuation">(</span>loss<span class="token punctuation">)</span></pre></td></tr></table></figure><p>如果从 loss 往回走，需要使用 tensor 的 grad_fn 属性，我们 Negative 看到这样的计算图：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>input -<span class="token operator">></span> conv2d -<span class="token operator">></span> relu -<span class="token operator">></span> maxpool2d -<span class="token operator">></span> conv2d -<span class="token operator">></span> relu -<span class="token operator">></span> maxpool2d</pre></td></tr><tr><td data-num="2"></td><td><pre>-<span class="token operator">></span> view -<span class="token operator">></span> linear -<span class="token operator">></span> relu -<span class="token operator">></span> linear -<span class="token operator">></span> relu -<span class="token operator">></span> linear</pre></td></tr><tr><td data-num="3"></td><td><pre>-<span class="token operator">></span> MSELoss</pre></td></tr><tr><td data-num="4"></td><td><pre>-<span class="token operator">></span> loss</pre></td></tr></table></figure><p>因此当调用 loss.backward () 时，PyTorch 会计算这个图中所有 requires_grad=True 的 tensor 关于 loss 的梯度。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>print<span class="token punctuation">(</span>loss.grad_fn<span class="token punctuation">)</span>  <span class="token comment"># MSELoss</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>loss.grad_fn.next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Add</span></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span>loss.grad_fn.next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Expand</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">#输出：</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token operator">&lt;</span>MseLossBackward object at 0x7f445b3a2dd<span class="token operator"><span class="token file-descriptor important">8</span>></span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">&lt;</span>AddmmBackward object at 0x7f445b3a2eb<span class="token operator"><span class="token file-descriptor important">8</span>></span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token operator">&lt;</span>ExpandBackward object at 0x7f445b3a2dd<span class="token operator"><span class="token file-descriptor important">8</span>></span></pre></td></tr></table></figure><h4 id="计算梯度"><a class="anchor" href="#计算梯度">#</a> 计算梯度</h4><p>在调用 loss.backward () 之前，我们需要清除掉 tensor 里之前的梯度，否则会累加进去。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>net.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 清掉 tensor 里缓存的梯度值。</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'conv1.bias.grad before backward'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>print<span class="token punctuation">(</span>net.conv1.bias.grad<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'conv1.bias.grad after backward'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>print<span class="token punctuation">(</span>net.conv1.bias.grad<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="更新参数"><a class="anchor" href="#更新参数">#</a> 更新参数</h4><p>更新参数最简单的方法是使用随机梯度下降 (SGD)： weight=weight−learningrate∗gradientweight=weight−learningrate∗gradient 我们可以使用如下简单的代码来实现更新：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>learning_rate <span class="token operator">=</span> <span class="token number">0.01</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">f</span> <span class="token keyword">in</span> net.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="3"></td><td><pre>	f.data.sub_<span class="token punctuation">(</span>f.grad.data * learning_rate<span class="token punctuation">)</span></pre></td></tr></table></figure><p>通常我们会使用更加复杂的优化方法，比如 SGD, Nesterov-SGD, Adam, RMSProp 等等。为了实现这些算法，我们可以使用 torch.optim 包，它的用法也非常简单：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch.optim as optim</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># 创建 optimizer，需要传入参数和 learning rate</span></pre></td></tr><tr><td data-num="4"></td><td><pre>optimizer <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>net.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 清除梯度</span></pre></td></tr><tr><td data-num="7"></td><td><pre>optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  </pre></td></tr><tr><td data-num="8"></td><td><pre>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output, target<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer 会自动帮我们更新参数</span></pre></td></tr></table></figure><p>注意：即使使用 optimizer，我们也需要清零梯度。但是我们不需要一个个的清除，而是用 optimizer.zero_grad () 一次清除所有。</p><h3 id="训练一个分类器"><a class="anchor" href="#训练一个分类器">#</a> 训练一个分类器</h3><p>介绍了 PyTorch 神经网络相关包之后我们就可以用这些知识来构建一个分类器了。</p><h4 id="如何进行数据处理"><a class="anchor" href="#如何进行数据处理">#</a> 如何进行数据处理</h4><p>一般地，当我们处理图片、文本、音频或者视频数据的时候，我们可以使用 python 代码来把它转换成 numpy 数组。然后再把 numpy 数组转换成 torch.xxxTensor。</p><ul><li>对于处理图像，常见的 lib 包括 Pillow 和 OpenCV</li><li>对于音频，常见的 lib 包括 scipy 和 librosa</li><li>对于文本，可以使用标准的 Python 库，另外比较流行的 lib 包括 NLTK 和 SpaCy</li></ul><p>对于视觉问题，PyTorch 提供了一个 torchvision 包 (需要单独安装)，它对于常见数据集比如 Imagenet, CIFAR10, MNIST 等提供了加载的方法。并且它也提供很多数据变化的工具，包括 torchvision.datasets 和 torch.utils.data.DataLoader。这会极大的简化我们的工作，避免重复的代码。</p><p>在这个教程里，我们使用 CIFAR10 数据集。它包括十个类别：”airplane”, “automobile”, “bird”, “cat”, “deer”, “dog”, “frog”, “horse”, “ship”,”truck”。图像的对象是 3x32x32，也就是 3 通道 (RGB) 的 32x32 的图片。下面是一些样例图片。</p><p><img data-src="/./images/bd00a994ea2a8f9b29ec53f4c8c166ed.png" alt="图 2"><br><em>图：cifar10 样例</em></p><h4 id="训练的步骤"><a class="anchor" href="#训练的步骤">#</a> 训练的步骤</h4><ul><li>使用 torchvision 加载和预处理 CIFAR10 训练和测试数据集。</li><li>定义卷积网络</li><li>定义损失函数</li><li>用训练数据训练模型</li><li>用测试数据测试模型</li></ul><h4 id="数据处理"><a class="anchor" href="#数据处理">#</a> 数据处理</h4><p>通过使用 torchvision，我们可以轻松的加载 CIFAR10 数据集。首先我们导入相关的包：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> torchvision</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token function">import</span> torchvision.transforms as transforms</pre></td></tr></table></figure><p>torchvision 读取的 datasets 是 PILImage 对象，它的取值范围是 [0, 1]，我们把它转换到范围 [-1, 1]。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>transform <span class="token operator">=</span> transforms.Compose<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>	<span class="token punctuation">[</span>transforms.ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="3"></td><td><pre>	transforms.Normalize<span class="token variable"><span class="token punctuation">((</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">))</span></span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>trainset <span class="token operator">=</span> torchvision.datasets.CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/path/to/data'</span>, <span class="token assign-left variable">train</span><span class="token operator">=</span>True,</pre></td></tr><tr><td data-num="6"></td><td><pre>	<span class="token assign-left variable">download</span><span class="token operator">=</span>True, <span class="token assign-left variable">transform</span><span class="token operator">=</span>transform<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>	trainloader <span class="token operator">=</span> torch.utils.data.DataLoader<span class="token punctuation">(</span>trainset, <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">4</span>,</pre></td></tr><tr><td data-num="8"></td><td><pre>	<span class="token assign-left variable">shuffle</span><span class="token operator">=</span>True, <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>testset <span class="token operator">=</span> torchvision.datasets.CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'/path/to/data'</span>, <span class="token assign-left variable">train</span><span class="token operator">=</span>False,</pre></td></tr><tr><td data-num="11"></td><td><pre>	<span class="token assign-left variable">download</span><span class="token operator">=</span>True, <span class="token assign-left variable">transform</span><span class="token operator">=</span>transform<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>	testloader <span class="token operator">=</span> torch.utils.data.DataLoader<span class="token punctuation">(</span>testset, <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">4</span>,</pre></td></tr><tr><td data-num="13"></td><td><pre>	<span class="token assign-left variable">shuffle</span><span class="token operator">=</span>False, <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span>, <span class="token string">'car'</span>, <span class="token string">'bird'</span>, <span class="token string">'cat'</span>,</pre></td></tr><tr><td data-num="16"></td><td><pre>	<span class="token string">'deer'</span>, <span class="token string">'dog'</span>, <span class="token string">'frog'</span>, <span class="token string">'horse'</span>, <span class="token string">'ship'</span>, <span class="token string">'truck'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>我们来看几张图片，如<span class="exturl" data-url="aHR0cDovL2ZhbmN5ZXJpaS5naXRodWIuaW8vYm9va3MvcHl0b3JjaC8jcHl0b3JjaC1jaWZhci1zYW1wbGU=">下图</span>所示，显示图片的代码如下：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> matplotlib.pyplot as plt</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> numpy as np</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 显示图片的函数</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>def imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="8"></td><td><pre>img <span class="token operator">=</span> img / <span class="token number">2</span> + <span class="token number">0.5</span>     <span class="token comment">#  [-1,1] -> [0,1]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>npimg <span class="token operator">=</span> img.numpy<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>plt.imshow<span class="token punctuation">(</span>np.transpose<span class="token punctuation">(</span>npimg, <span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">0</span><span class="token punctuation">))</span><span class="token punctuation">)</span> <span class="token comment"># (channel, width, height) -> (width, height, channel)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># 随机选择一些图片</span></pre></td></tr><tr><td data-num="14"></td><td><pre>dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>images, labels <span class="token operator">=</span> dataiter.next<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># 显示图片</span></pre></td></tr><tr><td data-num="18"></td><td><pre>imshow<span class="token punctuation">(</span>torchvision.utils.make_grid<span class="token punctuation">(</span>images<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment"># 打印 label</span></pre></td></tr><tr><td data-num="20"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">' '</span>.join<span class="token punctuation">(</span><span class="token string">'%5s'</span> % classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token for-or-select variable">j</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/c299d233fb17f6ced16575299bf28a32.png" alt="图 3"><br><em>图：随机选择的图片</em></p><h4 id="定义卷积网络"><a class="anchor" href="#定义卷积网络">#</a> 定义卷积网络</h4><p>网络结构和上一节的介绍类似，只是输入通道从 1 变成 3。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch.nn as nn</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> torch.nn.functional as F</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>class Net<span class="token punctuation">(</span>nn.Module<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="6"></td><td><pre>	def __init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="7"></td><td><pre>		super<span class="token punctuation">(</span>Net, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>		self.conv1 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token number">6</span>, <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>		self.pool <span class="token operator">=</span> nn.MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>		self.conv2 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">6</span>, <span class="token number">16</span>, <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>		self.fc1 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">16</span> * <span class="token number">5</span> * <span class="token number">5</span>, <span class="token number">120</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>		self.fc2 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">120</span>, <span class="token number">84</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>		self.fc3 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">84</span>, <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>	def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="16"></td><td><pre>		x <span class="token operator">=</span> self.pool<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv1<span class="token punctuation">(</span>x<span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>		x <span class="token operator">=</span> self.pool<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv2<span class="token punctuation">(</span>x<span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>		x <span class="token operator">=</span> x.view<span class="token punctuation">(</span>-1, <span class="token number">16</span> * <span class="token number">5</span> * <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>		x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc1<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="20"></td><td><pre>		x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc2<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="21"></td><td><pre>		x <span class="token operator">=</span> self.fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>		<span class="token builtin class-name">return</span> x</pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>\subsubsection {定义损失函数和 optimizer} 我们这里使用交叉熵损失函数，Optimizer 使用带冲量的 SGD。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch.optim as optim</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>criterion <span class="token operator">=</span> nn.CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>optimizer <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>net.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>\subsubsection {训练网络} 我们遍历 DataLoader 进行训练。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>:  <span class="token comment"># 这里只迭代 2 个 epoch，实际应该进行更多次训练 </span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>	running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	<span class="token keyword">for</span> i, data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader, <span class="token number">0</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="5"></td><td><pre>		<span class="token comment"># 得到输入</span></pre></td></tr><tr><td data-num="6"></td><td><pre>		inputs, labels <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>		<span class="token comment"># 梯度清零 </span></pre></td></tr><tr><td data-num="9"></td><td><pre>		optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>		<span class="token comment"># forward + backward + optimize</span></pre></td></tr><tr><td data-num="12"></td><td><pre>		outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>		loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs, labels<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>		loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>		optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>		<span class="token comment"># 定义统计信息</span></pre></td></tr><tr><td data-num="18"></td><td><pre>		running_loss <span class="token operator">+=</span> loss.item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>		<span class="token keyword">if</span> i % <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span>:</pre></td></tr><tr><td data-num="20"></td><td><pre>			print<span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> %</pre></td></tr><tr><td data-num="21"></td><td><pre>				<span class="token punctuation">(</span>epoch + <span class="token number">1</span>, i + <span class="token number">1</span>, running_loss / <span class="token number">2000</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="22"></td><td><pre>		running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="在测试数据集上进行测试"><a class="anchor" href="#在测试数据集上进行测试">#</a> 在测试数据集上进行测试</h4><p>我们进行了 2 轮迭代，可以使用测试数据集上的数据来进行测试。首先我们随机抽取几个样本来进行测试。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>testloader<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>images, labels <span class="token operator">=</span> dataiter.next<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>imshow<span class="token punctuation">(</span>torchvision.utils.make_grid<span class="token punctuation">(</span>images<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="6"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'GroundTruth: '</span>, <span class="token string">' '</span>.join<span class="token punctuation">(</span><span class="token string">'%5s'</span> % classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token for-or-select variable">j</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>随机选择出来的测试样例如下图所示。</p><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/8fb20c1fa51e9a05e85b0de5b67a0c85.png" alt="图 4"><br><em>图：随机测试的结果</em></p><p>我们用模型来预测一下，看看是否正确预测：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span></pre></td></tr></table></figure><p>outputs 是 10 个分类的 logits。我们在训练的时候需要用 softmax 把它变成概率 (CrossEntropyLoss 帮我们做了)，但是预测的时候没有必要，因为我们只需要知道哪个分类的概率大就行。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>_, predicted <span class="token operator">=</span> torch.max<span class="token punctuation">(</span>outputs, <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'Predicted: '</span>, <span class="token string">' '</span>.join<span class="token punctuation">(</span><span class="token string">'%5s'</span> % classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre>		<span class="token keyword">for</span> <span class="token for-or-select variable">j</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># cat  ship  ship  ship</span></pre></td></tr></table></figure><p>预测中的四个错了一个，似乎还不错。接下来我们看看在整个测试集合上的效果：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>correct <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="2"></td><td><pre>total <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="3"></td><td><pre>with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">data</span> <span class="token keyword">in</span> testloader:</pre></td></tr><tr><td data-num="5"></td><td><pre>	images, labels <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="6"></td><td><pre>	outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>	_, predicted <span class="token operator">=</span> torch.max<span class="token punctuation">(</span>outputs.data, <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>	total <span class="token operator">+=</span> labels.size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>	correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>print<span class="token punctuation">(</span><span class="token string">'Accuracy of the network on the 10000 test images: %d %%'</span> % <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>	<span class="token number">100</span> * correct / total<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment"># Accuracy of the network on the 10000 test images: 55 %</span></pre></td></tr></table></figure><p>看起来比随机的瞎猜要好，因为随机猜的准确率大概是 10% 的准确率，所以模型确实学到了一些东西。我们也可以看每个分类的准确率：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>class_correct <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token number">0</span>. <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="2"></td><td><pre>class_total <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token number">0</span>. <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="3"></td><td><pre>with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="4"></td><td><pre>	<span class="token keyword">for</span> <span class="token for-or-select variable">data</span> <span class="token keyword">in</span> testloader:</pre></td></tr><tr><td data-num="5"></td><td><pre>		images, labels <span class="token operator">=</span> data</pre></td></tr><tr><td data-num="6"></td><td><pre>		outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>		_, predicted <span class="token operator">=</span> torch.max<span class="token punctuation">(</span>outputs, <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>		c <span class="token operator">=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span>.squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>		<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="10"></td><td><pre>			label <span class="token operator">=</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="11"></td><td><pre>			class_correct<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token operator">+=</span> c<span class="token punctuation">[</span>i<span class="token punctuation">]</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>			class_total<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="16"></td><td><pre>	print<span class="token punctuation">(</span><span class="token string">'Accuracy of %5s : %2d %%'</span> % <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="17"></td><td><pre>		classes<span class="token punctuation">[</span>i<span class="token punctuation">]</span>, <span class="token number">100</span> * class_correct<span class="token punctuation">[</span>i<span class="token punctuation">]</span> / class_total<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">))</span></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>Accuracy of plane <span class="token builtin class-name">:</span> <span class="token number">52</span> %</pre></td></tr><tr><td data-num="2"></td><td><pre>Accuracy of   car <span class="token builtin class-name">:</span> <span class="token number">66</span> %</pre></td></tr><tr><td data-num="3"></td><td><pre>Accuracy of  bird <span class="token builtin class-name">:</span> <span class="token number">49</span> %</pre></td></tr><tr><td data-num="4"></td><td><pre>Accuracy of   <span class="token function">cat</span> <span class="token builtin class-name">:</span> <span class="token number">34</span> %</pre></td></tr><tr><td data-num="5"></td><td><pre>Accuracy of  deer <span class="token builtin class-name">:</span> <span class="token number">30</span> %</pre></td></tr><tr><td data-num="6"></td><td><pre>Accuracy of   dog <span class="token builtin class-name">:</span> <span class="token number">45</span> %</pre></td></tr><tr><td data-num="7"></td><td><pre>Accuracy of  frog <span class="token builtin class-name">:</span> <span class="token number">72</span> %</pre></td></tr><tr><td data-num="8"></td><td><pre>Accuracy of horse <span class="token builtin class-name">:</span> <span class="token number">71</span> %</pre></td></tr><tr><td data-num="9"></td><td><pre>Accuracy of  ship <span class="token builtin class-name">:</span> <span class="token number">76</span> %</pre></td></tr><tr><td data-num="10"></td><td><pre>Accuracy of truck <span class="token builtin class-name">:</span> <span class="token number">55</span> %</pre></td></tr></table></figure><h4 id="gpu上训练"><a class="anchor" href="#gpu上训练">#</a> GPU 上训练</h4><p>为了在 GPU 上训练，我们需要把 Tensor 移到 GPU 上。首先我们看看是否有 GPU，如果没有，那么我们还是 fallback 到 CPU。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch.cuda.is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># cuda:0</span></pre></td></tr></table></figure><p>用 GPU 进行训练：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>class Net2<span class="token punctuation">(</span>nn.Module<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="2"></td><td><pre>def __init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="3"></td><td><pre>super<span class="token punctuation">(</span>Net2, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>self.conv1 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token number">6</span>, <span class="token number">5</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>self.pool <span class="token operator">=</span> nn.MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">2</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>self.conv2 <span class="token operator">=</span> nn.Conv2d<span class="token punctuation">(</span><span class="token number">6</span>, <span class="token number">16</span>, <span class="token number">5</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>self.fc1 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">16</span> * <span class="token number">5</span> * <span class="token number">5</span>, <span class="token number">120</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>self.fc2 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">120</span>, <span class="token number">84</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>self.fc3 <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span><span class="token number">84</span>, <span class="token number">10</span><span class="token punctuation">)</span>.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="12"></td><td><pre>x <span class="token operator">=</span> self.pool<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv1<span class="token punctuation">(</span>x<span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>x <span class="token operator">=</span> self.pool<span class="token punctuation">(</span>F.relu<span class="token punctuation">(</span>self.conv2<span class="token punctuation">(</span>x<span class="token punctuation">))</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>x <span class="token operator">=</span> x.view<span class="token punctuation">(</span>-1, <span class="token number">16</span> * <span class="token number">5</span> * <span class="token number">5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc1<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="16"></td><td><pre>x <span class="token operator">=</span> F.relu<span class="token punctuation">(</span>self.fc2<span class="token punctuation">(</span>x<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="17"></td><td><pre>x <span class="token operator">=</span> self.fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token builtin class-name">return</span> x</pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>net <span class="token operator">=</span> Net2<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>criterion <span class="token operator">=</span> nn.CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>optimizer <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>net.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">epoch</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>	running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="28"></td><td><pre>	<span class="token keyword">for</span> i, data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader, <span class="token number">0</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="29"></td><td><pre>		<span class="token comment"># 得到输入</span></pre></td></tr><tr><td data-num="30"></td><td><pre>		inputs, labels <span class="token operator">=</span> data </pre></td></tr><tr><td data-num="31"></td><td><pre>		inputs, labels <span class="token operator">=</span> inputs.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>, labels.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> </pre></td></tr><tr><td data-num="32"></td><td><pre>		<span class="token comment"># 梯度清零 </span></pre></td></tr><tr><td data-num="33"></td><td><pre>		optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre></pre></td></tr><tr><td data-num="35"></td><td><pre>		<span class="token comment"># forward + backward + optimize</span></pre></td></tr><tr><td data-num="36"></td><td><pre>		outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>		loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs, labels<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>		loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>		optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>		<span class="token comment"># 定义统计信息</span></pre></td></tr><tr><td data-num="42"></td><td><pre>		running_loss <span class="token operator">+=</span> loss.item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>		<span class="token keyword">if</span> i % <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span>:</pre></td></tr><tr><td data-num="44"></td><td><pre>			print<span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> %</pre></td></tr><tr><td data-num="45"></td><td><pre>				<span class="token punctuation">(</span>epoch + <span class="token number">1</span>, i + <span class="token number">1</span>, running_loss / <span class="token number">2000</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="46"></td><td><pre>			running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>		print<span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="通过例子学pytorch"><a class="anchor" href="#通过例子学pytorch">#</a> 通过例子学 PyTorch</h2><p>下面我们通过使用不同的方法来实现一个简单的三层 (一个隐层) 的全连接神经网络来熟悉 PyTorch 的常见用法。</p><h3 id="使用numpy实现三层神经网络"><a class="anchor" href="#使用numpy实现三层神经网络">#</a> 使用 Numpy 实现三层神经网络</h3><p>我们需要实现一个全连接的激活为 ReLU 的网络，它只有一个隐层，没有 bias，用于回归预测一个值，loss 是计算实际值和预测值的欧氏距离。这里完全使用 numpy 手动的进行前向和后向计算。numpy 数组就是一个 n 维的数值，它并不知道任何关于深度学习、梯度下降或者计算图的东西，它只是进行数值运算。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> numpy as np</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># N 是 batch size；D_in 是输入大小</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># H 是隐层的大小；D_out 是输出大小。</span></pre></td></tr><tr><td data-num="5"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># 随机产生输入与输出</span></pre></td></tr><tr><td data-num="8"></td><td><pre>x <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>N, D_in<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>y <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 随机初始化参数</span></pre></td></tr><tr><td data-num="12"></td><td><pre>w1 <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>D_in, H<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>w2 <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>H, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>learning_rate <span class="token operator">=</span> 1e-6</pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="17"></td><td><pre>	<span class="token comment"># 前向计算 y</span></pre></td></tr><tr><td data-num="18"></td><td><pre>	h <span class="token operator">=</span> x.dot<span class="token punctuation">(</span>w1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>	h_relu <span class="token operator">=</span> np.maximum<span class="token punctuation">(</span>h, <span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>	y_pred <span class="token operator">=</span> h_relu.dot<span class="token punctuation">(</span>w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>	<span class="token comment"># 计算 loss</span></pre></td></tr><tr><td data-num="23"></td><td><pre>	loss <span class="token operator">=</span> np.square<span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>	print<span class="token punctuation">(</span>t, loss<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>	<span class="token comment"># 反向计算梯度 </span></pre></td></tr><tr><td data-num="27"></td><td><pre>	grad_y_pred <span class="token operator">=</span> <span class="token number">2.0</span> * <span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>	grad_w2 <span class="token operator">=</span> h_relu.T.dot<span class="token punctuation">(</span>grad_y_pred<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>	grad_h_relu <span class="token operator">=</span> grad_y_pred.dot<span class="token punctuation">(</span>w2.T<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>	grad_h <span class="token operator">=</span> grad_h_relu.copy<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>	grad_h<span class="token punctuation">[</span>h <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="32"></td><td><pre>	grad_w1 <span class="token operator">=</span> x.T.dot<span class="token punctuation">(</span>grad_h<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>	<span class="token comment"># 更新参数</span></pre></td></tr><tr><td data-num="35"></td><td><pre>	w1 -<span class="token operator">=</span> learning_rate * grad_w1</pre></td></tr><tr><td data-num="36"></td><td><pre>	w2 -<span class="token operator">=</span> learning_rate * grad_w2</pre></td></tr></table></figure><h3 id="使用tensor来实现三层神经网络"><a class="anchor" href="#使用tensor来实现三层神经网络">#</a> 使用 Tensor 来实现三层神经网络</h3><p>和前面一样，我们还是实现一个全连接的 Relu 激活的网络，它只有一个隐层并且没有 bias。loss 是预测与真实值的欧氏距离。之前我们用 Numpy 实现，自己手动前向计算 loss，反向计算梯度。这里还是一样，只不过把 numpy 数组换成了 PyTorch 的 Tensor。但是使用 PyTorch 的好处是我们可以利用 GPU 来加速计算，如果想用 GPU 计算，我们值需要在创建 tensor 的时候指定 device 为 gpu。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>dtype <span class="token operator">=</span> torch.float</pre></td></tr><tr><td data-num="5"></td><td><pre>device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># device = torch.device ("cuda:0") # 如果想在 GPU 上运算，把这行注释掉。</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>w1 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>D_in, H, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>w2 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>H, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>learning_rate <span class="token operator">=</span> 1e-6</pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>: </pre></td></tr><tr><td data-num="18"></td><td><pre>	h <span class="token operator">=</span> x.mm<span class="token punctuation">(</span>w1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>	h_relu <span class="token operator">=</span> h.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 使用 clamp (min=0) 来实现 ReLU</span></pre></td></tr><tr><td data-num="20"></td><td><pre>	y_pred <span class="token operator">=</span> h_relu.mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>	loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span>.pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span>.item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>	print<span class="token punctuation">(</span>t, loss<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>	grad_y_pred <span class="token operator">=</span> <span class="token number">2.0</span> * <span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>	grad_w2 <span class="token operator">=</span> h_relu.t<span class="token punctuation">(</span><span class="token punctuation">)</span>.mm<span class="token punctuation">(</span>grad_y_pred<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>	grad_h_relu <span class="token operator">=</span> grad_y_pred.mm<span class="token punctuation">(</span>w2.t<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="28"></td><td><pre>	grad_h <span class="token operator">=</span> grad_h_relu.clone<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>	grad_h<span class="token punctuation">[</span>h <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="30"></td><td><pre>	grad_w1 <span class="token operator">=</span> x.t<span class="token punctuation">(</span><span class="token punctuation">)</span>.mm<span class="token punctuation">(</span>grad_h<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>	w1 -<span class="token operator">=</span> learning_rate * grad_w1</pre></td></tr><tr><td data-num="33"></td><td><pre>	w2 -<span class="token operator">=</span> learning_rate * grad_w2</pre></td></tr></table></figure><h3 id="实现autograd来实现三层神经网络"><a class="anchor" href="#实现autograd来实现三层神经网络">#</a> 实现 autograd 来实现三层神经网络</h3><p>还是和前面一样实现一个全连接的网络，只有一个隐层而且没有 bias，使用欧氏距离作为损失函数。这个实现使用 PyTorch 的 Tensor 来计算前向阶段，然后使用 PyTorch 的 autograd 来自动帮我们反向计算梯度。PyTorch 的 Tensor 代表了计算图中的一个节点。如果 x 是一个 Tensor 并且 x.requires_grad=True，那么 x.grad 这个 Tensor 会保存某个 scalar (通常是 loss) 对 x 的梯度。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>dtype <span class="token operator">=</span> torch.float</pre></td></tr><tr><td data-num="4"></td><td><pre>device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># device = torch.device ("cuda:0") # 如果有 GPU 可以注释掉这行</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># N 是 batch size；D_in 是输入大小</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># H 是隐层的大小；D_out 是输出大小。</span></pre></td></tr><tr><td data-num="9"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 创建随机的 Tensor 作为输入和输出</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 输入和输出需要的 requires_grad=False (默认)，</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># 因为我们不需要计算 loss 对它们的梯度。</span></pre></td></tr><tr><td data-num="14"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># 创建 weight 的 Tensor，需要设置 requires_grad=True </span></pre></td></tr><tr><td data-num="18"></td><td><pre>w1 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>D_in, H, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>w2 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>H, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>learning_rate <span class="token operator">=</span> 1e-6</pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="23"></td><td><pre>	<span class="token comment"># Forward 阶段: mm 实现矩阵乘法，但是它不支持 broadcasting。</span></pre></td></tr><tr><td data-num="24"></td><td><pre>	<span class="token comment"># 如果需要 broadcasting，可以使用 matmul</span></pre></td></tr><tr><td data-num="25"></td><td><pre>	<span class="token comment"># clamp 本来的用途是把值 clamp 到指定的范围，这里实现 ReLU。 </span></pre></td></tr><tr><td data-num="26"></td><td><pre>	y_pred <span class="token operator">=</span> x.mm<span class="token punctuation">(</span>w1<span class="token punctuation">)</span>.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>.mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>	<span class="token comment"># pow (2) 实现平方计算。 </span></pre></td></tr><tr><td data-num="29"></td><td><pre>	<span class="token comment"># loss.item () 得到这个 tensor 的值。也可以直接打印 loss，这会打印很多附加信息。</span></pre></td></tr><tr><td data-num="30"></td><td><pre>	loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span>.pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>	print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>	<span class="token comment"># 使用 autograd 进行反向计算。它会计算 loss 对所有对它有影响的</span></pre></td></tr><tr><td data-num="34"></td><td><pre>	<span class="token comment"># requires_grad=True 的 Tensor 的梯度。</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>	loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>	<span class="token comment"># 手动使用梯度下降更新参数。一定要把更新的代码放到 torch.no_grad () 里</span></pre></td></tr><tr><td data-num="39"></td><td><pre>	<span class="token comment"># 否则下面的更新也会计算梯度。后面我们会使用 torch.optim.SGD，</span></pre></td></tr><tr><td data-num="40"></td><td><pre>	<span class="token comment"># 它会帮我们管理这些用于更新梯度的计算。</span></pre></td></tr><tr><td data-num="41"></td><td><pre></pre></td></tr><tr><td data-num="42"></td><td><pre>	with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="43"></td><td><pre>		w1 -<span class="token operator">=</span> learning_rate * w1.grad</pre></td></tr><tr><td data-num="44"></td><td><pre>		w2 -<span class="token operator">=</span> learning_rate * w2.grad</pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>		<span class="token comment"># 手动把梯度清零 </span></pre></td></tr><tr><td data-num="47"></td><td><pre>		w1.grad.zero_<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>		w2.grad.zero_<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="使用自定义的relu函数"><a class="anchor" href="#使用自定义的relu函数">#</a> 使用自定义的 ReLU 函数</h3><p>这里还是那个全连接网络的例子，不过这里我们不使用 clamp 来实现 ReLU，而是我们自己来实现一个 MyReLU 的函数。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>class MyReLU<span class="token punctuation">(</span>torch.autograd.Function<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="5"></td><td><pre>	<span class="token string">""</span>"</pre></td></tr><tr><td data-num="6"></td><td><pre>	为了实现自定义的实现autograd的函数，我们需要基础torch.autograd.Function，</pre></td></tr><tr><td data-num="7"></td><td><pre>	然后再实现forward和backward两个函数。</pre></td></tr><tr><td data-num="8"></td><td><pre>	<span class="token string">""</span>"</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>	@staticmethod</pre></td></tr><tr><td data-num="11"></td><td><pre>	def forward<span class="token punctuation">(</span>ctx, input<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="12"></td><td><pre>		<span class="token string">""</span>"</pre></td></tr><tr><td data-num="13"></td><td><pre>		在forward函数，我们的输入是input，然后我们根据input计算输出。</pre></td></tr><tr><td data-num="14"></td><td><pre>		<span class="token comment"># 同时为了下面的 backward，</span></pre></td></tr><tr><td data-num="15"></td><td><pre>		我们需要使用save_for_backward来保存用于反向计算的数据到ctx里，</pre></td></tr><tr><td data-num="16"></td><td><pre>		<span class="token comment"># 这里我们需要保存 input。</span></pre></td></tr><tr><td data-num="17"></td><td><pre>		<span class="token string">""</span>"</pre></td></tr><tr><td data-num="18"></td><td><pre>		ctx.save_for_backward<span class="token punctuation">(</span>input<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>		<span class="token builtin class-name">return</span> input.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>	@staticmethod</pre></td></tr><tr><td data-num="22"></td><td><pre>	def backward<span class="token punctuation">(</span>ctx, grad_output<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="23"></td><td><pre>		<span class="token string">""</span>"</pre></td></tr><tr><td data-num="24"></td><td><pre>		从ctx.saved_tensors里恢复input</pre></td></tr><tr><td data-num="25"></td><td><pre>		然后用input计算梯度</pre></td></tr><tr><td data-num="26"></td><td><pre>		<span class="token string">""</span>"</pre></td></tr><tr><td data-num="27"></td><td><pre>		input, <span class="token operator">=</span> ctx.saved_tensors</pre></td></tr><tr><td data-num="28"></td><td><pre>		grad_input <span class="token operator">=</span> grad_output.clone<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>		grad_input<span class="token punctuation">[</span>input <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="30"></td><td><pre>		<span class="token builtin class-name">return</span> grad_input</pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>dtype <span class="token operator">=</span> torch.float</pre></td></tr><tr><td data-num="34"></td><td><pre>device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>w1 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>D_in, H, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>w2 <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>H, D_out, <span class="token assign-left variable">device</span><span class="token operator">=</span>device, <span class="token assign-left variable">dtype</span><span class="token operator">=</span>dtype, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>learning_rate <span class="token operator">=</span> 1e-6</pre></td></tr><tr><td data-num="45"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="46"></td><td><pre>	<span class="token comment"># 为了调用我们自定义的函数，我们需要使用 Function.apply 方法，把它命名为 'relu'</span></pre></td></tr><tr><td data-num="47"></td><td><pre>	relu <span class="token operator">=</span> MyReLU.apply</pre></td></tr><tr><td data-num="48"></td><td><pre></pre></td></tr><tr><td data-num="49"></td><td><pre>	<span class="token comment"># 我们使用自定义的 ReLU 来进行 Forward 计算</span></pre></td></tr><tr><td data-num="50"></td><td><pre>	y_pred <span class="token operator">=</span> relu<span class="token punctuation">(</span>x.mm<span class="token punctuation">(</span>w1<span class="token punctuation">))</span>.mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre></pre></td></tr><tr><td data-num="52"></td><td><pre>	loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred - y<span class="token punctuation">)</span>.pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre>	print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="54"></td><td><pre></pre></td></tr><tr><td data-num="55"></td><td><pre>	loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre></pre></td></tr><tr><td data-num="57"></td><td><pre>	with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="58"></td><td><pre>		w1 -<span class="token operator">=</span> learning_rate * w1.grad</pre></td></tr><tr><td data-num="59"></td><td><pre>		w2 -<span class="token operator">=</span> learning_rate * w2.grad</pre></td></tr><tr><td data-num="60"></td><td><pre></pre></td></tr><tr><td data-num="61"></td><td><pre>		w1.grad.zero_<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="62"></td><td><pre>		w2.grad.zero_<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="和tensorflow的对比"><a class="anchor" href="#和tensorflow的对比">#</a> 和 Tensorflow 的对比</h3><p>这里我们还是和前面一样，实现一个隐层的全连接神经网络，优化的目标函数是预测值和真实值的欧氏距离。这个实现使用基本的 Tensorflow 操作来构建一个计算图，然后多次执行这个计算图来训练网络。Tensorflow 和 PyTorch 最大的区别之一就是 Tensorflow 使用静态计算图和 PyTorch 使用动态计算图。在 Tensorflow 里，我们首先构建计算图，然后多次执行它。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> tensorflow as tf</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> numpy as np</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># 首先构建计算图。</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># N 是 batch 大小；D_in 是输入大小。</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># H 是隐单元个数；D_out 是输出大小。</span></pre></td></tr><tr><td data-num="8"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment"># 输入和输出是 placeholder，在用 session 执行 graph 的时候</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># 我们会 feed 进去一个 batch 的训练数据。</span></pre></td></tr><tr><td data-num="12"></td><td><pre>x <span class="token operator">=</span> tf.placeholder<span class="token punctuation">(</span>tf.float32, <span class="token assign-left variable">shape</span><span class="token operator">=</span><span class="token punctuation">(</span>None, D_in<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="13"></td><td><pre>y <span class="token operator">=</span> tf.placeholder<span class="token punctuation">(</span>tf.float32, <span class="token assign-left variable">shape</span><span class="token operator">=</span><span class="token punctuation">(</span>None, D_out<span class="token punctuation">))</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># 创建变量，并且随机初始化。 </span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># 在 Tensorflow 里，变量的生命周期是整个 session，因此适合用它来保存模型的参数。</span></pre></td></tr><tr><td data-num="17"></td><td><pre>w1 <span class="token operator">=</span> tf.Variable<span class="token punctuation">(</span>tf.random_normal<span class="token variable"><span class="token punctuation">((</span>D_in<span class="token punctuation">,</span> H<span class="token punctuation">))</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>w2 <span class="token operator">=</span> tf.Variable<span class="token punctuation">(</span>tf.random_normal<span class="token variable"><span class="token punctuation">((</span>H<span class="token punctuation">,</span> D_out<span class="token punctuation">))</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment"># Forward pass：计算模型的预测值 y_pred </span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token comment"># 注意和 PyTorch 不同，这里不会执行任何计算，</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment"># 而只是定义了计算，后面用 session.run 的时候才会真正的执行计算。</span></pre></td></tr><tr><td data-num="23"></td><td><pre>h <span class="token operator">=</span> tf.matmul<span class="token punctuation">(</span>x, w1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>h_relu <span class="token operator">=</span> tf.maximum<span class="token punctuation">(</span>h, tf.zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="25"></td><td><pre>y_pred <span class="token operator">=</span> tf.matmul<span class="token punctuation">(</span>h_relu, w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token comment"># 计算 loss </span></pre></td></tr><tr><td data-num="28"></td><td><pre>loss <span class="token operator">=</span> tf.reduce_sum<span class="token variable"><span class="token punctuation">((</span>y <span class="token operator">-</span> y_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2.0</span><span class="token punctuation">)</span></span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre># 计算梯度。 </pre></td></tr><tr><td data-num="31"></td><td><pre>grad_w1<span class="token punctuation">,</span> grad_w2 <span class="token operator">=</span> tf.gradients<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> [w1<span class="token punctuation">,</span> w2]<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre># 使用梯度下降来更新参数。assign同样也只是定义更新参数的操作，不会真正的执行。</pre></td></tr><tr><td data-num="34"></td><td><pre># 在Tensorflow里，更新操作是计算图的一部分；</pre></td></tr><tr><td data-num="35"></td><td><pre># 而在PyTorch里，因为是动态的”实时“的计算，</pre></td></tr><tr><td data-num="36"></td><td><pre># 所以参数的更新只是普通的Tensor计算，不属于计算图的一部分。</pre></td></tr><tr><td data-num="37"></td><td><pre>learning_rate <span class="token operator">=</span> <span class="token number">1e-6</span></pre></td></tr><tr><td data-num="38"></td><td><pre>new_w1 <span class="token operator">=</span> w1.assign<span class="token punctuation">(</span>w1 <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grad_w1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>new_w2 <span class="token operator">=</span> w2.assign<span class="token punctuation">(</span>w2 <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grad_w2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre># 计算图构建好了之后，我们需要创建一个session来执行计算图。</pre></td></tr><tr><td data-num="42"></td><td><pre>with tf.Session<span class="token punctuation">(</span><span class="token punctuation">)</span> as sess<span class="token operator">:</span></pre></td></tr><tr><td data-num="43"></td><td><pre>	# 首先需要用session初始化变量 </pre></td></tr><tr><td data-num="44"></td><td><pre>	sess.run<span class="token punctuation">(</span>tf.global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>	<span class="token comment"># 这是 fake 的训练数据</span></pre></td></tr><tr><td data-num="47"></td><td><pre>	x_value <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>N, D_in<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="48"></td><td><pre>	y_value <span class="token operator">=</span> np.random.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>	<span class="token keyword">for</span> <span class="token for-or-select variable">_</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="50"></td><td><pre>		<span class="token comment"># 用 session 多次的执行计算图。每次 feed 进去不同的数据。</span></pre></td></tr><tr><td data-num="51"></td><td><pre>		<span class="token comment"># 这里是模拟的，实际应该每次 feed 一个 batch 的数据。</span></pre></td></tr><tr><td data-num="52"></td><td><pre>		<span class="token comment"># run 的第一个参数是需要执行的计算图的节点，它依赖的节点也会自动执行，</span></pre></td></tr><tr><td data-num="53"></td><td><pre>		<span class="token comment">#　因此我们不需要手动执行 forward 的计算。</span></pre></td></tr><tr><td data-num="54"></td><td><pre>		<span class="token comment"># run 返回这些节点执行后的值，并且返回的是 numpy array</span></pre></td></tr><tr><td data-num="55"></td><td><pre>		loss_value, _, _ <span class="token operator">=</span> sess.run<span class="token punctuation">(</span><span class="token punctuation">[</span>loss, new_w1, new_w2<span class="token punctuation">]</span>,</pre></td></tr><tr><td data-num="56"></td><td><pre>				<span class="token assign-left variable">feed_dict</span><span class="token operator">=</span><span class="token punctuation">&#123;</span>x: x_value, y: y_value<span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre>		print<span class="token punctuation">(</span>loss_value<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="使用nn模块来实现三层神经网络"><a class="anchor" href="#使用nn模块来实现三层神经网络">#</a> 使用 nn 模块来实现三层神经网络</h3><p>我们接下来使用 nn 模块来实现这个简单的全连接网络。前面我们通过用 Tensor 和 Operation 等 low-level API 来创建 动态的计算图，这里我们使用更简单的 high-level API。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre>print<span class="token punctuation">(</span>torch.__version__<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># N 是 batch size；D_in 是输入大小 # H 是隐层的大小；D_out 是输出大小。 N, D_in, H, D_out = 64, 1000, 100, 10</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment"># 创建随机的 Tensor 作为输入和输出 x = torch.randn (N, D_in)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># 使用 nn 包来定义网络。nn.Sequential 是一个包含其它模块 (Module) 的模块。 # 每个 Linear 模块使用线性函数来计算，它会内部创建需要的 weight 和 bias。 model = torch.nn.Sequential (</span></pre></td></tr><tr><td data-num="10"></td><td><pre>	torch.nn.Linear<span class="token punctuation">(</span>D_in, H<span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="11"></td><td><pre>	torch.nn.ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="12"></td><td><pre>	torch.nn.Linear<span class="token punctuation">(</span>H, D_out<span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># 常见的损失函数在 nn 包里也有，不需要我们自己实现 loss_fn = torch.nn.MSELoss (size_average=False)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre>learning_rate <span class="token operator">=</span> 1e-4</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment"># 前向计算：通过 x 来计算 y。Module 对象会重写__call__函数， # 因此我们可以把它当成函数来调用。 y_pred = model (x)</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token comment"># 计算 loss loss = loss_fn (y_pred, y)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token comment"># 梯度清空，调用 Sequential 对象的 zero_grad 后所有里面的变量都会清零梯度 model.zero_grad ()</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token comment"># 反向计算梯度。我们通过 Module 定义的变量都会计算梯度。 loss.backward ()</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token comment"># 更新参数，所有的参数都在 model.paramenters () 里 </span></pre></td></tr><tr><td data-num="29"></td><td><pre>with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="30"></td><td><pre>	<span class="token keyword">for</span> <span class="token for-or-select variable">param</span> <span class="token keyword">in</span> model.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="31"></td><td><pre>		param -<span class="token operator">=</span> learning_rate * param.grad</pre></td></tr></table></figure><h3 id="使用optim包"><a class="anchor" href="#使用optim包">#</a> 使用 optim 包</h3><p>前面我们使用 nn 模块时是自己来更新模型参数的，PyTorch 也提供了 optim 包，我们可以使用里面的 Optimizer 来自动的更新模型参数。除了最基本的 SGD 算法，这个包也实现了常见的 SGD+momentum, RMSProp, Adam 等算法。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>model <span class="token operator">=</span> torch.nn.Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="9"></td><td><pre>	torch.nn.Linear<span class="token punctuation">(</span>D_in, H<span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="10"></td><td><pre>	torch.nn.ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="11"></td><td><pre>	torch.nn.Linear<span class="token punctuation">(</span>H, D_out<span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>loss_fn <span class="token operator">=</span> torch.nn.MSELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span>False<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment"># 使用 Adam 算法，需要提供模型的参数和 learning rate learning_rate = 1e-4</span></pre></td></tr><tr><td data-num="16"></td><td><pre>optimizer <span class="token operator">=</span> torch.optim.Adam<span class="token punctuation">(</span>model.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>: </pre></td></tr><tr><td data-num="18"></td><td><pre>	y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>	loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred, y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>	print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>	<span class="token comment"># 梯度清零，原来调用的是 model.zero_grad，现在调用的是 optimizer 的 zero_grad 	optimizer.zero_grad ()</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>	loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>	<span class="token comment"># 调用 optimizer.step 实现参数更新 	optimizer.step ()</span></pre></td></tr></table></figure><h3 id="自定义nn模块"><a class="anchor" href="#自定义nn模块">#</a> 自定义 nn 模块</h3><p>对于复杂的网络结构，我们可以通过基础 Module 了自定义 nn 模块。这样的好处是用一个类来同样管理，而且更容易复用代码。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>class TwoLayerNet<span class="token punctuation">(</span>torch.nn.Module<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="5"></td><td><pre>	def __init__<span class="token punctuation">(</span>self, D_in, H, D_out<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="6"></td><td><pre>		<span class="token string">""</span>" 在构造函数里，我们定义两个nn.Linear模块，把它们保存到self里。 <span class="token string">""</span>"</pre></td></tr><tr><td data-num="7"></td><td><pre>		super<span class="token punctuation">(</span>TwoLayerNet, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>		self.linear1 <span class="token operator">=</span> torch.nn.Linear<span class="token punctuation">(</span>D_in, H<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>		self.linear2 <span class="token operator">=</span> torch.nn.Linear<span class="token punctuation">(</span>H, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>	def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="12"></td><td><pre>		<span class="token string">""</span>" 在forward函数里，我们需要根据网络结构来实现前向计算。 通常我们会上定义的模块来计算。 <span class="token string">""</span>"</pre></td></tr><tr><td data-num="13"></td><td><pre>		h_relu <span class="token operator">=</span> self.linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>		y_pred <span class="token operator">=</span> self.linear2<span class="token punctuation">(</span>h_relu<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>		<span class="token builtin class-name">return</span> y_pred</pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>model <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>D_in, H, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>criterion <span class="token operator">=</span> torch.nn.MSELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span>False<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>optimizer <span class="token operator">=</span> torch.optim.SGD<span class="token punctuation">(</span>model.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span>1e-4<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>: </pre></td></tr><tr><td data-num="28"></td><td><pre>	y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>	loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred, y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>	print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>	optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>	loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>	optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="流程控制和参数共享"><a class="anchor" href="#流程控制和参数共享">#</a> 流程控制和参数共享</h3><p>为了展示 PyTorch 的动态图的能力，我们这里会实现一个很奇怪模型：这个全连接的网络的隐层个数是个 1 到 4 之间的随机数，而且这些网络层的参数是共享的。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">import</span> random</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>class DynamicNet<span class="token punctuation">(</span>torch.nn.Module<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="6"></td><td><pre>	def __init__<span class="token punctuation">(</span>self, D_in, H, D_out<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="7"></td><td><pre>		<span class="token string">""</span>" 构造3个nn.Linear实例。 <span class="token string">""</span>"</pre></td></tr><tr><td data-num="8"></td><td><pre>		super<span class="token punctuation">(</span>DynamicNet, self<span class="token punctuation">)</span>.__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>		self.input_linear <span class="token operator">=</span> torch.nn.Linear<span class="token punctuation">(</span>D_in, H<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>		self.middle_linear <span class="token operator">=</span> torch.nn.Linear<span class="token punctuation">(</span>H, H<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>		self.output_linear <span class="token operator">=</span> torch.nn.Linear<span class="token punctuation">(</span>H, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>	def forward<span class="token punctuation">(</span>self, x<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="14"></td><td><pre>		<span class="token comment"># 输入和输出层是固定的，但是中间层的个数是随机的 (0,1,2)， 		# 并且中间层的参数是共享的。 </span></pre></td></tr><tr><td data-num="15"></td><td><pre>		<span class="token comment"># 因为每次计算的计算图是动态 (实时) 构造的， 		# 所以我们可以使用普通的 Python 流程控制代码比如 for 循环 		# 来实现。读者可以尝试一下怎么用 TensorFlow 来实现。 		# 另外一点就是一个 Module 可以多次使用，这样就 		# 可以实现参数共享。 </span></pre></td></tr><tr><td data-num="16"></td><td><pre>		h_relu <span class="token operator">=</span> self.input_linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>		<span class="token keyword">for</span> <span class="token for-or-select variable">_</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span>random.randint<span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">3</span><span class="token punctuation">))</span>:</pre></td></tr><tr><td data-num="18"></td><td><pre>		h_relu <span class="token operator">=</span> self.middle_linear<span class="token punctuation">(</span>h_relu<span class="token punctuation">)</span>.clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>		y_pred <span class="token operator">=</span> self.output_linear<span class="token punctuation">(</span>h_relu<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>		<span class="token builtin class-name">return</span> y_pred</pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>N, D_in, H, D_out <span class="token operator">=</span> <span class="token number">64</span>, <span class="token number">1000</span>, <span class="token number">100</span>, <span class="token number">10</span></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>x <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_in<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>y <span class="token operator">=</span> torch.randn<span class="token punctuation">(</span>N, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>model <span class="token operator">=</span> DynamicNet<span class="token punctuation">(</span>D_in, H, D_out<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>criterion <span class="token operator">=</span> torch.nn.MSELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span>False<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>optimizer <span class="token operator">=</span> torch.optim.SGD<span class="token punctuation">(</span>model.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span>1e-4, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">t</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>: </pre></td></tr><tr><td data-num="33"></td><td><pre>	y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre></pre></td></tr><tr><td data-num="35"></td><td><pre>	loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred, y<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>	print<span class="token punctuation">(</span>t, loss.item<span class="token punctuation">(</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>	optimizer.zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>	loss.backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>	optimizer.step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="迁移学习示例"><a class="anchor" href="#迁移学习示例">#</a> 迁移学习示例</h2><p>在这个教程里，我们会学习怎么使用迁移学习来训练模型。通常我们的训练数据量不会很大，很难达到像 ImageNet 那样上百万的标注数据集。我们可以使用迁移学习来解决训练数据不足的问题。迁移学习里，我们根据训练数据的多少通常可以采取如下方法：</p><ul><li>训练数据很少 那么我们通常把一个 pretraning 的网络的大部分固定住，然后只是把最后一个全连接层换成新的 (最后一层通常是不一样的，因为分类的数量不同)，然后只训练这一层</li><li>训练数据较多 我们可以把 pretraining 的网络的前面一些层固定住，但后面的层不固定，把最后一层换新的，然后训练</li><li>训练数据很多 所有的 pretraining 的层都可以 fine-tuning，只是用 pretraining 的参数作为初始化参数。</li></ul><p>首先我们引入依赖：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>from __future__ <span class="token function">import</span> print_function, division</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token function">import</span> torch</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token function">import</span> torch.nn as nn</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token function">import</span> torch.optim as optim</pre></td></tr><tr><td data-num="6"></td><td><pre>from torch.optim <span class="token function">import</span> lr_scheduler</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token function">import</span> numpy as np</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token function">import</span> torchvision</pre></td></tr><tr><td data-num="9"></td><td><pre>from torchvision <span class="token function">import</span> datasets, models, transforms</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token function">import</span> matplotlib.pyplot as plt</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token function">import</span> <span class="token function">time</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token function">import</span> os</pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token function">import</span> copy</pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>plt.ion<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="加载数据"><a class="anchor" href="#加载数据">#</a> 加载数据</h3><p>我们使用 torchvision 和 torch.utils.data 包来加载数据。我们要解决的问题是训练一个模型来区分蚂蚁和蜜蜂，每个类别我们大概有 120 个训练数据，另外每个类有 75 个验证数据。这是一个很小的训练集，如果直接用一个神经网络来训练，效果会很差。现在我们用迁移学习来解决这个问题。数据可以在<span class="exturl" data-url="aHR0cHM6Ly9kb3dubG9hZC5weXRvcmNoLm9yZy90dXRvcmlhbC9oeW1lbm9wdGVyYV9kYXRhLnppcA==">这里</span>下载，下载后请解压到 data 目录下。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 训练的时候会做数据增强和归一化</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 而验证的时候只做归一化</span></pre></td></tr><tr><td data-num="3"></td><td><pre>data_transforms <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	<span class="token string">'train'</span><span class="token builtin class-name">:</span> transforms.Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="5"></td><td><pre>		transforms.RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="6"></td><td><pre>		transforms.RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="7"></td><td><pre>		transforms.ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="8"></td><td><pre>		transforms.Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span>, <span class="token number">0.456</span>, <span class="token number">0.406</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">0.229</span>, <span class="token number">0.224</span>, <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>	<span class="token punctuation">]</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="10"></td><td><pre>	<span class="token string">'val'</span><span class="token builtin class-name">:</span> transforms.Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="11"></td><td><pre>		transforms.Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="12"></td><td><pre>		transforms.CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="13"></td><td><pre>		transforms.ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="14"></td><td><pre>		transforms.Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span>, <span class="token number">0.456</span>, <span class="token number">0.406</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">0.229</span>, <span class="token number">0.224</span>, <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>	<span class="token punctuation">]</span><span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>data_dir <span class="token operator">=</span> <span class="token string">'../data/hymenoptera_data'</span></pre></td></tr><tr><td data-num="19"></td><td><pre>image_datasets <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x: datasets.ImageFolder<span class="token punctuation">(</span>os.path.join<span class="token punctuation">(</span>data_dir, x<span class="token punctuation">)</span>,</pre></td></tr><tr><td data-num="20"></td><td><pre>		data_transforms<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span> </pre></td></tr><tr><td data-num="21"></td><td><pre>	<span class="token keyword">for</span> <span class="token for-or-select variable">x</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span>, <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="22"></td><td><pre>dataloaders <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x: torch.utils.data.DataLoader<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span>, <span class="token assign-left variable">batch_size</span><span class="token operator">=</span><span class="token number">4</span>,</pre></td></tr><tr><td data-num="23"></td><td><pre>		<span class="token assign-left variable">shuffle</span><span class="token operator">=</span>True, <span class="token assign-left variable">num_workers</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>	<span class="token keyword">for</span> <span class="token for-or-select variable">x</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span>, <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="25"></td><td><pre>dataset_sizes <span class="token operator">=</span> <span class="token punctuation">&#123;</span>x: len<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">x</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span>, <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="26"></td><td><pre>class_names <span class="token operator">=</span> image_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span>.classes</pre></td></tr><tr><td data-num="27"></td><td><pre></pre></td></tr><tr><td data-num="28"></td><td><pre>device <span class="token operator">=</span> torch.device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch.cuda.is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="可视化图片"><a class="anchor" href="#可视化图片">#</a> 可视化图片</h3><p>我们来显示几张图片看看，<span class="exturl" data-url="aHR0cDovL2ZhbmN5ZXJpaS5naXRodWIuaW8vYm9va3MvcHl0b3JjaC8jdHJhbnNmZXIx">下图</span>是一个 batch 的图片，显示的代码如下：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>def imshow<span class="token punctuation">(</span>inp, <span class="token assign-left variable">title</span><span class="token operator">=</span>None<span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="2"></td><td><pre>	inp <span class="token operator">=</span> inp.numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>.transpose<span class="token variable"><span class="token punctuation">((</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">))</span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>	mean <span class="token operator">=</span> np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span>, <span class="token number">0.456</span>, <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	std <span class="token operator">=</span> np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.229</span>, <span class="token number">0.224</span>, <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>	inp <span class="token operator">=</span> std * inp + mean</pre></td></tr><tr><td data-num="6"></td><td><pre>	inp <span class="token operator">=</span> np.clip<span class="token punctuation">(</span>inp, <span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>	plt.imshow<span class="token punctuation">(</span>inp<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>	<span class="token keyword">if</span> title is not None:</pre></td></tr><tr><td data-num="9"></td><td><pre>		plt.title<span class="token punctuation">(</span>title<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>	plt.pause<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># 得到一个 batch 的数据</span></pre></td></tr><tr><td data-num="14"></td><td><pre>inputs, classes <span class="token operator">=</span> next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloaders<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment"># 把 batch 张图片拼接成一个大图</span></pre></td></tr><tr><td data-num="17"></td><td><pre>out <span class="token operator">=</span> torchvision.utils.make_grid<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>imshow<span class="token punctuation">(</span>out, <span class="token assign-left variable">title</span><span class="token operator">=</span><span class="token punctuation">[</span>class_names<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token for-or-select variable">x</span> <span class="token keyword">in</span> classes<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/./images/pytorch%E5%85%A5%E9%97%A8/cf0dbfb6c30cd9c05fa99948d6999f81.png" alt="图 5"><br><em>图：迁移学习数据示例</em></p><h3 id="训练模型"><a class="anchor" href="#训练模型">#</a> 训练模型</h3><p>现在我们来实现一个用于训练模型的通用函数。这里我们会演示怎么实现：</p><ul><li>learning rate 的自适应</li><li>保存最好的模型</li></ul><p>在下面的函数中，参数 scheduler 是来自 torch.optim.lr_scheduler 的 LR scheduler 对象 (_LRScheduler 的子类）</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> scheduler<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>	since <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>	best_model_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>	best_acc <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>	<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>		<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch &#123;&#125;/&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> num_epochs <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>		<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>		<span class="token comment"># 每个 epoch 都分为训练和验证阶段</span></pre></td></tr><tr><td data-num="12"></td><td><pre>		<span class="token keyword">for</span> phase <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>			<span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>				scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>				model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 训练阶段</span></pre></td></tr><tr><td data-num="16"></td><td><pre>			<span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>				model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># 验证阶段</span></pre></td></tr><tr><td data-num="18"></td><td><pre>	</pre></td></tr><tr><td data-num="19"></td><td><pre>			running_loss <span class="token operator">=</span> <span class="token number">0.0</span></pre></td></tr><tr><td data-num="20"></td><td><pre>			running_corrects <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="21"></td><td><pre>	</pre></td></tr><tr><td data-num="22"></td><td><pre>			<span class="token comment"># 变量数据集</span></pre></td></tr><tr><td data-num="23"></td><td><pre>			<span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloaders<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="24"></td><td><pre>				inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>				labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>	</pre></td></tr><tr><td data-num="27"></td><td><pre>			<span class="token comment"># 参数梯度清空</span></pre></td></tr><tr><td data-num="28"></td><td><pre>			optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>	</pre></td></tr><tr><td data-num="30"></td><td><pre>			<span class="token comment"># forward</span></pre></td></tr><tr><td data-num="31"></td><td><pre>			<span class="token comment"># 只有训练的时候 track 用于梯度计算的历史信息。</span></pre></td></tr><tr><td data-num="32"></td><td><pre>			<span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span>phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="33"></td><td><pre>				outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>				_<span class="token punctuation">,</span> preds <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>				loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>		</pre></td></tr><tr><td data-num="37"></td><td><pre>				<span class="token comment"># 如果是训练，那么需要 backward 和更新参数 </span></pre></td></tr><tr><td data-num="38"></td><td><pre>				<span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="39"></td><td><pre>					loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>					optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>	</pre></td></tr><tr><td data-num="42"></td><td><pre>			<span class="token comment"># 统计</span></pre></td></tr><tr><td data-num="43"></td><td><pre>			running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>			running_corrects <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">.</span>data<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>	</pre></td></tr><tr><td data-num="46"></td><td><pre>			epoch_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="47"></td><td><pre>			epoch_acc <span class="token operator">=</span> running_corrects<span class="token punctuation">.</span>double<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="48"></td><td><pre>	</pre></td></tr><tr><td data-num="49"></td><td><pre>			<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="50"></td><td><pre>				phase<span class="token punctuation">,</span> epoch_loss<span class="token punctuation">,</span> epoch_acc<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>	</pre></td></tr><tr><td data-num="52"></td><td><pre>			<span class="token comment"># 保存验证集上的最佳模型</span></pre></td></tr><tr><td data-num="53"></td><td><pre>			<span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'val'</span> <span class="token keyword">and</span> epoch_acc <span class="token operator">></span> best_acc<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="54"></td><td><pre>				best_acc <span class="token operator">=</span> epoch_acc</pre></td></tr><tr><td data-num="55"></td><td><pre>				best_model_wts <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>	</pre></td></tr><tr><td data-num="57"></td><td><pre>			<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>	time_elapsed <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> since</pre></td></tr><tr><td data-num="60"></td><td><pre>	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="61"></td><td><pre>		time_elapsed <span class="token operator">//</span> <span class="token number">60</span><span class="token punctuation">,</span> time_elapsed <span class="token operator">%</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="62"></td><td><pre>	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best val Acc: &#123;:4f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre>	<span class="token comment"># 加载最优模型</span></pre></td></tr><tr><td data-num="65"></td><td><pre>	model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>best_model_wts<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="66"></td><td><pre>	<span class="token keyword">return</span> model</pre></td></tr></table></figure><h3 id="可视化预测结果的函数"><a class="anchor" href="#可视化预测结果的函数">#</a> 可视化预测结果的函数</h3><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>def visualize_model<span class="token punctuation">(</span>model, <span class="token assign-left variable">num_images</span><span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="2"></td><td><pre>	was_training <span class="token operator">=</span> model.training</pre></td></tr><tr><td data-num="3"></td><td><pre>	model.eval<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	images_so_far <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="5"></td><td><pre>	fig <span class="token operator">=</span> plt.figure<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>	with torch.no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="8"></td><td><pre>		<span class="token keyword">for</span> i, <span class="token punctuation">(</span>inputs, labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>dataloaders<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="9"></td><td><pre>			inputs <span class="token operator">=</span> inputs.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>			labels <span class="token operator">=</span> labels.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>	</pre></td></tr><tr><td data-num="12"></td><td><pre>			outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>			_, preds <span class="token operator">=</span> torch.max<span class="token punctuation">(</span>outputs, <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>	</pre></td></tr><tr><td data-num="15"></td><td><pre>			<span class="token keyword">for</span> <span class="token for-or-select variable">j</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span>inputs.size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="16"></td><td><pre>				images_so_far <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="17"></td><td><pre>				ax <span class="token operator">=</span> plt.subplot<span class="token punctuation">(</span>num_images//2, <span class="token number">2</span>, images_so_far<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>				ax.axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>				ax.set_title<span class="token punctuation">(</span><span class="token string">'predicted: &#123;&#125;'</span>.format<span class="token punctuation">(</span>class_names<span class="token punctuation">[</span>preds<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">))</span></pre></td></tr><tr><td data-num="20"></td><td><pre>				imshow<span class="token punctuation">(</span>inputs.cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>.data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>		</pre></td></tr><tr><td data-num="22"></td><td><pre>				<span class="token keyword">if</span> images_so_far <span class="token operator">==</span> num_images:</pre></td></tr><tr><td data-num="23"></td><td><pre>					model.train<span class="token punctuation">(</span>mode<span class="token operator">=</span>was_training<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>					<span class="token builtin class-name">return</span></pre></td></tr><tr><td data-num="25"></td><td><pre>		model.train<span class="token punctuation">(</span>mode<span class="token operator">=</span>was_training<span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="fine-tuning所有参数"><a class="anchor" href="#fine-tuning所有参数">#</a> fine-tuning 所有参数</h3><p>我们首先加载一个预训练的模型 (imagenet 上的 resnet)，因为我们的类别数和 imagenet 不同，所以我们需要删掉原来的全连接层，换成新的全连接层。这里我们让所有的模型参数都可以调整，包括新加的全连接层和预训练的层。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>model_ft <span class="token operator">=</span> models.resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>num_ftrs <span class="token operator">=</span> model_ft.fc.in_features</pre></td></tr><tr><td data-num="3"></td><td><pre>model_ft.fc <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span>num_ftrs, <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>model_ft <span class="token operator">=</span> model_ft.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>criterion <span class="token operator">=</span> nn.CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment"># 所有的参数都可以训练</span></pre></td></tr><tr><td data-num="10"></td><td><pre>optimizer_ft <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>model_ft.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment"># 每 7 个 epoch learning rate 变为原来的 10% </span></pre></td></tr><tr><td data-num="13"></td><td><pre>exp_lr_scheduler <span class="token operator">=</span> lr_scheduler.StepLR<span class="token punctuation">(</span>optimizer_ft, <span class="token assign-left variable">step_size</span><span class="token operator">=</span><span class="token number">7</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>model_ft <span class="token operator">=</span> train_model<span class="token punctuation">(</span>model_ft, criterion, optimizer_ft, exp_lr_scheduler,</pre></td></tr><tr><td data-num="16"></td><td><pre>	<span class="token assign-left variable">num_epochs</span><span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>最终我们得到的分类准确率大概在 94.7%。</p><h3 id="fine-tuning最后一层参数"><a class="anchor" href="#fine-tuning最后一层参数">#</a> fine-tuning 最后一层参数</h3><p>我们用可以固定住前面层的参数，只训练最后一层。这比之前要快将近一倍，因为反向计算梯度只需要计算最后一层。但是前向计算的时间是一样的。</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>model_conv <span class="token operator">=</span> torchvision.models.resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>True<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">for</span> <span class="token for-or-select variable">param</span> <span class="token keyword">in</span> model_conv.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>:</pre></td></tr><tr><td data-num="3"></td><td><pre>	param.requires_grad <span class="token operator">=</span> False</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment"># 新加的层默认 requires_grad=True </span></pre></td></tr><tr><td data-num="6"></td><td><pre>num_ftrs <span class="token operator">=</span> model_conv.fc.in_features</pre></td></tr><tr><td data-num="7"></td><td><pre>model_conv.fc <span class="token operator">=</span> nn.Linear<span class="token punctuation">(</span>num_ftrs, <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>model_conv <span class="token operator">=</span> model_conv.to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>criterion <span class="token operator">=</span> nn.CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># 值训练最后一个全连接层。</span></pre></td></tr><tr><td data-num="14"></td><td><pre>optimizer_conv <span class="token operator">=</span> optim.SGD<span class="token punctuation">(</span>model_conv.fc.parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>, <span class="token assign-left variable">lr</span><span class="token operator">=</span><span class="token number">0.001</span>, <span class="token assign-left variable">momentum</span><span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>exp_lr_scheduler <span class="token operator">=</span> lr_scheduler.StepLR<span class="token punctuation">(</span>optimizer_conv, <span class="token assign-left variable">step_size</span><span class="token operator">=</span><span class="token number">7</span>, <span class="token assign-left variable">gamma</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>model_conv <span class="token operator">=</span> train_model<span class="token punctuation">(</span>model_conv, criterion, optimizer_conv,</pre></td></tr><tr><td data-num="19"></td><td><pre>	exp_lr_scheduler, <span class="token assign-left variable">num_epochs</span><span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>最终我们得到的分类准确率大概在 96%。</p><div class="tags"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 深度学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" rel="tag"><i class="ic i-tag"></i> 深度学习框架</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-11-12 19:08:00" itemprop="dateModified" datetime="2022-11-12T19:08:00+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" title="pytorch入门">https://jyuanhust.github.io/2022/07/22/ai/pytorch/pytorch入门/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/07/21/ai/cv/OpenCV%E6%95%99%E7%A8%8B/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(66).webp" title="OpenCV教程"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> cv</span><h3>OpenCV教程</h3></a></div><div class="item right"><a href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(62).webp" title="ncnn和opencv在vs2022上创建工程推理示例"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> cv</span><h3>ncnn和opencv在vs2022上创建工程推理示例</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B"><span class="toc-number">1.</span> <span class="toc-text">初始</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%A2%E6%BA%90"><span class="toc-number">1.2.</span> <span class="toc-text">换源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">1.3.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFpytorch"><span class="toc-number">1.4.</span> <span class="toc-text">什么是 pytorch?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5gpu%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">检查 GPU 是否可用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E6%B3%95%E5%AE%9D%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.</span> <span class="toc-text">两个法宝函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dataset"><span class="toc-number">1.7.</span> <span class="toc-text">Dataset</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensorboard"><span class="toc-number">2.</span> <span class="toc-text">tensorboard</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#transform"><span class="toc-number">2.1.</span> <span class="toc-text">Transform</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#totensor"><span class="toc-number">2.1.1.</span> <span class="toc-text">Totensor</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#normalize"><span class="toc-number">2.2.</span> <span class="toc-text">Normalize</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#resize"><span class="toc-number">2.3.</span> <span class="toc-text">Resize</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#compose"><span class="toc-number">2.4.</span> <span class="toc-text">Compose</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#torchvision%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8"><span class="toc-number">2.5.</span> <span class="toc-text">torchvision 数据集使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dataloader"><span class="toc-number">2.6.</span> <span class="toc-text">dataloader</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nn"><span class="toc-number">3.</span> <span class="toc-text">nn</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E4%BE%8B%E5%AD%90"><span class="toc-number">3.1.</span> <span class="toc-text">简单例子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">3.2.</span> <span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">最大池化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB"><span class="toc-number">3.4.</span> <span class="toc-text">非线性激活</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82%E5%8F%8A%E5%85%B6%E4%BB%96%E5%B1%82"><span class="toc-number">4.</span> <span class="toc-text">线性层及其他层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%B1%82"><span class="toc-number">4.1.</span> <span class="toc-text">正则化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82"><span class="toc-number">4.2.</span> <span class="toc-text">线性层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sequential"><span class="toc-number">4.3.</span> <span class="toc-text">Sequential</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">5.</span> <span class="toc-text">损失函数和反向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">5.1.</span> <span class="toc-text">优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">5.1.1.</span> <span class="toc-text">基本使用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">5.1.2.</span> <span class="toc-text">优化器的选择</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#1sgd"><span class="toc-number"></span> <span class="toc-text">1.SGD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2rmsproproot-mean-square-prop%E5%9D%87%E6%96%B9%E6%A0%B9%E4%BC%A0%E9%80%92"><span class="toc-number"></span> <span class="toc-text">2.RMSProp (Root Mean Square Prop，均方根传递）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3adamamsgrad"><span class="toc-number"></span> <span class="toc-text">3.Adam(AMSGrad)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%AE%E6%94%B9%E5%92%8C%E4%BD%BF%E7%94%A8"><span class="toc-number">1.</span> <span class="toc-text">现有模型的修改和使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">2.</span> <span class="toc-text">网络模型保存与读取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98"><span class="toc-number">2.1.</span> <span class="toc-text">保存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96"><span class="toc-number">2.2.</span> <span class="toc-text">读取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8gpu%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">3.</span> <span class="toc-text">利用 GPU 进行训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%B8%80"><span class="toc-number">3.1.</span> <span class="toc-text">方式一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%BC%8F%E4%BA%8C"><span class="toc-number">3.2.</span> <span class="toc-text">方式二</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%8B%E9%9D%A2%E6%98%AF%E5%8E%9F%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9"><span class="toc-number"></span> <span class="toc-text">下面是原博客内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#tensor"><span class="toc-number">0.1.</span> <span class="toc-text">Tensor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#operation"><span class="toc-number">0.2.</span> <span class="toc-text">Operation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tensor%E7%9A%84%E5%8F%98%E6%8D%A2"><span class="toc-number">0.3.</span> <span class="toc-text">Tensor 的变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tensor%E4%B8%8Enumpy%E7%9A%84%E4%BA%92%E7%9B%B8%E8%BD%AC%E6%8D%A2"><span class="toc-number">0.4.</span> <span class="toc-text">Tensor 与 Numpy 的互相转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cuda-tensor"><span class="toc-number">0.5.</span> <span class="toc-text">CUDA Tensor</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#autograd-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC"><span class="toc-number">1.</span> <span class="toc-text">Autograd: 自动求导</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E7%9C%8Btensor"><span class="toc-number">1.1.</span> <span class="toc-text">从自动求导看 Tensor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6"><span class="toc-number">1.2.</span> <span class="toc-text">梯度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text">PyTorch 神经网络简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C"><span class="toc-number">2.1.</span> <span class="toc-text">定义网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C"><span class="toc-number">2.2.</span> <span class="toc-text">测试网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6"><span class="toc-number">2.4.</span> <span class="toc-text">计算梯度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0"><span class="toc-number">2.5.</span> <span class="toc-text">更新参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">3.</span> <span class="toc-text">训练一个分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">如何进行数据处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.2.</span> <span class="toc-text">训练的步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">3.3.</span> <span class="toc-text">数据处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="toc-number">3.4.</span> <span class="toc-text">定义卷积网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%B5%8B%E8%AF%95"><span class="toc-number">3.5.</span> <span class="toc-text">在测试数据集上进行测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gpu%E4%B8%8A%E8%AE%AD%E7%BB%83"><span class="toc-number">3.6.</span> <span class="toc-text">GPU 上训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E4%BE%8B%E5%AD%90%E5%AD%A6pytorch"><span class="toc-number"></span> <span class="toc-text">通过例子学 PyTorch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">使用 Numpy 实现三层神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8tensor%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">2.</span> <span class="toc-text">使用 Tensor 来实现三层神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0autograd%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.</span> <span class="toc-text">实现 autograd 来实现三层神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84relu%E5%87%BD%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text">使用自定义的 ReLU 函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%92%8Ctensorflow%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">5.</span> <span class="toc-text">和 Tensorflow 的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8nn%E6%A8%A1%E5%9D%97%E6%9D%A5%E5%AE%9E%E7%8E%B0%E4%B8%89%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">6.</span> <span class="toc-text">使用 nn 模块来实现三层神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8optim%E5%8C%85"><span class="toc-number">7.</span> <span class="toc-text">使用 optim 包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89nn%E6%A8%A1%E5%9D%97"><span class="toc-number">8.</span> <span class="toc-text">自定义 nn 模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%92%8C%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB"><span class="toc-number">9.</span> <span class="toc-text">流程控制和参数共享</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%A4%BA%E4%BE%8B"><span class="toc-number"></span> <span class="toc-text">迁移学习示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">1.</span> <span class="toc-text">加载数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E7%89%87"><span class="toc-number">2.</span> <span class="toc-text">可视化图片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E5%87%BD%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text">可视化预测结果的函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fine-tuning%E6%89%80%E6%9C%89%E5%8F%82%E6%95%B0"><span class="toc-number">5.</span> <span class="toc-text">fine-tuning 所有参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fine-tuning%E6%9C%80%E5%90%8E%E4%B8%80%E5%B1%82%E5%8F%82%E6%95%B0"><span class="toc-number">6.</span> <span class="toc-text">fine-tuning 最后一层参数</span></a></li></ol></li></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/2022/07/22/ai/pytorch/pytorch%E5%85%A5%E9%97%A8/" rel="bookmark" title="pytorch入门">pytorch入门</a></li><li><a href="/2022/07/25/ai/pytorch/argmax-torch/" rel="bookmark" title="argmax-torch">argmax-torch</a></li><li><a href="/2022/07/25/ai/pytorch/%E4%BD%BF%E7%94%A8Pytorch%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" rel="bookmark" title="使用Pytorch实现手写数字识别">使用Pytorch实现手写数字识别</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" rel="bookmark" title="Pytorch中transforms.RandomResizedCrop()等图像操作">Pytorch中transforms.RandomResizedCrop()等图像操作</a></li><li><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" rel="bookmark" title="pytorch中的transpose方法（函数）">pytorch中的transpose方法（函数）</a></li><li><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" rel="bookmark" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()">PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" rel="bookmark" title="Pytorch函数expand()详解">Pytorch函数expand()详解</a></li><li><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" rel="bookmark" title="pytorch固定随机种子-训练稳定复现">pytorch固定随机种子-训练稳定复现</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" rel="bookmark" title="Pytorch的data.norm（几种范数(norm)的详细介绍）">Pytorch的data.norm（几种范数(norm)的详细介绍）</a></li><li><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" rel="bookmark" title="Pytorch通过requires_grad固定部分参数进行网络训练">Pytorch通过requires_grad固定部分参数进行网络训练</a></li><li><a href="/2022/08/24/ai/pytorch/torch-matmul-%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D/" rel="bookmark" title="torch.matmul()用法介绍">torch.matmul()用法介绍</a></li><li><a href="/2022/08/24/ai/pytorch/torchvision-datasets-ImageFolder/" rel="bookmark" title="torchvision.datasets.ImageFolder">torchvision.datasets.ImageFolder</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/07/21/ai/cv/OpenCV%E6%95%99%E7%A8%8B/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/25/language/vbs/vbs/" title="vbs">vbs</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E8%93%9D%E6%A1%A5%E6%9D%AF/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/JavaScript/%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%E7%82%B9/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computational-performance/" title="分类于 chapter_computational-performance">chapter_computational-performance</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/hardware/" title="hardware">hardware</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E6%A1%88%E4%BE%8B/2018/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-recurrent-modern/" title="分类于 chapter_recurrent-modern">chapter_recurrent-modern</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_recurrent-modern/beam-search/" title="beam-search">beam-search</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E6%80%BB%E7%BA%BF/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-pretraining/" title="分类于 chapter_natural-language-processing-pretraining">chapter_natural-language-processing-pretraining</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-pretraining/index/" title="index">index</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E8%93%9D%E6%A1%A5%E6%9D%AF/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/jQuery/%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%E7%82%B9/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/" title="分类于 huggingface">huggingface</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/DATASETS%E5%BA%93/" title="分类于 DATASETS库">DATASETS库</a></div><span><a href="/2022/09/21/ai/nlp/huggingface/DATASETS%E5%BA%93/%E5%88%87%E7%89%87/" title="datasets 切片">datasets 切片</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/MyBatisPlus/" title="分类于 MyBatisPlus">MyBatisPlus</a></div><span><a href="/2022/11/12/backend/Mybatisplus/MyBatisPlus/" title="MyBatisPlus">MyBatisPlus</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/07/22/ai/pytorch/pytorch入门/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>