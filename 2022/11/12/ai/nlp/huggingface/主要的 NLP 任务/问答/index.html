<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://huang-junyuan.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://huang-junyuan.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://huang-junyuan.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="è‡ªç„¶è¯­è¨€å¤„ç†"><link rel="canonical" href="https://huang-junyuan.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/"><title>é—®ç­” question answer - ä¸»è¦nlpä»»åŠ¡ - huggingface - nlp - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">é—®ç­” question answer</h1><div class="meta"><span class="item" title="åˆ›å»ºæ—¶é—´ï¼š2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">å‘è¡¨äº</span> <time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="æœ¬æ–‡å­—æ•°"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">æœ¬æ–‡å­—æ•°</span> <span>18k</span> <span class="text">å­—</span> </span><span class="item" title="é˜…è¯»æ—¶é•¿"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">é˜…è¯»æ—¶é•¿</span> <span>16 åˆ†é’Ÿ</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="åˆ‡æ¢å¯¼èˆªæ "><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giciusoyjnj219g0u0x56.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicitspjpbj20zk0m81ky.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclh0m9pdj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giph4lm9i7j20zk0m84qp.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclx29mstj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipeyvx1d4j20zk0m8hdt.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">é¦–é¡µ</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="åˆ†ç±»äº ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/" itemprop="item" rel="index" title="åˆ†ç±»äº nlp"><span itemprop="name">nlp</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/" itemprop="item" rel="index" title="åˆ†ç±»äº huggingface"><span itemprop="name">huggingface</span></a><meta itemprop="position" content="3"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81nlp%E4%BB%BB%E5%8A%A1/" itemprop="item" rel="index" title="åˆ†ç±»äº ä¸»è¦nlpä»»åŠ¡"><span itemprop="name">ä¸»è¦nlpä»»åŠ¡</span></a><meta itemprop="position" content="4"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://huang-junyuan.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="é—®ç­”-question-answering"><a class="anchor" href="#é—®ç­”-question-answering">#</a> é—®ç­” Question answering</h1><p>æ˜¯æ—¶å€™çœ‹é—®ç­”äº†ï¼è¿™é¡¹ä»»åŠ¡æœ‰å¤šç§å½¢å¼ï¼Œä½†æˆ‘ä»¬å°†åœ¨æœ¬èŠ‚ä¸­å…³æ³¨çš„ä¸€é¡¹ç§°ä¸ºæå–çš„é—®ç­” extractive question answeringã€‚é—®é¢˜çš„ç­”æ¡ˆå°±åœ¨ ç»™å®šçš„æ–‡æ¡£ ä¹‹ä¸­ã€‚</p><p>æˆ‘ä»¬å°†ä½¿ç”¨ <span class="exturl" data-url="aHR0cHM6Ly9yYWpwdXJrYXIuZ2l0aHViLmlvL1NRdUFELWV4cGxvcmVyLw==">SQuAD æ•°æ®é›†</span> å¾®è°ƒä¸€ä¸ª BERT æ¨¡å‹ï¼Œå…¶ä¸­åŒ…æ‹¬ç¾¤ä¼—å·¥ä½œè€…å¯¹ä¸€ç»„ç»´åŸºç™¾ç§‘æ–‡ç« æå‡ºçš„é—®é¢˜ã€‚</p><blockquote><p>åƒ BERT è¿™æ ·çš„çº¯ç¼–ç å™¨æ¨¡å‹å¾€å¾€å¾ˆæ“…é•¿æå–è¯¸å¦‚ â€œè°å‘æ˜äº† Transformer æ¶æ„ï¼Ÿâ€ ä¹‹ç±»çš„äº‹å®æ€§é—®é¢˜çš„ç­”æ¡ˆã€‚ä½†åœ¨ç»™å‡ºè¯¸å¦‚ â€œä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿâ€ ä¹‹ç±»çš„å¼€æ”¾å¼é—®é¢˜æ—¶è¡¨ç°ä¸ä½³ã€‚åœ¨è¿™äº›æ›´å…·æŒ‘æˆ˜æ€§çš„æƒ…å†µä¸‹ï¼ŒT5 å’Œ BART ç­‰ç¼–ç å™¨ - è§£ç å™¨æ¨¡å‹é€šå¸¸ä½¿ç”¨ä»¥ä¸ <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9jb3Vyc2UvY2hhcHRlcjcvNQ==">æ–‡æœ¬æ‘˜è¦</span> éå¸¸ç›¸ä¼¼çš„æ–¹å¼åˆæˆä¿¡æ¯ã€‚å¦‚æœä½ å¯¹è¿™ç§ç±»å‹çš„ç”Ÿæˆå¼é—®ç­”æ„Ÿå…´è¶£ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹æˆ‘ä»¬åŸºäº <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9lbGk1">ELI5 æ•°æ®é›†</span> çš„ <span class="exturl" data-url="aHR0cHM6Ly95amVybml0ZS5naXRodWIuaW8vbGZxYS5odG1s">æ¼”ç¤º</span>ã€‚</p></blockquote><h2 id="å‡†å¤‡æ•°æ®"><a class="anchor" href="#å‡†å¤‡æ•°æ®">#</a> å‡†å¤‡æ•°æ®</h2><p>æœ€å¸¸ç”¨ä½œæŠ½å–å¼é—®ç­”çš„å­¦æœ¯åŸºå‡†çš„æ•°æ®é›†æ˜¯ SQuAD, æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„ã€‚è¿˜æœ‰ä¸€ä¸ªæ›´éš¾çš„ <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9zcXVhZF92Mg==">SQuAD v2</span> åŸºå‡†ï¼Œå…¶ä¸­åŒ…æ‹¬æ²¡æœ‰ç­”æ¡ˆçš„é—®é¢˜ã€‚åªè¦ä½ è‡ªå·±çš„æ•°æ®é›†åŒ…å«ä¸Šä¸‹æ–‡åˆ—ã€é—®é¢˜åˆ—å’Œç­”æ¡ˆåˆ—ï¼Œä½ å°±åº”è¯¥èƒ½å¤Ÿè°ƒæ•´ä»¥ä¸‹æ­¥éª¤ã€‚</p><h3 id="squad-æ•°æ®é›†"><a class="anchor" href="#squad-æ•°æ®é›†">#</a> SQuAD æ•°æ®é›†</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>ç„¶åæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹è¿™ä¸ªå¯¹è±¡ä»¥ï¼Œäº†è§£æœ‰å…³ SQuAD æ•°æ®é›†çš„æ›´å¤šä¿¡æ¯:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>raw_datasets</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>DatasetDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">87599</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">10570</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>çœ‹èµ·æ¥æˆ‘ä»¬æ‹¥æœ‰æ‰€éœ€çš„ <code>context</code> <code>ã€question</code> å’Œ <code>answers</code> å­—æ®µï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ‰“å°è®­ç»ƒé›†çš„ç¬¬ä¸€ä¸ªå…ƒç´ :</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Context: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Question: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Answer: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>Context<span class="token punctuation">:</span> <span class="token string">'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'</span></pre></td></tr><tr><td data-num="6"></td><td><pre>Question<span class="token punctuation">:</span> <span class="token string">'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'</span></pre></td></tr><tr><td data-num="7"></td><td><pre>Answer<span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Saint Bernadette Soubirous'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">515</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p><code>context</code> å’Œ <code>question</code> å­—æ®µä½¿ç”¨èµ·æ¥éå¸¸ç®€å•ã€‚ä½†æ˜¯ <code>answers</code> å­—æ®µæœ‰ç‚¹æ£˜æ‰‹ï¼Œå› ä¸ºå®ƒå°†å­—å…¸ä¸ä¸¤ä¸ªéƒ½æ˜¯åˆ—è¡¨çš„å­—æ®µç»„æˆã€‚è¿™æ˜¯åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ squad æŒ‡æ ‡æ‰€æœŸæœ›çš„æ ¼å¼ï¼›å¦‚æœä½ ä½¿ç”¨çš„æ˜¯è‡ªå·±çš„æ•°æ®ï¼Œ <code>åˆ™ä¸å¿…æ‹…å¿ƒå°†ç­”æ¡ˆé‡‡ç”¨ç›¸åŒçš„æ ¼å¼ã€‚text</code> å­—æ®µæ¯”è¾ƒæ˜æ˜¾ï¼Œè€Œ <code>answer_start</code> å­—æ®µåŒ…å«ä¸Šä¸‹æ–‡ä¸­æ¯ä¸ªç­”æ¡ˆçš„èµ·å§‹å­—ç¬¦ç´¢å¼•ã€‚</p><p>è¿™ä¸ªèµ·å§‹å­—ç¬¦ç´¢å¼• <code>answer_start</code> ï¼Œæ˜¯é’ˆå¯¹å­—ç¬¦è€Œä¸æ˜¯ token</p><p>åœ¨è®­ç»ƒæœŸé—´ï¼Œåªæœ‰ä¸€ç§å¯èƒ½çš„ç­”æ¡ˆã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <code>Dataset.filter()</code> æ–¹æ³•:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    num_rows<span class="token punctuation">:</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>ç„¶è€Œï¼Œå¯¹äºè¯„ä¼°ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æœ‰å‡ ä¸ªå¯èƒ½çš„ç­”æ¡ˆï¼Œå®ƒä»¬å¯èƒ½ç›¸åŒæˆ–ä¸åŒ:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Denver Broncos'</span><span class="token punctuation">,</span> <span class="token string">'Denver Broncos'</span><span class="token punctuation">,</span> <span class="token string">'Denver Broncos'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Santa Clara, California'</span><span class="token punctuation">,</span> <span class="token string">"Levi's Stadium"</span><span class="token punctuation">,</span> <span class="token string">"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">403</span><span class="token punctuation">,</span> <span class="token number">355</span><span class="token punctuation">,</span> <span class="token number">355</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>æˆ‘ä»¬ä¸ä¼šæ·±å…¥ç ”ç©¶è¯„ä¼°è„šæœ¬ï¼Œå› ä¸ºå®ƒéƒ½ä¼šè¢«ä¸€ä¸ª Datasets æŒ‡æ ‡åŒ…è£¹èµ·æ¥ï¼Œä½†ç®€çŸ­çš„ç‰ˆæœ¬æ˜¯ä¸€äº›é—®é¢˜æœ‰å‡ ä¸ªå¯èƒ½çš„ç­”æ¡ˆï¼Œè¿™ä¸ªè„šæœ¬ä¼šå°†é¢„æµ‹çš„ç­”æ¡ˆä¸æ‰€æœ‰â€‹â€‹çš„å¯æ¥å—çš„ç­”æ¡ˆå¹¶è·å¾—æœ€é«˜åˆ†ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸‹ç´¢å¼• 2 å¤„çš„æ ·æœ¬ e:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the "golden anniversary" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as "Super Bowl L"), so that the logo could prominently feature the Arabic numerals 50.'</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">'Where did Super Bowl 50 take place?'</span></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç­”æ¡ˆç¡®å®å¯ä»¥æ˜¯æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ä¸‰ç§å¯èƒ½æ€§ä¹‹ä¸€ã€‚</p><h3 id="å¤„ç†è®­ç»ƒæ•°æ®"><a class="anchor" href="#å¤„ç†è®­ç»ƒæ•°æ®">#</a> å¤„ç†è®­ç»ƒæ•°æ®</h3><p>è®©æˆ‘ä»¬ä»é¢„å¤„ç†è®­ç»ƒæ•°æ®å¼€å§‹ã€‚å›°éš¾çš„éƒ¨åˆ†å°†æ˜¯ä¸ºé—®é¢˜çš„ç­”æ¡ˆç”Ÿæˆæ ‡ç­¾ï¼Œè¿™å°†æ˜¯ä¸ä¸Šä¸‹æ–‡ä¸­çš„ç­”æ¡ˆç›¸å¯¹åº”çš„æ ‡è®°çš„å¼€å§‹å’Œç»“æŸä½ç½®ã€‚</p><p>ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸è¦è¶…è¶Šè‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åˆ†è¯å™¨å°†è¾“å…¥ä¸­çš„æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„ ID:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>model_checkpoint <span class="token operator">=</span> <span class="token string">"bert-base-cased"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr></table></figure><p>å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å°†å¯¹ BERT æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ä»»ä½•å…¶ä»–æ¨¡å‹ç±»å‹ï¼Œåªè¦å®ƒå®ç°äº†å¿«é€Ÿæ ‡è®°å™¨å³å¯ã€‚ä½ å¯ä»¥åœ¨ <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby90cmFuc2Zvcm1lcnMvI3N1cHBvcnRlZC1mcmFtZXdvcmtz">this big table</span> ä¸­çœ‹åˆ°æ‰€æœ‰å¿«é€Ÿç‰ˆæœ¬çš„æ¶æ„ï¼Œå¹¶æ£€æŸ¥ä½ æ­£åœ¨ä½¿ç”¨çš„ tokenizer å¯¹è±¡ç¡®å®ç”± ğŸ¤— Tokenizers æ”¯æŒï¼Œä½ å¯ä»¥æŸ¥çœ‹å®ƒçš„ is_fast å±æ€§:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>tokenizer<span class="token punctuation">.</span>is_fast</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token boolean">True</span></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥å°†é—®é¢˜å’Œä¸Šä¸‹æ–‡ä¸€èµ·ä¼ é€’ç»™æˆ‘ä»¬çš„æ ‡è®°å™¨ï¼Œå®ƒä¼šæ­£ç¡®æ’å…¥ç‰¹æ®Šæ ‡è®°ä»¥å½¢æˆå¦‚ä¸‹å¥å­:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>CLS<span class="token punctuation">]</span> question <span class="token punctuation">[</span>SEP<span class="token punctuation">]</span> context <span class="token punctuation">[</span>SEP<span class="token punctuation">]</span></pre></td></tr></table></figure><p>è®©æˆ‘ä»¬ä»”ç»†æ£€æŸ¥ä¸€ä¸‹:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>context <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>question <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, '</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin '</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token string">'Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms '</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred '</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token string">'Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a '</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">'replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette '</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token string">'Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues '</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">'and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'</span></pre></td></tr></table></figure><p>ç„¶åæ ‡ç­¾æ˜¯å¼€å§‹å’Œç»“æŸç­”æ¡ˆçš„ token çš„ç´¢å¼•ï¼Œå¹¶ä¸”æ¨¡å‹çš„ä»»åŠ¡æ˜¯é¢„æµ‹è¾“å…¥ä¸­æ¯ä¸ª token çš„å¼€å§‹å’Œç»“æŸ logit, ç†è®ºæ ‡ç­¾å¦‚ä¸‹:</p><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666617486761.png" alt="1666617486761"></p><p>ä¸Šé¢å›¾ç‰‡ä¸­æ¯ä¸ª token ä¸‹é¢çš„ä¸¤ä¸ªæ•°å­—åº”è¯¥æ˜¯åˆ†åˆ«è¡¨ç¤ºç­”æ¡ˆæ˜¯å¦å¼€å§‹å’Œæ˜¯å¦ç»“æŸ</p><p>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸Šä¸‹æ–‡ä¸ä¼šå¤ªé•¿ï¼Œä½†æ˜¯æ•°æ®é›†ä¸­çš„ä¸€äº›ç¤ºä¾‹çš„ä¸Šä¸‹æ–‡å¾ˆé•¿ï¼Œä¼šè¶…è¿‡æˆ‘ä»¬è®¾ç½®çš„æœ€å¤§é•¿åº¦ (åœ¨è¿™ç§æƒ…å†µä¸‹ä¸º 384)ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ ç¬¬å…­ç«  ä¸­æ‰€çœ‹åˆ°çš„ï¼Œå½“æˆ‘ä»¬æ¢ç´¢ question-answering ç®¡é“çš„å†…éƒ¨ç»“æ„æ—¶ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä»æˆ‘ä»¬çš„æ•°æ®é›†çš„ä¸€ä¸ªæ ·æœ¬ä¸­åˆ›å»ºå‡ ä¸ªè®­ç»ƒç‰¹å¾æ¥å¤„ç†é•¿ä¸Šä¸‹æ–‡ï¼Œå®ƒä»¬ä¹‹é—´æœ‰ä¸€ä¸ªæ»‘åŠ¨çª—å£ã€‚</p><p>è¦ä½¿ç”¨å½“å‰ç¤ºä¾‹æŸ¥çœ‹å…¶å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬å¯ä»¥å°†é•¿åº¦é™åˆ¶ä¸º 100, å¹¶ä½¿ç”¨ 50 ä¸ªæ ‡è®°çš„æ»‘åŠ¨çª—å£ã€‚æé†’ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨:</p><ul><li><code>max_length</code> è®¾ç½®æœ€å¤§é•¿åº¦ (æ­¤å¤„ä¸º 100)</li><li><code>truncation=&quot;only_second&quot;</code> ç”¨äºå½“å¸¦æœ‰ä¸Šä¸‹æ–‡çš„é—®é¢˜å¤ªé•¿æ—¶ï¼Œæˆªæ–­ä¸Šä¸‹æ–‡ t (ä½äºç¬¬äºŒä¸ªä½ç½®)</li><li><code>stride</code> è®¾ç½®ä¸¤ä¸ªè¿ç»­å—ä¹‹é—´çš„é‡å æ ‡è®°æ•° (è¿™é‡Œä¸º 50)</li><li><code>return_overflowing_tokens=True</code> è®©æ ‡è®°å™¨çŸ¥é“æˆ‘ä»¬æƒ³è¦æº¢å‡ºçš„æ ‡è®°</li></ul><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    question<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    context<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>inputs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'overflow_to_sample_mapping'])</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">for</span> ids <span class="token keyword">in</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]'</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]'</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'</span></pre></td></tr></table></figure><p>å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬çš„ç¤ºä¾‹è¢«åˆ†æˆå››ä¸ªè¾“å…¥ï¼Œæ¯ä¸ªè¾“å…¥éƒ½åŒ…å«é—®é¢˜å’Œä¸Šä¸‹æ–‡çš„ä¸€éƒ¨åˆ†ã€‚ è¯·æ³¨æ„ï¼Œé—®é¢˜çš„ç­”æ¡ˆ (â€œBernadette Soubirousâ€) ä»…å‡ºç°åœ¨ç¬¬ä¸‰ä¸ªä¹Ÿæ˜¯æœ€åä¸€ä¸ªè¾“å…¥ä¸­ï¼Œå› æ­¤é€šè¿‡ä»¥è¿™ç§æ–¹å¼å¤„ç†é•¿ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€äº›ç­”æ¡ˆä¸åŒ…å«åœ¨ä¸Šä¸‹æ–‡ä¸­çš„è®­ç»ƒç¤ºä¾‹ã€‚å¯¹äºè¿™äº›ç¤ºä¾‹ï¼Œæ ‡ç­¾å°†æ˜¯ start_position = end_position = 0 (æ‰€ä»¥æˆ‘ä»¬é¢„æµ‹ [CLS] æ ‡è®°)ã€‚æˆ‘ä»¬è¿˜å°†åœ¨ç­”æ¡ˆè¢«æˆªæ–­çš„ä¸å¹¸æƒ…å†µä¸‹è®¾ç½®è¿™äº›æ ‡ç­¾ï¼Œä»¥ä¾¿æˆ‘ä»¬åªæœ‰å®ƒçš„å¼€å§‹ (æˆ–ç»“æŸ)ã€‚å¯¹äºç­”æ¡ˆå®Œå…¨åœ¨ä¸Šä¸‹æ–‡ä¸­çš„ç¤ºä¾‹ï¼Œæ ‡ç­¾å°†æ˜¯ç­”æ¡ˆå¼€å§‹çš„æ ‡è®°çš„ç´¢å¼•å’Œç­”æ¡ˆç»“æŸçš„æ ‡è®°çš„ç´¢å¼•ã€‚</p><p>æ•°æ®é›†ä¸ºæˆ‘ä»¬æä¾›äº†ä¸Šä¸‹æ–‡ä¸­ç­”æ¡ˆçš„å¼€å§‹å­—ç¬¦ï¼Œé€šè¿‡æ·»åŠ ç­”æ¡ˆçš„é•¿åº¦ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°ä¸Šä¸‹æ–‡ä¸­çš„ç»“æŸå­—ç¬¦ã€‚è¦å°†å®ƒä»¬æ˜ å°„åˆ°ä»¤ç‰Œç´¢å¼•ï¼Œæˆ‘ä»¬å°†éœ€è¦ä½¿ç”¨æˆ‘ä»¬åœ¨ <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9jb3Vyc2UvY2hhcHRlcjYvNA==">ç¬¬å…­ç« </span> ä¸­ç ”ç©¶çš„åç§»æ˜ å°„ã€‚æˆ‘ä»¬å¯ä»¥è®©æ ‡è®°å™¨é€šè¿‡ä¼ é€’ <code>return_offsets_mapping=True</code> æ¥è¿”å›è¿™äº›å€¼:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    question<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    context<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>inputs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'offset_mapping'</span><span class="token punctuation">,</span> <span class="token string">'overflow_to_sample_mapping'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666696075334.png" alt="1666696075334"></p><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666696200826.png" alt="1666696200826"></p><p>ä»ä¸Šé¢çš„æˆªå›¾ä¸­çœ‹å‡º <code>offset_mapping</code> å¾—åˆ°çš„æ˜¯å°† token æ— ç©ºæ ¼çš„è¿æ¥èµ·æ¥ä¹‹åçš„ token çš„ç´¢å¼•ã€‚</p><p>å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬å–å›äº†é€šå¸¸çš„è¾“å…¥ IDã€ä»¤ç‰Œç±»å‹ ID å’Œæ³¨æ„æ©ç ï¼Œä»¥åŠæˆ‘ä»¬éœ€è¦çš„åç§»æ˜ å°„å’Œä¸€ä¸ªé¢å¤–çš„é”®ï¼Œ <code>overflow_to_sample_mapping</code> ã€‚å½“æˆ‘ä»¬åŒæ—¶æ ‡è®°å¤šä¸ªæ–‡æœ¬æ—¶ï¼Œç›¸åº”çš„å€¼å°†å¯¹æˆ‘ä»¬æœ‰ç”¨ (æˆ‘ä»¬åº”è¯¥è¿™æ ·åšä»¥å—ç›Šäºæˆ‘ä»¬çš„æ ‡è®°å™¨ç”± Rust æ”¯æŒçš„äº‹å®)ã€‚ç”±äºä¸€ä¸ªæ ·æœ¬å¯ä»¥æä¾›å¤šä¸ªç‰¹å¾ï¼Œå› æ­¤å®ƒå°†æ¯ä¸ªç‰¹å¾æ˜ å°„åˆ°å…¶æ¥æºçš„ç¤ºä¾‹ã€‚å› ä¸ºè¿™é‡Œæˆ‘ä»¬åªæ ‡è®°äº†ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ª 0 çš„åˆ—è¡¨:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æ ‡è®°æ›´å¤šç¤ºä¾‹ï¼Œè¿™å°†å˜å¾—æ›´åŠ æœ‰ç”¨:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"The 4 examples gave </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> features."</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Here is where each comes from: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>inputs<span class="token punctuation">[</span><span class="token string">'overflow_to_sample_mapping'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">."</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'The 4 examples gave 19 features.'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].'</span></pre></td></tr></table></figure><p>æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œå‰ä¸‰ä¸ªç¤ºä¾‹ (åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼• 2ã€3 å’Œ 4 å¤„) æ¯ä¸ªéƒ½ç»™å‡ºäº†å››ä¸ªç‰¹å¾ï¼Œæœ€åä¸€ä¸ªç¤ºä¾‹ (åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼• 5 å¤„) ç»™å‡ºäº† 7 ä¸ªç‰¹å¾ã€‚</p><p>æ­¤ä¿¡æ¯å°†æœ‰åŠ©äºå°†æˆ‘ä»¬è·å¾—çš„æ¯ä¸ªç‰¹å¾æ˜ å°„åˆ°å…¶ç›¸åº”çš„æ ‡ç­¾ã€‚å¦‚å‰æ‰€è¿°ï¼Œè¿™äº›æ ‡ç­¾æ˜¯:</p><ul><li><code>(0, 0)</code> å¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡çš„ç›¸åº”èŒƒå›´å†…</li><li><code>(start_position, end_position)</code> å¦‚æœç­”æ¡ˆåœ¨ä¸Šä¸‹æ–‡çš„ç›¸åº”èŒƒå›´å†…ï¼Œåˆ™ start_position æ˜¯ç­”æ¡ˆå¼€å¤´çš„æ ‡è®°ç´¢å¼• (åœ¨è¾“å…¥ ID ä¸­), å¹¶ä¸” end_position æ˜¯ç­”æ¡ˆç»“æŸçš„æ ‡è®°çš„ç´¢å¼• (åœ¨è¾“å…¥ ID ä¸­)ã€‚</li></ul><p>ä¸Šé¢çš„è¾“å…¥ ID æ˜¯ä»€ä¹ˆ</p><p>ä¸ºäº†ç¡®å®šæ˜¯å“ªç§æƒ…å†µä»¥åŠæ ‡è®°çš„ä½ç½®ï¼Œä»¥åŠ (å¦‚æœç›¸å…³çš„è¯) æ ‡è®°çš„ä½ç½®ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨è¾“å…¥ ID ä¸­æ‰¾åˆ°å¼€å§‹å’Œç»“æŸä¸Šä¸‹æ–‡çš„ç´¢å¼•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ ‡è®°ç±»å‹ ID æ¥æ‰§è¡Œæ­¤æ“ä½œï¼Œä½†ç”±äºè¿™äº› ID ä¸ä¸€å®šå­˜åœ¨äºæ‰€æœ‰æ¨¡å‹ä¸­ (ä¾‹å¦‚ï¼ŒDistilBERT ä¸éœ€è¦å®ƒä»¬), æˆ‘ä»¬å°†æ”¹ä¸ºä½¿ç”¨æˆ‘ä»¬çš„æ ‡è®°å™¨è¿”å›çš„ BatchEncoding çš„ sequence_ids () æ–¹æ³•ã€‚</p><p>ä¸€æ—¦æˆ‘ä»¬æœ‰äº†è¿™äº›æ ‡è®°ç´¢å¼•ï¼Œæˆ‘ä»¬å°±ä¼šæŸ¥çœ‹ç›¸åº”çš„åç§»é‡ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ•´æ•°çš„å…ƒç»„ï¼Œè¡¨ç¤ºåŸå§‹ä¸Šä¸‹æ–‡ä¸­çš„å­—ç¬¦èŒƒå›´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æµ‹æ­¤ç‰¹å¾ä¸­çš„ä¸Šä¸‹æ–‡å—æ˜¯åœ¨ç­”æ¡ˆä¹‹åå¼€å§‹è¿˜æ˜¯åœ¨ç­”æ¡ˆå¼€å§‹ä¹‹å‰ç»“æŸ (åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ ‡ç­¾æ˜¯ (0, 0))ã€‚å¦‚æœä¸æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬å¾ªç¯æŸ¥æ‰¾ç­”æ¡ˆçš„ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ ‡è®°:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>answers <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="29"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>        idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>start_positions<span class="token punctuation">,</span> end_positions</pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="2"></td><td><pre> <span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>è®©æˆ‘ä»¬çœ‹ä¸€äº›ç»“æœæ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•æ˜¯å¦æ­£ç¡®ã€‚å¯¹äºæˆ‘ä»¬å‘ç°çš„ç¬¬ä¸€ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬å°† (83, 85) ä½œä¸ºæ ‡ç­¾ï¼Œè®©æˆ‘ä»¬å°†ç†è®ºç­”æ¡ˆä¸ä» 83 åˆ° 85 (åŒ…æ‹¬) çš„æ ‡è®°è§£ç èŒƒå›´è¿›è¡Œæ¯”è¾ƒ:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="2"></td><td><pre>sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>start <span class="token operator">=</span> start_positions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre>end <span class="token operator">=</span> end_positions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>labeled_answer <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span>start <span class="token punctuation">:</span> end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Theoretical answer: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>answer<span class="token punctuation">&#125;</span></span><span class="token string">, labels give: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>labeled_answer<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'Theoretical answer: the Main Building, labels give: the Main Building'</span></pre></td></tr></table></figure><p>æ‰€ä»¥è¿™æ˜¯ä¸€åœºæ¯”èµ›ï¼ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥ç´¢å¼• 4, æˆ‘ä»¬å°†æ ‡ç­¾è®¾ç½®ä¸º (0, 0), è¿™æ„å‘³ç€ç­”æ¡ˆä¸åœ¨è¯¥åŠŸèƒ½çš„ä¸Šä¸‹æ–‡å—ä¸­</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx <span class="token operator">=</span> <span class="token number">4</span></pre></td></tr><tr><td data-num="2"></td><td><pre>sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>decoded_example <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Theoretical answer: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>answer<span class="token punctuation">&#125;</span></span><span class="token string">, decoded example: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>decoded_example<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]'</span></pre></td></tr></table></figure><p>äº‹å®ä¸Šï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸‹æ–‡ä¸­çœ‹ä¸åˆ°ç­”æ¡ˆã€‚</p><p>ç°åœ¨æˆ‘ä»¬å·²ç»é€æ­¥äº†è§£äº†å¦‚ä½•é¢„å¤„ç†æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†ç»„åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å°†åº”ç”¨äºæ•´ä¸ªè®­ç»ƒæ•°æ®é›†ã€‚æˆ‘ä»¬ä¼šå°†æ¯ä¸ªç‰¹å¾å¡«å……åˆ°æˆ‘ä»¬è®¾ç½®çš„æœ€å¤§é•¿åº¦ï¼Œå› ä¸ºå¤§å¤šæ•°ä¸Šä¸‹æ–‡ä¼šå¾ˆé•¿ (å¹¶ä¸”ç›¸åº”çš„æ ·æœ¬å°†è¢«åˆ†æˆå‡ ä¸ªç‰¹å¾), æ‰€ä»¥åœ¨è¿™é‡Œåº”ç”¨åŠ¨æ€å¡«å……æ²¡æœ‰çœŸæ­£çš„å¥½å¤„:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>max_length <span class="token operator">=</span> <span class="token number">384</span></pre></td></tr><tr><td data-num="2"></td><td><pre>stride <span class="token operator">=</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_training_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="36"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="37"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="39"></td><td><pre></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="42"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>            <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="46"></td><td><pre>            idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="47"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="48"></td><td><pre>                idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="49"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre>            idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="52"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="53"></td><td><pre>                idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="54"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="55"></td><td><pre></pre></td></tr><tr><td data-num="56"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions</pre></td></tr><tr><td data-num="57"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions</pre></td></tr><tr><td data-num="58"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr></table></figure><p>è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªå¸¸æ•°æ¥ç¡®å®šä½¿ç”¨çš„æœ€å¤§é•¿åº¦ä»¥åŠæ»‘åŠ¨çª—å£çš„é•¿åº¦ï¼Œå¹¶ä¸”æˆ‘ä»¬åœ¨æ ‡è®°åŒ–ä¹‹å‰æ·»åŠ äº†ä¸€ç‚¹æ¸…ç†: SQuAD æ•°æ®é›†ä¸­çš„ä¸€äº›é—®é¢˜åœ¨å¼€å¤´æœ‰é¢å¤–çš„ç©ºæ ¼ï¼Œå¹¶ä¸”ä¸æ·»åŠ ä»»ä½•å†…å®¹çš„ç»“å°¾ (å¦‚æœä½ ä½¿ç”¨åƒ RoBERTa è¿™æ ·çš„æ¨¡å‹ï¼Œåˆ™åœ¨æ ‡è®°åŒ–æ—¶ä¼šå ç”¨ç©ºé—´), å› æ­¤æˆ‘ä»¬åˆ é™¤äº†é‚£äº›é¢å¤–çš„ç©ºæ ¼ã€‚</p><p>ä¸ºäº†å°†æ­¤å‡½æ•°åº”ç”¨äºæ•´ä¸ªè®­ç»ƒé›†ï¼Œæˆ‘ä»¬ä½¿ç”¨ Dataset.map () æ–¹æ³•ä¸ batched=True æ ‡å¿—ã€‚è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨æ›´æ”¹æ•°æ®é›†çš„é•¿åº¦ (å› ä¸ºä¸€ä¸ªç¤ºä¾‹å¯ä»¥æä¾›å¤šä¸ªè®­ç»ƒç‰¹å¾):</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    preprocess_training_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token builtin">len</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">(</span><span class="token number">87599</span><span class="token punctuation">,</span> <span class="token number">88729</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œé¢„å¤„ç†å¢åŠ äº†å¤§çº¦ 1,000 ä¸ªç‰¹å¾ã€‚æˆ‘ä»¬çš„è®­ç»ƒé›†ç°åœ¨å¯ä»¥ä½¿ç”¨äº† â€” è®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶éªŒè¯é›†çš„é¢„å¤„ç†ï¼</p><p>åœ¨ map çš„æ—¶å€™ä½¿ç”¨ <code>batched=True</code> ï¼Œé‚£ä¹ˆä¼ å…¥å‡½æ•°ä¸­çš„ example æ˜¯ä¸æ˜¯å°±æ˜¯å¥½å‡ æ¡æ•°æ®ï¼Œæ€ä¹ˆéªŒè¯å‘¢ï¼Ÿ<br>æ˜¯çš„ï¼Œç›´æ¥åœ¨å‡½æ•°ä¸­æ‰“å°å³å¯ã€‚</p><h3 id="å¤„ç†éªŒè¯æ•°æ®"><a class="anchor" href="#å¤„ç†éªŒè¯æ•°æ®">#</a> å¤„ç†éªŒè¯æ•°æ®</h3><p>é¢„å¤„ç†éªŒè¯æ•°æ®ä¼šç¨å¾®å®¹æ˜“ä¸€äº›ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦ç”Ÿæˆæ ‡ç­¾ (é™¤éæˆ‘ä»¬æƒ³è®¡ç®—éªŒè¯æŸå¤±ï¼Œä½†è¿™ä¸ªæ•°å­—å¹¶ä¸èƒ½çœŸæ­£å¸®åŠ©æˆ‘ä»¬ç†è§£æ¨¡å‹æœ‰å¤šå¥½)ã€‚çœŸæ­£çš„ä¹è¶£æ˜¯å°†æ¨¡å‹çš„é¢„æµ‹è§£é‡Šä¸ºåŸå§‹ä¸Šä¸‹æ–‡çš„è·¨åº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦å­˜å‚¨åç§»æ˜ å°„å’ŒæŸç§æ–¹å¼æ¥å°†æ¯ä¸ªåˆ›å»ºçš„ç‰¹å¾ä¸å®ƒæ¥è‡ªçš„åŸå§‹ç¤ºä¾‹ç›¸åŒ¹é…ã€‚ç”±äºåŸå§‹æ•°æ®é›†ä¸­æœ‰ä¸€ä¸ª ID åˆ—ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¯¥ IDã€‚</p><p>æˆ‘ä»¬å°†åœ¨è¿™é‡Œæ·»åŠ çš„å”¯ä¸€å†…å®¹æ˜¯å¯¹åç§»æ˜ å°„çš„ä¸€ç‚¹ç‚¹æ¸…ç†ã€‚å®ƒä»¬å°†åŒ…å«é—®é¢˜å’Œä¸Šä¸‹æ–‡çš„åç§»é‡ï¼Œä½†æ˜¯ä¸€æ—¦æˆ‘ä»¬è¿›å…¥åå¤„ç†é˜¶æ®µï¼Œæˆ‘ä»¬å°†æ— æ³•çŸ¥é“è¾“å…¥ ID çš„å“ªä¸€éƒ¨åˆ†å¯¹åº”äºä¸Šä¸‹æ–‡ä»¥åŠå“ªä¸€éƒ¨åˆ†æ˜¯é—®é¢˜ (æˆ‘ä»¬ä½¿ç”¨çš„ sequence_ids () æ–¹æ³•ä»…å¯ç”¨äºæ ‡è®°å™¨çš„è¾“å‡º)ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä¸é—®é¢˜å¯¹åº”çš„åç§»é‡è®¾ç½®ä¸º None:</p><h2 id="ä½¿ç”¨-trainer-api-å¾®è°ƒæ¨¡å‹"><a class="anchor" href="#ä½¿ç”¨-trainer-api-å¾®è°ƒæ¨¡å‹">#</a> ä½¿ç”¨ Trainer API å¾®è°ƒæ¨¡å‹</h2><h2 id="ä½¿ç”¨-trainer-çš„å®Œæ•´ä»£ç "><a class="anchor" href="#ä½¿ç”¨-trainer-çš„å®Œæ•´ä»£ç ">#</a> ä½¿ç”¨ Trainer çš„å®Œæ•´ä»£ç </h2><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># å¤„ç†è®­ç»ƒæ•°æ®</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>model_checkpoint <span class="token operator">=</span> <span class="token string">"bert-base-cased"</span></pre></td></tr><tr><td data-num="12"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>max_length <span class="token operator">=</span> <span class="token number">384</span></pre></td></tr><tr><td data-num="15"></td><td><pre>stride <span class="token operator">=</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_training_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>        <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="47"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="48"></td><td><pre>        context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="49"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="50"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre>        <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="54"></td><td><pre>        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="55"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="58"></td><td><pre>            <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="59"></td><td><pre>            idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="60"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="61"></td><td><pre>                idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="62"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre>            idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="65"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="66"></td><td><pre>                idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="67"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="68"></td><td><pre></pre></td></tr><tr><td data-num="69"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions</pre></td></tr><tr><td data-num="70"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions</pre></td></tr><tr><td data-num="71"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr><tr><td data-num="72"></td><td><pre></pre></td></tr><tr><td data-num="73"></td><td><pre></pre></td></tr><tr><td data-num="74"></td><td><pre>train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="75"></td><td><pre>    preprocess_training_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="76"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="77"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="78"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="79"></td><td><pre></pre></td></tr><tr><td data-num="80"></td><td><pre></pre></td></tr><tr><td data-num="81"></td><td><pre><span class="token comment"># å¤„ç†éªŒè¯æ•°æ®</span></pre></td></tr><tr><td data-num="82"></td><td><pre></pre></td></tr><tr><td data-num="83"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_validation_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="84"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="85"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="86"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="87"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="88"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="90"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="91"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="92"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="93"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="94"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="95"></td><td><pre></pre></td></tr><tr><td data-num="96"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="97"></td><td><pre>    example_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="98"></td><td><pre></pre></td></tr><tr><td data-num="99"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="100"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="101"></td><td><pre>        example_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="102"></td><td><pre></pre></td></tr><tr><td data-num="103"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="104"></td><td><pre>        offset <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="105"></td><td><pre>        inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="106"></td><td><pre>            o <span class="token keyword">if</span> sequence_ids<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token boolean">None</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> o <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="107"></td><td><pre>        <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="108"></td><td><pre></pre></td></tr><tr><td data-num="109"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"example_id"</span><span class="token punctuation">]</span> <span class="token operator">=</span> example_ids</pre></td></tr><tr><td data-num="110"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr><tr><td data-num="111"></td><td><pre></pre></td></tr><tr><td data-num="112"></td><td><pre>validation_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="113"></td><td><pre>    preprocess_validation_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="114"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="115"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="116"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="117"></td><td><pre></pre></td></tr><tr><td data-num="118"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric</pre></td></tr><tr><td data-num="119"></td><td><pre></pre></td></tr><tr><td data-num="120"></td><td><pre>metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="121"></td><td><pre></pre></td></tr><tr><td data-num="122"></td><td><pre><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm</pre></td></tr><tr><td data-num="123"></td><td><pre></pre></td></tr><tr><td data-num="124"></td><td><pre></pre></td></tr><tr><td data-num="125"></td><td><pre><span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> end_logits<span class="token punctuation">,</span> features<span class="token punctuation">,</span> examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="126"></td><td><pre>    example_to_features <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="127"></td><td><pre>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> feature <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="128"></td><td><pre>        example_to_features<span class="token punctuation">[</span>feature<span class="token punctuation">[</span><span class="token string">"example_id"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="129"></td><td><pre></pre></td></tr><tr><td data-num="130"></td><td><pre>    predicted_answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="131"></td><td><pre>    <span class="token keyword">for</span> example <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="132"></td><td><pre>        example_id <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="133"></td><td><pre>        context <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="134"></td><td><pre>        answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="135"></td><td><pre></pre></td></tr><tr><td data-num="136"></td><td><pre>        <span class="token comment"># Loop through all features associated with that example</span></pre></td></tr><tr><td data-num="137"></td><td><pre>        <span class="token keyword">for</span> feature_index <span class="token keyword">in</span> example_to_features<span class="token punctuation">[</span>example_id<span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="138"></td><td><pre>            start_logit <span class="token operator">=</span> start_logits<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="139"></td><td><pre>            end_logit <span class="token operator">=</span> end_logits<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="140"></td><td><pre>            offsets <span class="token operator">=</span> features<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="141"></td><td><pre></pre></td></tr><tr><td data-num="142"></td><td><pre>            start_indexes <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>start_logit<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span>n_best <span class="token operator">-</span> <span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="143"></td><td><pre>            end_indexes <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>end_logit<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span>n_best <span class="token operator">-</span> <span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="144"></td><td><pre>            <span class="token keyword">for</span> start_index <span class="token keyword">in</span> start_indexes<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="145"></td><td><pre>                <span class="token keyword">for</span> end_index <span class="token keyword">in</span> end_indexes<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="146"></td><td><pre>                    <span class="token comment"># Skip answers that are not fully in the context</span></pre></td></tr><tr><td data-num="147"></td><td><pre>                    <span class="token keyword">if</span> offsets<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> offsets<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="148"></td><td><pre>                        <span class="token keyword">continue</span></pre></td></tr><tr><td data-num="149"></td><td><pre>                    <span class="token comment"># Skip answers with a length that is either &lt; 0 or > max_answer_length</span></pre></td></tr><tr><td data-num="150"></td><td><pre>                    <span class="token keyword">if</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="151"></td><td><pre>                        end_index <span class="token operator">&lt;</span> start_index</pre></td></tr><tr><td data-num="152"></td><td><pre>                        <span class="token keyword">or</span> end_index <span class="token operator">-</span> start_index <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">></span> max_answer_length</pre></td></tr><tr><td data-num="153"></td><td><pre>                    <span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="154"></td><td><pre>                        <span class="token keyword">continue</span></pre></td></tr><tr><td data-num="155"></td><td><pre></pre></td></tr><tr><td data-num="156"></td><td><pre>                    answer <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="157"></td><td><pre>                        <span class="token string">"text"</span><span class="token punctuation">:</span> context<span class="token punctuation">[</span>offsets<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token punctuation">:</span> offsets<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="158"></td><td><pre>                        <span class="token string">"logit_score"</span><span class="token punctuation">:</span> start_logit<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span> <span class="token operator">+</span> end_logit<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="159"></td><td><pre>                    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="160"></td><td><pre>                    answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>answer<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="161"></td><td><pre></pre></td></tr><tr><td data-num="162"></td><td><pre>        <span class="token comment"># Select the answer with the best score</span></pre></td></tr><tr><td data-num="163"></td><td><pre>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answers<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="164"></td><td><pre>            best_answer <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>answers<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">"logit_score"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="165"></td><td><pre>            predicted_answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="166"></td><td><pre>                <span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> example_id<span class="token punctuation">,</span> <span class="token string">"prediction_text"</span><span class="token punctuation">:</span> best_answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="167"></td><td><pre>            <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="168"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="169"></td><td><pre>            predicted_answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> example_id<span class="token punctuation">,</span> <span class="token string">"prediction_text"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="170"></td><td><pre></pre></td></tr><tr><td data-num="171"></td><td><pre>    theoretical_answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> ex<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"answers"</span><span class="token punctuation">:</span> ex<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span> <span class="token keyword">for</span> ex <span class="token keyword">in</span> examples<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="172"></td><td><pre>    <span class="token keyword">return</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predicted_answers<span class="token punctuation">,</span> references<span class="token operator">=</span>theoretical_answers<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="173"></td><td><pre></pre></td></tr><tr><td data-num="174"></td><td><pre>model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="175"></td><td><pre></pre></td></tr><tr><td data-num="176"></td><td><pre></pre></td></tr><tr><td data-num="177"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments</pre></td></tr><tr><td data-num="178"></td><td><pre></pre></td></tr><tr><td data-num="179"></td><td><pre>args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="180"></td><td><pre>    <span class="token string">"bert-finetuned-squad"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="181"></td><td><pre>    evaluation_strategy<span class="token operator">=</span><span class="token string">"no"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="182"></td><td><pre>    save_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="183"></td><td><pre>    learning_rate<span class="token operator">=</span><span class="token number">2e-5</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="184"></td><td><pre>    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="185"></td><td><pre>    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="186"></td><td><pre>    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="187"></td><td><pre>    push_to_hub<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="188"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="189"></td><td><pre></pre></td></tr><tr><td data-num="190"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer</pre></td></tr><tr><td data-num="191"></td><td><pre></pre></td></tr><tr><td data-num="192"></td><td><pre>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="193"></td><td><pre>    model<span class="token operator">=</span>model<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="194"></td><td><pre>    args<span class="token operator">=</span>args<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="195"></td><td><pre>    train_dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="196"></td><td><pre>    eval_dataset<span class="token operator">=</span>validation_dataset<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="197"></td><td><pre>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="198"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="199"></td><td><pre>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><div class="tags"><a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"><i class="ic i-tag"></i> è‡ªç„¶è¯­è¨€å¤„ç†</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">æ›´æ–°äº</span> <time title="ä¿®æ”¹æ—¶é—´ï¼š2022-11-12 13:39:58" itemprop="dateModified" datetime="2022-11-12T13:39:58+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> èµèµ</button><p>è¯·æˆ‘å–[èŒ¶]~(ï¿£â–½ï¿£)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan å¾®ä¿¡æ”¯ä»˜"><p>å¾®ä¿¡æ”¯ä»˜</p></div><div><img data-src="/images/alipay.png" alt="yuan æ”¯ä»˜å®"><p>æ”¯ä»˜å®</p></div><div><img data-src="/images/paypal.png" alt="yuan è´å®"><p>è´å®</p></div></div></div><div id="copyright"><ul><li class="author"><strong>æœ¬æ–‡ä½œè€…ï¼š </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>æœ¬æ–‡é“¾æ¥ï¼š</strong> <a href="https://huang-junyuan.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/" title="é—®ç­” question answer">https://huang-junyuan.github.io/2022/11/12/ai/nlp/huggingface/ä¸»è¦çš„ NLP ä»»åŠ¡/é—®ç­”/</a></li><li class="license"><strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬ç«™æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclh0m9pdj20zk0m8hdt.jpg" title="å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹-å¤„ç†æ•°æ®"><span class="type">ä¸Šä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹</span><h3>å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹-å¤„ç†æ•°æ®</h3></a></div><div class="item right"><a href="/2022/11/12/ai/nlp/huggingface/%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/note/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipey84bjtj20zk0m8hdt.jpg" title="NLPå’Œtransformerå¤§ç±»æ¦‚è¿°"><span class="type">ä¸‹ä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> huggingface</span><h3>NLPå’Œtransformerå¤§ç±»æ¦‚è¿°</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="æ–‡ç« ç›®å½•"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E7%AD%94-question-answering"><span class="toc-number">1.</span> <span class="toc-text">é—®ç­” Question answering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.</span> <span class="toc-text">å‡†å¤‡æ•°æ®</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#squad-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.1.</span> <span class="toc-text">SQuAD æ•°æ®é›†</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.2.</span> <span class="toc-text">å¤„ç†è®­ç»ƒæ•°æ®</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E9%AA%8C%E8%AF%81%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.3.</span> <span class="toc-text">å¤„ç†éªŒè¯æ•°æ®</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-trainer-api-%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">ä½¿ç”¨ Trainer API å¾®è°ƒæ¨¡å‹</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-trainer-%E7%9A%84%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">1.3.</span> <span class="toc-text">ä½¿ç”¨ Trainer çš„å®Œæ•´ä»£ç </span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="ç³»åˆ—æ–‡ç« "><ul><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" rel="bookmark" title="å¾®è°ƒä¸€ä¸ªæ©ç è¯­è¨€æ¨¡å‹">å¾®è°ƒä¸€ä¸ªæ©ç è¯­è¨€æ¨¡å‹</a></li><li class="active"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/" rel="bookmark" title="é—®ç­” question answer">é—®ç­” question answer</a></li><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/" rel="bookmark" title="æ–‡æœ¬æ‘˜è¦ summarize">æ–‡æœ¬æ‘˜è¦ summarize</a></li></ul></div><div class="overview panel" data-title="ç«™ç‚¹æ¦‚è§ˆ"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">206</span> <span class="name">æ–‡ç« </span></a></div><div class="item categories"><a href="/categories/"><span class="count">46</span> <span class="name">åˆ†ç±»</span></a></div><div class="item tags"><a href="/tags/"><span class="count">39</span> <span class="name">æ ‡ç­¾</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>é¦–é¡µ</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>å…³äº</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>æ–‡ç« </a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>å½’æ¡£</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>åˆ†ç±»</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>æ ‡ç­¾</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" rel="prev" title="ä¸Šä¸€ç¯‡"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/11/12/ai/nlp/huggingface/%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/note/" rel="next" title="ä¸‹ä¸€ç¯‡"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>éšæœºæ–‡ç« </h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="åˆ†ç±»äº pytorch">pytorch</a></div><span><a href="/2022/07/25/ai/pytorch/argmax-torch/" title="argmax-torch">argmax-torch</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="åˆ†ç±»äº åç«¯">åç«¯</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/spring/" title="åˆ†ç±»äº spring">spring</a></div><span><a href="/2022/11/12/backend/Spring/spring_day03/Spring_day03/" title="Spring_day03">Spring_day03</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tools/" title="åˆ†ç±»äº tools">tools</a> <i class="ic i-angle-right"></i> <a href="/categories/tools/%E7%88%AC%E8%99%AB/" title="åˆ†ç±»äº çˆ¬è™«">çˆ¬è™«</a></div><span><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy-Item-%E5%8A%A0%E8%BD%BD%E5%99%A8/" title="scrapy-Item-åŠ è½½å™¨">scrapy-Item-åŠ è½½å™¨</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" title="åˆ†ç±»äº ç¼–ç¨‹è¯­è¨€">ç¼–ç¨‹è¯­è¨€</a></div><span><a href="/2022/07/22/language/C++/C-%E6%95%99%E7%A8%8B/" title="C++æ•™ç¨‹">C++æ•™ç¨‹</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/11/06/ai/pytorch/note/" title="æœªå‘½å">æœªå‘½å</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/25/language/vbs/vbs/" title="vbs">vbs</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/10/31/computer-science/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E6%A1%88%E4%BE%8B/2016/" title="æœªå‘½å">æœªå‘½å</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="åˆ†ç±»äº å‰ç«¯">å‰ç«¯</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="åˆ†ç±»äº vue">vue</a></div><span><a href="/2022/08/05/frontend/vue/vue%E8%B7%AF%E7%94%B1/" title="vueè·¯ç”±">vueè·¯ç”±</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/11/13/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD13-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="æœªå‘½å">æœªå‘½å</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="åˆ†ç±»äº cv">cv</a></div><span><a href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/" title="ncnnå’Œopencvåœ¨vs2022ä¸Šåˆ›å»ºå·¥ç¨‹æ¨ç†ç¤ºä¾‹">ncnnå’Œopencvåœ¨vs2022ä¸Šåˆ›å»ºå·¥ç¨‹æ¨ç†ç¤ºä¾‹</a></span></li></ul></div><div><h2>æœ€æ–°è¯„è®º</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 â€“ <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="ç«™ç‚¹æ€»å­—æ•°">1.5m å­—</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">22:19</span></div><div class="powered-by">åŸºäº <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/11/12/ai/nlp/huggingface/ä¸»è¦çš„ NLP ä»»åŠ¡/é—®ç­”/",favicon:{show:"ï¼ˆâ—Â´3ï½€â—ï¼‰ã‚„ã‚Œã‚„ã‚Œã ãœ",hide:"(Â´Ğ”ï½€)å¤§å¤‰ã ï¼"},search:{placeholder:"æ–‡ç« æœç´¢",empty:"å…³äº ã€Œ ${query} ã€ï¼Œä»€ä¹ˆä¹Ÿæ²¡æœåˆ°",stats:"${time} ms å†…æ‰¾åˆ° ${hits} æ¡ç»“æœ"},valine:!0,fancybox:!0,copyright:'å¤åˆ¶æˆåŠŸï¼Œè½¬è½½è¯·éµå®ˆ <i class="ic i-creative-commons"></i>BY-NC-SA åè®®ã€‚',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>