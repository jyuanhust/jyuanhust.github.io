<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="自然语言处理"><link rel="canonical" href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/"><title>问答 question answer - 主要nlp任务 - huggingface - nlp - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">问答 question answer</h1><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>18k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>16 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(46).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(23).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(78).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(55).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(93).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(41).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/" itemprop="item" rel="index" title="分类于 nlp"><span itemprop="name">nlp</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/" itemprop="item" rel="index" title="分类于 huggingface"><span itemprop="name">huggingface</span></a><meta itemprop="position" content="3"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81nlp%E4%BB%BB%E5%8A%A1/" itemprop="item" rel="index" title="分类于 主要nlp任务"><span itemprop="name">主要nlp任务</span></a><meta itemprop="position" content="4"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="问答-question-answering"><a class="anchor" href="#问答-question-answering">#</a> 问答 Question answering</h1><p>是时候看问答了！这项任务有多种形式，但我们将在本节中关注的一项称为提取的问答 extractive question answering。问题的答案就在 给定的文档 之中。</p><p>我们将使用 <span class="exturl" data-url="aHR0cHM6Ly9yYWpwdXJrYXIuZ2l0aHViLmlvL1NRdUFELWV4cGxvcmVyLw==">SQuAD 数据集</span> 微调一个 BERT 模型，其中包括群众工作者对一组维基百科文章提出的问题。</p><blockquote><p>像 BERT 这样的纯编码器模型往往很擅长提取诸如 “谁发明了 Transformer 架构？” 之类的事实性问题的答案。但在给出诸如 “为什么天空是蓝色的？” 之类的开放式问题时表现不佳。在这些更具挑战性的情况下，T5 和 BART 等编码器 - 解码器模型通常使用以与 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9jb3Vyc2UvY2hhcHRlcjcvNQ==">文本摘要</span> 非常相似的方式合成信息。如果你对这种类型的生成式问答感兴趣，我们建议您查看我们基于 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9lbGk1">ELI5 数据集</span> 的 <span class="exturl" data-url="aHR0cHM6Ly95amVybml0ZS5naXRodWIuaW8vbGZxYS5odG1s">演示</span>。</p></blockquote><h2 id="准备数据"><a class="anchor" href="#准备数据">#</a> 准备数据</h2><p>最常用作抽取式问答的学术基准的数据集是 SQuAD, 所以这就是我们将在这里使用的。还有一个更难的 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9zcXVhZF92Mg==">SQuAD v2</span> 基准，其中包括没有答案的问题。只要你自己的数据集包含上下文列、问题列和答案列，你就应该能够调整以下步骤。</p><h3 id="squad-数据集"><a class="anchor" href="#squad-数据集">#</a> SQuAD 数据集</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>然后我们可以查看这个对象以，了解有关 SQuAD 数据集的更多信息:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>raw_datasets</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>DatasetDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">87599</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">10570</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>看起来我们拥有所需的 <code>context</code> <code>、question</code> 和 <code>answers</code> 字段，所以让我们打印训练集的第一个元素:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Context: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Question: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Answer: "</span><span class="token punctuation">,</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>Context<span class="token punctuation">:</span> <span class="token string">'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'</span></pre></td></tr><tr><td data-num="6"></td><td><pre>Question<span class="token punctuation">:</span> <span class="token string">'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'</span></pre></td></tr><tr><td data-num="7"></td><td><pre>Answer<span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Saint Bernadette Soubirous'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">515</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p><code>context</code> 和 <code>question</code> 字段使用起来非常简单。但是 <code>answers</code> 字段有点棘手，因为它将字典与两个都是列表的字段组成。这是在评估过程中 squad 指标所期望的格式；如果你使用的是自己的数据， <code>则不必担心将答案采用相同的格式。text</code> 字段比较明显，而 <code>answer_start</code> 字段包含上下文中每个答案的起始字符索引。</p><p>这个起始字符索引 <code>answer_start</code> ，是针对字符而不是 token</p><p>在训练期间，只有一种可能的答案。我们可以使用 <code>Dataset.filter()</code> 方法:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'title'</span><span class="token punctuation">,</span> <span class="token string">'context'</span><span class="token punctuation">,</span> <span class="token string">'question'</span><span class="token punctuation">,</span> <span class="token string">'answers'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    num_rows<span class="token punctuation">:</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>然而，对于评估，每个样本都有几个可能的答案，它们可能相同或不同:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Denver Broncos'</span><span class="token punctuation">,</span> <span class="token string">'Denver Broncos'</span><span class="token punctuation">,</span> <span class="token string">'Denver Broncos'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">&#123;</span><span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Santa Clara, California'</span><span class="token punctuation">,</span> <span class="token string">"Levi's Stadium"</span><span class="token punctuation">,</span> <span class="token string">"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">403</span><span class="token punctuation">,</span> <span class="token number">355</span><span class="token punctuation">,</span> <span class="token number">355</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>我们不会深入研究评估脚本，因为它都会被一个 Datasets 指标包裹起来，但简短的版本是一些问题有几个可能的答案，这个脚本会将预测的答案与所有​​的可接受的答案并获得最高分。例如，我们看一下索引 2 处的样本 e:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the "golden anniversary" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as "Super Bowl L"), so that the logo could prominently feature the Arabic numerals 50.'</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">'Where did Super Bowl 50 take place?'</span></pre></td></tr></table></figure><p>我们可以看到，答案确实可以是我们之前看到的三种可能性之一。</p><h3 id="处理训练数据"><a class="anchor" href="#处理训练数据">#</a> 处理训练数据</h3><p>让我们从预处理训练数据开始。困难的部分将是为问题的答案生成标签，这将是与上下文中的答案相对应的标记的开始和结束位置。</p><p>但是，我们不要超越自己。首先，我们需要使用分词器将输入中的文本转换为模型可以理解的 ID:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>model_checkpoint <span class="token operator">=</span> <span class="token string">"bert-base-cased"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr></table></figure><p>如前所述，我们将对 BERT 模型进行微调，但你可以使用任何其他模型类型，只要它实现了快速标记器即可。你可以在 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby90cmFuc2Zvcm1lcnMvI3N1cHBvcnRlZC1mcmFtZXdvcmtz">this big table</span> 中看到所有快速版本的架构，并检查你正在使用的 tokenizer 对象确实由 🤗 Tokenizers 支持，你可以查看它的 is_fast 属性:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>tokenizer<span class="token punctuation">.</span>is_fast</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token boolean">True</span></pre></td></tr></table></figure><p>我们可以将问题和上下文一起传递给我们的标记器，它会正确插入特殊标记以形成如下句子:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>CLS<span class="token punctuation">]</span> question <span class="token punctuation">[</span>SEP<span class="token punctuation">]</span> context <span class="token punctuation">[</span>SEP<span class="token punctuation">]</span></pre></td></tr></table></figure><p>让我们仔细检查一下:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>context <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>question <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, '</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin '</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token string">'Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms '</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred '</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token string">'Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a '</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token string">'replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette '</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token string">'Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues '</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">'and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'</span></pre></td></tr></table></figure><p>然后标签是开始和结束答案的 token 的索引，并且模型的任务是预测输入中每个 token 的开始和结束 logit, 理论标签如下:</p><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666617486761.png" alt="1666617486761"></p><p>上面图片中每个 token 下面的两个数字应该是分别表示答案是否开始和是否结束</p><p>在这种情况下，上下文不会太长，但是数据集中的一些示例的上下文很长，会超过我们设置的最大长度 (在这种情况下为 384)。正如我们在 第六章 中所看到的，当我们探索 question-answering 管道的内部结构时，我们将通过从我们的数据集的一个样本中创建几个训练特征来处理长上下文，它们之间有一个滑动窗口。</p><p>要使用当前示例查看其工作原理，我们可以将长度限制为 100, 并使用 50 个标记的滑动窗口。提醒一下，我们使用:</p><ul><li><code>max_length</code> 设置最大长度 (此处为 100)</li><li><code>truncation=&quot;only_second&quot;</code> 用于当带有上下文的问题太长时，截断上下文 t (位于第二个位置)</li><li><code>stride</code> 设置两个连续块之间的重叠标记数 (这里为 50)</li><li><code>return_overflowing_tokens=True</code> 让标记器知道我们想要溢出的标记</li></ul><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    question<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    context<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>inputs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'overflow_to_sample_mapping'])</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">for</span> ids <span class="token keyword">in</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]'</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]'</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'</span></pre></td></tr></table></figure><p>如我们所见，我们的示例被分成四个输入，每个输入都包含问题和上下文的一部分。 请注意，问题的答案 (“Bernadette Soubirous”) 仅出现在第三个也是最后一个输入中，因此通过以这种方式处理长上下文，我们将创建一些答案不包含在上下文中的训练示例。对于这些示例，标签将是 start_position = end_position = 0 (所以我们预测 [CLS] 标记)。我们还将在答案被截断的不幸情况下设置这些标签，以便我们只有它的开始 (或结束)。对于答案完全在上下文中的示例，标签将是答案开始的标记的索引和答案结束的标记的索引。</p><p>数据集为我们提供了上下文中答案的开始字符，通过添加答案的长度，我们可以找到上下文中的结束字符。要将它们映射到令牌索引，我们将需要使用我们在 <span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9jb3Vyc2UvY2hhcHRlcjYvNA==">第六章</span> 中研究的偏移映射。我们可以让标记器通过传递 <code>return_offsets_mapping=True</code> 来返回这些值:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    question<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    context<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>inputs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'offset_mapping'</span><span class="token punctuation">,</span> <span class="token string">'overflow_to_sample_mapping'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666696075334.png" alt="1666696075334"></p><p><img data-src="/./images/%E9%97%AE%E7%AD%94/1666696200826.png" alt="1666696200826"></p><p>从上面的截图中看出 <code>offset_mapping</code> 得到的是将 token 无空格的连接起来之后的 token 的索引。</p><p>如我们所见，我们取回了通常的输入 ID、令牌类型 ID 和注意掩码，以及我们需要的偏移映射和一个额外的键， <code>overflow_to_sample_mapping</code> 。当我们同时标记多个文本时，相应的值将对我们有用 (我们应该这样做以受益于我们的标记器由 Rust 支持的事实)。由于一个样本可以提供多个特征，因此它将每个特征映射到其来源的示例。因为这里我们只标记了一个例子，我们得到一个 0 的列表:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>但是，如果我们标记更多示例，这将变得更加有用:</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    max_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    stride<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"The 4 examples gave </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> features."</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Here is where each comes from: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>inputs<span class="token punctuation">[</span><span class="token string">'overflow_to_sample_mapping'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">."</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'The 4 examples gave 19 features.'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].'</span></pre></td></tr></table></figure><p>正如我们所看到的，前三个示例 (在训练集中的索引 2、3 和 4 处) 每个都给出了四个特征，最后一个示例 (在训练集中的索引 5 处) 给出了 7 个特征。</p><p>此信息将有助于将我们获得的每个特征映射到其相应的标签。如前所述，这些标签是:</p><ul><li><code>(0, 0)</code> 如果答案不在上下文的相应范围内</li><li><code>(start_position, end_position)</code> 如果答案在上下文的相应范围内，则 start_position 是答案开头的标记索引 (在输入 ID 中), 并且 end_position 是答案结束的标记的索引 (在输入 ID 中)。</li></ul><p>上面的输入 ID 是什么</p><p>为了确定是哪种情况以及标记的位置，以及 (如果相关的话) 标记的位置，我们首先在输入 ID 中找到开始和结束上下文的索引。我们可以使用标记类型 ID 来执行此操作，但由于这些 ID 不一定存在于所有模型中 (例如，DistilBERT 不需要它们), 我们将改为使用我们的标记器返回的 BatchEncoding 的 sequence_ids () 方法。</p><p>一旦我们有了这些标记索引，我们就会查看相应的偏移量，它们是两个整数的元组，表示原始上下文中的字符范围。因此，我们可以检测此特征中的上下文块是在答案之后开始还是在答案开始之前结束 (在这种情况下，标签是 (0, 0))。如果不是这样，我们循环查找答案的第一个和最后一个标记:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>answers <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="29"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>        idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>start_positions<span class="token punctuation">,</span> end_positions</pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="2"></td><td><pre> <span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">53</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>让我们看一些结果来验证我们的方法是否正确。对于我们发现的第一个特征，我们将 (83, 85) 作为标签，让我们将理论答案与从 83 到 85 (包括) 的标记解码范围进行比较:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="2"></td><td><pre>sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>start <span class="token operator">=</span> start_positions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre>end <span class="token operator">=</span> end_positions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>labeled_answer <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span>start <span class="token punctuation">:</span> end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Theoretical answer: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>answer<span class="token punctuation">&#125;</span></span><span class="token string">, labels give: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>labeled_answer<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'Theoretical answer: the Main Building, labels give: the Main Building'</span></pre></td></tr></table></figure><p>所以这是一场比赛！现在让我们检查索引 4, 我们将标签设置为 (0, 0), 这意味着答案不在该功能的上下文块中</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx <span class="token operator">=</span> <span class="token number">4</span></pre></td></tr><tr><td data-num="2"></td><td><pre>sample_idx <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>decoded_example <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Theoretical answer: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>answer<span class="token punctuation">&#125;</span></span><span class="token string">, decoded example: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>decoded_example<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]'</span></pre></td></tr></table></figure><p>事实上，我们在上下文中看不到答案。</p><p>现在我们已经逐步了解了如何预处理我们的训练数据，我们可以将其分组到一个函数中，我们将应用于整个训练数据集。我们会将每个特征填充到我们设置的最大长度，因为大多数上下文会很长 (并且相应的样本将被分成几个特征), 所以在这里应用动态填充没有真正的好处:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>max_length <span class="token operator">=</span> <span class="token number">384</span></pre></td></tr><tr><td data-num="2"></td><td><pre>stride <span class="token operator">=</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_training_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="36"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="37"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="39"></td><td><pre></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="42"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>            <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="46"></td><td><pre>            idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="47"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="48"></td><td><pre>                idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="49"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre>            idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="52"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="53"></td><td><pre>                idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="54"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="55"></td><td><pre></pre></td></tr><tr><td data-num="56"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions</pre></td></tr><tr><td data-num="57"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions</pre></td></tr><tr><td data-num="58"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr></table></figure><p>请注意，我们定义了两个常数来确定使用的最大长度以及滑动窗口的长度，并且我们在标记化之前添加了一点清理: SQuAD 数据集中的一些问题在开头有额外的空格，并且不添加任何内容的结尾 (如果你使用像 RoBERTa 这样的模型，则在标记化时会占用空间), 因此我们删除了那些额外的空格。</p><p>为了将此函数应用于整个训练集，我们使用 Dataset.map () 方法与 batched=True 标志。这是必要的，因为我们正在更改数据集的长度 (因为一个示例可以提供多个训练特征):</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    preprocess_training_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token builtin">len</span><span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">(</span><span class="token number">87599</span><span class="token punctuation">,</span> <span class="token number">88729</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>正如我们所见，预处理增加了大约 1,000 个特征。我们的训练集现在可以使用了 — 让我们深入研究验证集的预处理！</p><p>在 map 的时候使用 <code>batched=True</code> ，那么传入函数中的 example 是不是就是好几条数据，怎么验证呢？<br>是的，直接在函数中打印即可。</p><h3 id="处理验证数据"><a class="anchor" href="#处理验证数据">#</a> 处理验证数据</h3><p>预处理验证数据会稍微容易一些，因为我们不需要生成标签 (除非我们想计算验证损失，但这个数字并不能真正帮助我们理解模型有多好)。真正的乐趣是将模型的预测解释为原始上下文的跨度。为此，我们只需要存储偏移映射和某种方式来将每个创建的特征与它来自的原始示例相匹配。由于原始数据集中有一个 ID 列，我们将使用该 ID。</p><p>我们将在这里添加的唯一内容是对偏移映射的一点点清理。它们将包含问题和上下文的偏移量，但是一旦我们进入后处理阶段，我们将无法知道输入 ID 的哪一部分对应于上下文以及哪一部分是问题 (我们使用的 sequence_ids () 方法仅可用于标记器的输出)。因此，我们将与问题对应的偏移量设置为 None:</p><h2 id="使用-trainer-api-微调模型"><a class="anchor" href="#使用-trainer-api-微调模型">#</a> 使用 Trainer API 微调模型</h2><h2 id="使用-trainer-的完整代码"><a class="anchor" href="#使用-trainer-的完整代码">#</a> 使用 Trainer 的完整代码</h2><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># 处理训练数据</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>model_checkpoint <span class="token operator">=</span> <span class="token string">"bert-base-cased"</span></pre></td></tr><tr><td data-num="12"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>max_length <span class="token operator">=</span> <span class="token number">384</span></pre></td></tr><tr><td data-num="15"></td><td><pre>stride <span class="token operator">=</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_training_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>        <span class="token comment"># Find the start and end of the context</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        idx <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="47"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="48"></td><td><pre>        context_start <span class="token operator">=</span> idx</pre></td></tr><tr><td data-num="49"></td><td><pre>        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="50"></td><td><pre>            idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre>        <span class="token comment"># If the answer is not fully inside the context, label is (0, 0)</span></pre></td></tr><tr><td data-num="54"></td><td><pre>        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> start_char <span class="token keyword">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="55"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="58"></td><td><pre>            <span class="token comment"># Otherwise it's the start and end token positions</span></pre></td></tr><tr><td data-num="59"></td><td><pre>            idx <span class="token operator">=</span> context_start</pre></td></tr><tr><td data-num="60"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="61"></td><td><pre>                idx <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="62"></td><td><pre>            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre>            idx <span class="token operator">=</span> context_end</pre></td></tr><tr><td data-num="65"></td><td><pre>            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token keyword">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="66"></td><td><pre>                idx <span class="token operator">-=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="67"></td><td><pre>            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="68"></td><td><pre></pre></td></tr><tr><td data-num="69"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions</pre></td></tr><tr><td data-num="70"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions</pre></td></tr><tr><td data-num="71"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr><tr><td data-num="72"></td><td><pre></pre></td></tr><tr><td data-num="73"></td><td><pre></pre></td></tr><tr><td data-num="74"></td><td><pre>train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="75"></td><td><pre>    preprocess_training_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="76"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="77"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="78"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="79"></td><td><pre></pre></td></tr><tr><td data-num="80"></td><td><pre></pre></td></tr><tr><td data-num="81"></td><td><pre><span class="token comment"># 处理验证数据</span></pre></td></tr><tr><td data-num="82"></td><td><pre></pre></td></tr><tr><td data-num="83"></td><td><pre><span class="token keyword">def</span> <span class="token function">preprocess_validation_examples</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="84"></td><td><pre>    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="85"></td><td><pre>    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="86"></td><td><pre>        questions<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="87"></td><td><pre>        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="88"></td><td><pre>        max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="89"></td><td><pre>        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="90"></td><td><pre>        stride<span class="token operator">=</span>stride<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="91"></td><td><pre>        return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="92"></td><td><pre>        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="93"></td><td><pre>        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="94"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="95"></td><td><pre></pre></td></tr><tr><td data-num="96"></td><td><pre>    sample_map <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="97"></td><td><pre>    example_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="98"></td><td><pre></pre></td></tr><tr><td data-num="99"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="100"></td><td><pre>        sample_idx <span class="token operator">=</span> sample_map<span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="101"></td><td><pre>        example_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="102"></td><td><pre></pre></td></tr><tr><td data-num="103"></td><td><pre>        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="104"></td><td><pre>        offset <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="105"></td><td><pre>        inputs<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="106"></td><td><pre>            o <span class="token keyword">if</span> sequence_ids<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token boolean">None</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> o <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>offset<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="107"></td><td><pre>        <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="108"></td><td><pre></pre></td></tr><tr><td data-num="109"></td><td><pre>    inputs<span class="token punctuation">[</span><span class="token string">"example_id"</span><span class="token punctuation">]</span> <span class="token operator">=</span> example_ids</pre></td></tr><tr><td data-num="110"></td><td><pre>    <span class="token keyword">return</span> inputs</pre></td></tr><tr><td data-num="111"></td><td><pre></pre></td></tr><tr><td data-num="112"></td><td><pre>validation_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="113"></td><td><pre>    preprocess_validation_examples<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="114"></td><td><pre>    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="115"></td><td><pre>    remove_columns<span class="token operator">=</span>raw_datasets<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="116"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="117"></td><td><pre></pre></td></tr><tr><td data-num="118"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric</pre></td></tr><tr><td data-num="119"></td><td><pre></pre></td></tr><tr><td data-num="120"></td><td><pre>metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="121"></td><td><pre></pre></td></tr><tr><td data-num="122"></td><td><pre><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm</pre></td></tr><tr><td data-num="123"></td><td><pre></pre></td></tr><tr><td data-num="124"></td><td><pre></pre></td></tr><tr><td data-num="125"></td><td><pre><span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> end_logits<span class="token punctuation">,</span> features<span class="token punctuation">,</span> examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="126"></td><td><pre>    example_to_features <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="127"></td><td><pre>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> feature <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="128"></td><td><pre>        example_to_features<span class="token punctuation">[</span>feature<span class="token punctuation">[</span><span class="token string">"example_id"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="129"></td><td><pre></pre></td></tr><tr><td data-num="130"></td><td><pre>    predicted_answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="131"></td><td><pre>    <span class="token keyword">for</span> example <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="132"></td><td><pre>        example_id <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="133"></td><td><pre>        context <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="134"></td><td><pre>        answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="135"></td><td><pre></pre></td></tr><tr><td data-num="136"></td><td><pre>        <span class="token comment"># Loop through all features associated with that example</span></pre></td></tr><tr><td data-num="137"></td><td><pre>        <span class="token keyword">for</span> feature_index <span class="token keyword">in</span> example_to_features<span class="token punctuation">[</span>example_id<span class="token punctuation">]</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="138"></td><td><pre>            start_logit <span class="token operator">=</span> start_logits<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="139"></td><td><pre>            end_logit <span class="token operator">=</span> end_logits<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="140"></td><td><pre>            offsets <span class="token operator">=</span> features<span class="token punctuation">[</span>feature_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="141"></td><td><pre></pre></td></tr><tr><td data-num="142"></td><td><pre>            start_indexes <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>start_logit<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span>n_best <span class="token operator">-</span> <span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="143"></td><td><pre>            end_indexes <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>end_logit<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span>n_best <span class="token operator">-</span> <span class="token number">1</span> <span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="144"></td><td><pre>            <span class="token keyword">for</span> start_index <span class="token keyword">in</span> start_indexes<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="145"></td><td><pre>                <span class="token keyword">for</span> end_index <span class="token keyword">in</span> end_indexes<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="146"></td><td><pre>                    <span class="token comment"># Skip answers that are not fully in the context</span></pre></td></tr><tr><td data-num="147"></td><td><pre>                    <span class="token keyword">if</span> offsets<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> offsets<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="148"></td><td><pre>                        <span class="token keyword">continue</span></pre></td></tr><tr><td data-num="149"></td><td><pre>                    <span class="token comment"># Skip answers with a length that is either &lt; 0 or > max_answer_length</span></pre></td></tr><tr><td data-num="150"></td><td><pre>                    <span class="token keyword">if</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="151"></td><td><pre>                        end_index <span class="token operator">&lt;</span> start_index</pre></td></tr><tr><td data-num="152"></td><td><pre>                        <span class="token keyword">or</span> end_index <span class="token operator">-</span> start_index <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">></span> max_answer_length</pre></td></tr><tr><td data-num="153"></td><td><pre>                    <span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="154"></td><td><pre>                        <span class="token keyword">continue</span></pre></td></tr><tr><td data-num="155"></td><td><pre></pre></td></tr><tr><td data-num="156"></td><td><pre>                    answer <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="157"></td><td><pre>                        <span class="token string">"text"</span><span class="token punctuation">:</span> context<span class="token punctuation">[</span>offsets<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token punctuation">:</span> offsets<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="158"></td><td><pre>                        <span class="token string">"logit_score"</span><span class="token punctuation">:</span> start_logit<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span> <span class="token operator">+</span> end_logit<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="159"></td><td><pre>                    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="160"></td><td><pre>                    answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>answer<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="161"></td><td><pre></pre></td></tr><tr><td data-num="162"></td><td><pre>        <span class="token comment"># Select the answer with the best score</span></pre></td></tr><tr><td data-num="163"></td><td><pre>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>answers<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="164"></td><td><pre>            best_answer <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>answers<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">"logit_score"</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="165"></td><td><pre>            predicted_answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="166"></td><td><pre>                <span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> example_id<span class="token punctuation">,</span> <span class="token string">"prediction_text"</span><span class="token punctuation">:</span> best_answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="167"></td><td><pre>            <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="168"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="169"></td><td><pre>            predicted_answers<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> example_id<span class="token punctuation">,</span> <span class="token string">"prediction_text"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="170"></td><td><pre></pre></td></tr><tr><td data-num="171"></td><td><pre>    theoretical_answers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">"id"</span><span class="token punctuation">:</span> ex<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"answers"</span><span class="token punctuation">:</span> ex<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span> <span class="token keyword">for</span> ex <span class="token keyword">in</span> examples<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="172"></td><td><pre>    <span class="token keyword">return</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predicted_answers<span class="token punctuation">,</span> references<span class="token operator">=</span>theoretical_answers<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="173"></td><td><pre></pre></td></tr><tr><td data-num="174"></td><td><pre>model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="175"></td><td><pre></pre></td></tr><tr><td data-num="176"></td><td><pre></pre></td></tr><tr><td data-num="177"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments</pre></td></tr><tr><td data-num="178"></td><td><pre></pre></td></tr><tr><td data-num="179"></td><td><pre>args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="180"></td><td><pre>    <span class="token string">"bert-finetuned-squad"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="181"></td><td><pre>    evaluation_strategy<span class="token operator">=</span><span class="token string">"no"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="182"></td><td><pre>    save_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="183"></td><td><pre>    learning_rate<span class="token operator">=</span><span class="token number">2e-5</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="184"></td><td><pre>    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="185"></td><td><pre>    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="186"></td><td><pre>    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="187"></td><td><pre>    push_to_hub<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="188"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="189"></td><td><pre></pre></td></tr><tr><td data-num="190"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer</pre></td></tr><tr><td data-num="191"></td><td><pre></pre></td></tr><tr><td data-num="192"></td><td><pre>trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="193"></td><td><pre>    model<span class="token operator">=</span>model<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="194"></td><td><pre>    args<span class="token operator">=</span>args<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="195"></td><td><pre>    train_dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="196"></td><td><pre>    eval_dataset<span class="token operator">=</span>validation_dataset<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="197"></td><td><pre>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="198"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="199"></td><td><pre>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><div class="tags"><a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"><i class="ic i-tag"></i> 自然语言处理</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-11-12 13:39:58" itemprop="dateModified" datetime="2022-11-12T13:39:58+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/" title="问答 question answer">https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/主要的 NLP 任务/问答/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/09/23/language/python/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(90).webp" title="程序执行流程-python"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> Python</span><h3>程序执行流程-python</h3></a></div><div class="item right"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(75).webp" title="微调一个预训练模型-处理数据"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 微调一个预训练模型</span><h3>微调一个预训练模型-处理数据</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E7%AD%94-question-answering"><span class="toc-number">1.</span> <span class="toc-text">问答 Question answering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.</span> <span class="toc-text">准备数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#squad-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.1.</span> <span class="toc-text">SQuAD 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.2.</span> <span class="toc-text">处理训练数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E9%AA%8C%E8%AF%81%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.3.</span> <span class="toc-text">处理验证数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-trainer-api-%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">使用 Trainer API 微调模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-trainer-%E7%9A%84%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">1.3.</span> <span class="toc-text">使用 Trainer 的完整代码</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" rel="bookmark" title="微调一个掩码语言模型">微调一个掩码语言模型</a></li><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/" rel="bookmark" title="文本摘要 summarize">文本摘要 summarize</a></li><li class="active"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/" rel="bookmark" title="问答 question answer">问答 question answer</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/09/23/language/python/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/" title="分类于 huggingface">huggingface</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/Tokenizer%E5%BA%93/" title="分类于 Tokenizer库">Tokenizer库</a></div><span><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/NormalizationAndPre-tokenization/" title="Normalization and pre-tokenization">Normalization and pre-tokenization</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computational-performance/" title="分类于 chapter_computational-performance">chapter_computational-performance</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/parameterserver/" title="parameterserver">parameterserver</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/08/26/computer-science/algorithm/%E5%9B%BE%E8%A7%A3%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/24/language/Go/note/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/03/26/computer-science/algorithm/hot100/%E7%9F%A9%E9%98%B5/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-pretraining/" title="分类于 chapter_natural-language-processing-pretraining">chapter_natural-language-processing-pretraining</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-pretraining/word-embedding-dataset/" title="word-embedding-dataset">word-embedding-dataset</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/django/" title="分类于 django">django</a></div><span><a href="/2022/09/13/backend/django/%E5%9C%A8app%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8Btests%E6%A8%A1%E5%9D%97%E4%B8%AD%E6%B5%8B%E8%AF%95/" title="在app文件夹下tests模块中测试">在app文件夹下tests模块中测试</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-linear-networks/" title="分类于 chapter_linear-networks">chapter_linear-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_linear-networks/softmax-regression-concise/" title="softmax-regression-concise">softmax-regression-concise</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/11/12/ai/nlp/huggingface/主要的 NLP 任务/问答/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>