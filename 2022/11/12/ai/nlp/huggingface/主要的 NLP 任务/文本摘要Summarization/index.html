<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="自然语言处理"><link rel="canonical" href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/"><title>文本摘要 summarize - 主要nlp任务 - huggingface - nlp - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">文本摘要 summarize</h1><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>6.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>6 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(58).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(8).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(97).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(91).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(79).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(38).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/" itemprop="item" rel="index" title="分类于 nlp"><span itemprop="name">nlp</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/" itemprop="item" rel="index" title="分类于 huggingface"><span itemprop="name">huggingface</span></a><meta itemprop="position" content="3"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81nlp%E4%BB%BB%E5%8A%A1/" itemprop="item" rel="index" title="分类于 主要nlp任务"><span itemprop="name">主要nlp任务</span></a><meta itemprop="position" content="4"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="文本摘要"><a class="anchor" href="#文本摘要">#</a> 文本摘要</h1><p>在本节中，我们将看看如何使用 Transformer 模型将长文档压缩为摘要，这项任务称为文本摘要。这是最具挑战性的 NLP 任务之一，因为它需要一系列能力，例如理解长篇文章和生成能够捕捉文档中主要主题的连贯文本。但是，如果做得好，文本摘要是一种强大的工具，可以减轻领域专家详细阅读长文档的负担，从而加快各种业务流程。</p><p>尽管在 Hugging Face Hub 上已经存在各种微调模型用于文本摘要，几乎所有这些都只适用于英文文档。因此，为了在本节中添加一些变化，我们将为英语和西班牙语训练一个双语模型。在本节结束时，您将有一个可以总结客户评论的<span class="exturl" data-url="aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9odWdnaW5nZmFjZS1jb3Vyc2UvbXQ1LXNtYWxsLWZpbmV0dW5lZC1hbWF6b24tZW4tZXM=">模型</span>。</p><h2 id="准备多语言语料库"><a class="anchor" href="#准备多语言语料库">#</a> 准备多语言语料库</h2><p>我们将使用多语言亚马逊评论语料库创建我们的双语摘要器。该语料库由六种语言的亚马逊产品评论组成，通常用于对多语言分类器进行基准测试。然而，由于每条评论都附有一个简短的标题，我们可以使用标题作为我们模型学习的目标摘要！首先，让我们从 Hugging Face Hub 下载英语和西班牙语子集</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>spanish_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"amazon_reviews_multi"</span><span class="token punctuation">,</span> <span class="token string">"es"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>english_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"amazon_reviews_multi"</span><span class="token punctuation">,</span> <span class="token string">"en"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>english_dataset</pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>DatasetDict<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'review_id'</span><span class="token punctuation">,</span> <span class="token string">'product_id'</span><span class="token punctuation">,</span> <span class="token string">'reviewer_id'</span><span class="token punctuation">,</span> <span class="token string">'stars'</span><span class="token punctuation">,</span> <span class="token string">'review_body'</span><span class="token punctuation">,</span> <span class="token string">'review_title'</span><span class="token punctuation">,</span> <span class="token string">'language'</span><span class="token punctuation">,</span> <span class="token string">'product_category'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">200000</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'review_id'</span><span class="token punctuation">,</span> <span class="token string">'product_id'</span><span class="token punctuation">,</span> <span class="token string">'reviewer_id'</span><span class="token punctuation">,</span> <span class="token string">'stars'</span><span class="token punctuation">,</span> <span class="token string">'review_body'</span><span class="token punctuation">,</span> <span class="token string">'review_title'</span><span class="token punctuation">,</span> <span class="token string">'language'</span><span class="token punctuation">,</span> <span class="token string">'product_category'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">5000</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    test<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'review_id'</span><span class="token punctuation">,</span> <span class="token string">'product_id'</span><span class="token punctuation">,</span> <span class="token string">'reviewer_id'</span><span class="token punctuation">,</span> <span class="token string">'stars'</span><span class="token punctuation">,</span> <span class="token string">'review_body'</span><span class="token punctuation">,</span> <span class="token string">'review_title'</span><span class="token punctuation">,</span> <span class="token string">'language'</span><span class="token punctuation">,</span> <span class="token string">'product_category'</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        num_rows<span class="token punctuation">:</span> <span class="token number">5000</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>如您所见，对于每种语言，都有 200,000 条评论 train 拆分，每个评论有 5,000 条评论 validation 和 test 分裂。我们感兴趣的评论信息包含在 review_body 和 review_title 列。让我们通过创建一个简单的函数来查看一些示例，该函数使用我们在第五章学到过：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">show_samples</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    sample <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span>seed<span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">for</span> example <span class="token keyword">in</span> sample<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n'>> Title: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>example<span class="token punctuation">[</span><span class="token string">'review_title'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"'>> Review: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>example<span class="token punctuation">[</span><span class="token string">'review_body'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">'"</span></span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>show_samples<span class="token punctuation">(</span>english_dataset<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'>> Title: Worked in front position, not rear'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'>> Title: meh'</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token string">'>> Review: Does it’s job and it’s gorgeous but mine is falling apart, I had to basically put it together again with hot glue'</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token string">'>> Title: Can\'t beat these for the money'</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">'>> Review: Bought this for handling miscellaneous aircraft parts and hanger "stuff" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn\'t get brittle and split like my older plastic drawers did. I like the all-plastic construction. It\'s heavy duty enough to hold metal parts, but being made of plastic it\'s not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can\'t beat it. Best one of these I\'ve bought to date-- and I\'ve been using some version of these for over forty years.'</span></pre></td></tr></table></figure><p>试试看！ 更改 Dataset.shuffle () 命令中的随机种子以探索语料库中的其他评论。 如果您是说西班牙语的人，请查看 spanish_dataset 中的一些评论，看看标题是否也像合理的摘要。</p><p>此示例显示了人们通常在网上找到的评论的多样性，从正面到负面（以及介于两者之间的所有内容！）。尽管标题为 “meh” 的示例信息量不大，但其他标题看起来像是对评论本身的体面总结。在单个 GPU 上训练所有 400,000 条评论的摘要模型将花费太长时间，因此我们将专注于为单个产品领域生成摘要。为了了解我们可以选择哪些域，让我们将 english_dataset 转换到 pandas.DataFrame 并计算每个产品类别的评论数量：</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>english_dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">"pandas"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>english_df <span class="token operator">=</span> english_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Show counts for top 20 products</span></pre></td></tr><tr><td data-num="4"></td><td><pre>english_df<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>home                      <span class="token number">17679</span></pre></td></tr><tr><td data-num="2"></td><td><pre>apparel                   <span class="token number">15951</span></pre></td></tr><tr><td data-num="3"></td><td><pre>wireless                  <span class="token number">15717</span></pre></td></tr><tr><td data-num="4"></td><td><pre>other                     <span class="token number">13418</span></pre></td></tr><tr><td data-num="5"></td><td><pre>beauty                    <span class="token number">12091</span></pre></td></tr><tr><td data-num="6"></td><td><pre>drugstore                 <span class="token number">11730</span></pre></td></tr><tr><td data-num="7"></td><td><pre>kitchen                   <span class="token number">10382</span></pre></td></tr><tr><td data-num="8"></td><td><pre>toy                        <span class="token number">8745</span></pre></td></tr><tr><td data-num="9"></td><td><pre>sports                     <span class="token number">8277</span></pre></td></tr><tr><td data-num="10"></td><td><pre>automotive                 <span class="token number">7506</span></pre></td></tr><tr><td data-num="11"></td><td><pre>lawn_and_garden            <span class="token number">7327</span></pre></td></tr><tr><td data-num="12"></td><td><pre>home_improvement           <span class="token number">7136</span></pre></td></tr><tr><td data-num="13"></td><td><pre>pet_products               <span class="token number">7082</span></pre></td></tr><tr><td data-num="14"></td><td><pre>digital_ebook_purchase     <span class="token number">6749</span></pre></td></tr><tr><td data-num="15"></td><td><pre>pc                         <span class="token number">6401</span></pre></td></tr><tr><td data-num="16"></td><td><pre>electronics                <span class="token number">6186</span></pre></td></tr><tr><td data-num="17"></td><td><pre>office_product             <span class="token number">5521</span></pre></td></tr><tr><td data-num="18"></td><td><pre>shoes                      <span class="token number">5197</span></pre></td></tr><tr><td data-num="19"></td><td><pre>grocery                    <span class="token number">4730</span></pre></td></tr><tr><td data-num="20"></td><td><pre>book                       <span class="token number">3756</span></pre></td></tr><tr><td data-num="21"></td><td><pre>Name<span class="token punctuation">:</span> product_category<span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> int64</pre></td></tr></table></figure><p>英语数据集中最受欢迎的产品是家居用品、服装和无线电子产品。不过，为了坚持亚马逊的主题，让我们专注于总结书籍的评论 —— 毕竟，这是亚马逊这家公司成立的基础！我们可以看到两个符合要求的产品类别（ book 和 digital_ebook_purchase )，所以让我们为这些产品过滤两种语言的数据集。正如我们在第五章学到的， 这 Dataset.filter () 函数允许我们非常有效地对数据集进行切片，因此我们可以定义一个简单的函数来执行此操作：</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">filter_books</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">return</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        example<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"book"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token keyword">or</span> example<span class="token punctuation">[</span><span class="token string">"product_category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"digital_ebook_purchase"</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr></table></figure><p>现在，当我们将此函数应用于 english_dataset 和 spanish_dataset ，结果将只包含涉及书籍类别的那些行。在应用过滤器之前，让我们将 english_dataset 的格式从 pandas 切换回到 arrow ：</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>english_dataset<span class="token punctuation">.</span>reset_format<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>然后我们可以应用过滤器功能，作为健全性检查，让我们检查评论样本，看看它们是否确实与书籍有关：</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre>spanish_books <span class="token operator">=</span> spanish_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>filter_books<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>english_books <span class="token operator">=</span> english_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>filter_books<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>show_samples<span class="token punctuation">(</span>english_books<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'>> Title: I\'m dissapointed.'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I\'d at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I\'m dissapointed.'</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'>> Title: Good art, good price, poor design'</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token string">'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it\'s less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar'</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token string">'>> Title: Helpful'</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'</span></pre></td></tr></table></figure><p>好的，我们可以看到评论并不是严格意义上的书籍，可能是指日历和 OneNote 等电子应用程序等内容。尽管如此，该领域似乎适合训练摘要模型。在我们查看适合此任务的各种模型之前，我们还有最后一点数据准备要做：将英语和西班牙语评论合并为一个 DatasetDict 目的。 🤗 Datasets 提供了一个方便的 concatenate_datasets () 函数（顾名思义）合并 Dataset 对象。因此，为了创建我们的双语数据集，我们将遍历每个拆分，连接该拆分的数据集，并打乱结果以确保我们的模型不会过度拟合单一语言：</p><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> concatenate_datasets<span class="token punctuation">,</span> DatasetDict</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>books_dataset <span class="token operator">=</span> DatasetDict<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">for</span> split <span class="token keyword">in</span> english_books<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> concatenate_datasets<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token punctuation">[</span>english_books<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">,</span> spanish_books<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> books_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># Peek at a few examples</span></pre></td></tr><tr><td data-num="12"></td><td><pre>show_samples<span class="token punctuation">(</span>books_dataset<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight py"><figcaption data-lang="Python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">'>> Title: Easy to follow!!!!'</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.'</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'>> Title: PARCIALMENTE DAÑADO'</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token string">'>> Review: Me llegó el día que tocaba, junto a otros libros que pedí, pero la caja llegó en mal estado lo cual dañó las esquinas de los libros porque venían sin protección (forro).'</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token string">'>> Title: no lo he podido descargar'</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token string">'>> Review: igual que el anterior'</span></pre></td></tr></table></figure><div class="tags"><a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"><i class="ic i-tag"></i> 自然语言处理</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-11-12 13:39:42" itemprop="dateModified" datetime="2022-11-12T13:39:42+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/" title="文本摘要 summarize">https://jyuanhust.github.io/2022/11/12/ai/nlp/huggingface/主要的 NLP 任务/文本摘要Summarization/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(46).webp" title="微调一个预训练模型-处理数据"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 微调一个预训练模型</span><h3>微调一个预训练模型-处理数据</h3></a></div><div class="item right"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(50).webp" title="微调一个掩码语言模型"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 主要nlp任务</span><h3>微调一个掩码语言模型</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">文本摘要</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%A4%9A%E8%AF%AD%E8%A8%80%E8%AF%AD%E6%96%99%E5%BA%93"><span class="toc-number">1.1.</span> <span class="toc-text">准备多语言语料库</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" rel="bookmark" title="微调一个掩码语言模型">微调一个掩码语言模型</a></li><li class="active"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81Summarization/" rel="bookmark" title="文本摘要 summarize">文本摘要 summarize</a></li><li><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E9%97%AE%E7%AD%94/" rel="bookmark" title="问答 question answer">问答 question answer</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/11/12/ai/nlp/huggingface/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/tools/" title="分类于 tools">tools</a></div><span><a href="/2022/07/26/tools/csdn%E5%8D%9A%E5%AE%A2%E5%AF%BC%E5%87%BA%E4%B8%BAmd/" title="csdn博客导出为md">csdn博客导出为md</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-recurrent-neural-networks/" title="分类于 chapter_recurrent-neural-networks">chapter_recurrent-neural-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_recurrent-neural-networks/bptt/" title="bptt">bptt</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-appendix-tools-for-deep-learning/" title="分类于 chapter_appendix-tools-for-deep-learning">chapter_appendix-tools-for-deep-learning</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_appendix-tools-for-deep-learning/index/" title="index">index</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-applications/" title="分类于 chapter_natural-language-processing-applications">chapter_natural-language-processing-applications</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-applications/finetuning-bert/" title="finetuning-bert">finetuning-bert</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-pretraining/" title="分类于 chapter_natural-language-processing-pretraining">chapter_natural-language-processing-pretraining</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-pretraining/word2vec/" title="word2vec">word2vec</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/base/" title="分类于 base">base</a></div><span><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" title="Subword算法">Subword算法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-appendix-tools-for-deep-learning/" title="分类于 chapter_appendix-tools-for-deep-learning">chapter_appendix-tools-for-deep-learning</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_appendix-tools-for-deep-learning/aws/" title="aws">aws</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 computer-science">computer-science</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/" title="分类于 数据库系统原理实践MySQL">数据库系统原理实践MySQL</a></div><span><a href="/2022/08/24/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD2-%E8%A1%A8%E7%BB%93%E6%9E%84%E4%B8%8E%E5%AE%8C%E6%95%B4%E6%80%A7%E7%BA%A6%E6%9D%9F%E7%9A%84%E4%BF%AE%E6%94%B9ALTER/" title="实训2-表结构与完整性约束的修改ALTER">实训2-表结构与完整性约束的修改ALTER</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-recurrent-modern/" title="分类于 chapter_recurrent-modern">chapter_recurrent-modern</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_recurrent-modern/lstm/" title="lstm">lstm</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a></div><span><a href="/2022/07/25/frontend/javascript/JavaScript/" title="JavaScript">JavaScript</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/11/12/ai/nlp/huggingface/主要的 NLP 任务/文本摘要Summarization/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(i){return i.includes("#")},function(i){return new RegExp(LOCAL.path+"$").test(i)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>