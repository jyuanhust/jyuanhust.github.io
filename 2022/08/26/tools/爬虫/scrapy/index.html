<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="scrapy"><link rel="canonical" href="https://jyuanhust.github.io/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy/"><title>scrapy - 爬虫 - tools | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">scrapy</h1><div class="meta"><span class="item" title="创建时间：2022-08-26 14:38:19"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-08-26T14:38:19+08:00">2022-08-26</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>11k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>10 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(91).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(8).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(65).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(67).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(95).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(39).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/tools/" itemprop="item" rel="index" title="分类于 tools"><span itemprop="name">tools</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/tools/%E7%88%AC%E8%99%AB/" itemprop="item" rel="index" title="分类于 爬虫"><span itemprop="name">爬虫</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><p>scrapy fetch &quot;http:😕/www.baidu.com&quot;</p><h3 id="creating-a-project"><a class="anchor" href="#creating-a-project">#</a> Creating a project</h3><p>Before you start scraping, you will have to set up a new Scrapy project. Enter a directory where you’d like to store your code and run:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>scrapy startproject tutorial</pre></td></tr></table></figure><p>This will create a tutorial directory with the following contents:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>tutorial/</pre></td></tr><tr><td data-num="2"></td><td><pre>    scrapy.cfg            <span class="token comment"># deploy configuration file</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    tutorial/             <span class="token comment"># project's Python module, you'll import your code from here</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        __init__.py</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>        items.py          <span class="token comment"># project items definition file</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>        middlewares.py    <span class="token comment"># project middlewares file</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>        pipelines.py      <span class="token comment"># project pipelines file</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>        settings.py       <span class="token comment"># project settings file</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>        spiders/          <span class="token comment"># a directory where you'll later put your spiders</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            __init__.py</pre></td></tr></table></figure><h2 id="our-first-spider"><a class="anchor" href="#our-first-spider">#</a> Our first Spider</h2><p>Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass <code>scrapy.Spider</code> and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.</p><p>This is the code for our first Spider. Save it in a file named <code>quotes_spider.py</code> under the <code>tutorial/spiders</code> directory in your project:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> scrapy</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">"quotes"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        urls <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="9"></td><td><pre>            <span class="token string">'http://quotes.toscrape.com/page/1/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>            <span class="token string">'http://quotes.toscrape.com/page/2/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token keyword">for</span> url <span class="token keyword">in</span> urls<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        page <span class="token operator">=</span> response<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        filename <span class="token operator">=</span> <span class="token string">'quotes-%s.html'</span> <span class="token operator">%</span> page</pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">'Saved file %s'</span> <span class="token operator">%</span> filename<span class="token punctuation">)</span></pre></td></tr></table></figure><p>上面的 response 的类型为 <code>scrapy.http.response.html.HtmlResponse</code> ， <code>response.body</code> 的类型为 <code>bytes</code> （类似这样 <code>b'...字符...'</code> ）。</p><p>As you can see, our Spider subclasses <a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code>scrapy.Spider</code> </a>and defines some attributes and methods:</p><ul><li><a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/spiders.html#scrapy.spiders.Spider.name" title="scrapy.spiders.Spider.name"><code>name</code> </a>: identifies the Spider. It must be unique within a project, that is, you can’t set the same name for different Spiders.</li><li><a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code>start_requests()</code> </a>: must return an iterable of Requests (you can return a list of requests or write a generator function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests.</li><li><a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code>parse()</code> </a>: a method that will be called to handle the response downloaded for each of the requests made. The response parameter is an instance of <a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/request-response.html#scrapy.http.TextResponse" title="scrapy.http.TextResponse"><code>TextResponse</code> </a>that holds the page content and has further helpful methods to handle it. <strong>疑问？response 真是这个类型吗</strong></li></ul><p>The <a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code>parse()</code> </a>method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (<a target="_blank" rel="noopener" href="https://scrapy-16.readthedocs.io/zh_CN/1.6/topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"> <code>Request</code> </a>) from them.</p><h2 id="how-to-run-our-spider"><a class="anchor" href="#how-to-run-our-spider">#</a> How to run our spider</h2><p>To put our spider to work, go to the project’s top level directory and run:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>scrapy crawl quotes</pre></td></tr></table></figure><p>This command runs the spider with name <code>quotes</code> that we’ve just added, that will send some requests for the <code>quotes.toscrape.com</code> domain</p><h2 id="what-just-happened-under-the-hood"><a class="anchor" href="#what-just-happened-under-the-hood">#</a> What just happened under the hood?</h2><p>Scrapy schedules the <code>scrapy.Request</code> objects returned by the <code>start_requests</code> method of the Spider. Upon receiving a response for each one, it instantiates <code>Response</code> objects and calls the callback method associated with the request (in this case, the <code>parse</code> method) passing the response as argument.</p><h2 id="a-shortcut-to-the-start_requests-method"><a class="anchor" href="#a-shortcut-to-the-start_requests-method">#</a> A shortcut to the start_requests method</h2><p>Instead of implementing a <code>start_requests()</code> method that generates <code>scrapy.Request</code> objects from URLs, you can just define a <code>start_urls</code> class attribute with a list of URLs. This list will then be used by the default implementation of <code>start_requests()</code> to create the initial requests for your spider:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> scrapy</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">"quotes"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/1/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/2/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        page <span class="token operator">=</span> response<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        filename <span class="token operator">=</span> <span class="token string">'quotes-%s.html'</span> <span class="token operator">%</span> page</pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span></pre></td></tr></table></figure><p>The <code>parse()</code> method will be called to handle each of the requests for those URLs, even though we haven’t explicitly told Scrapy to do so. This happens because <code>parse()</code> is Scrapy’s default callback method, which is called for requests without an explicitly assigned callback.</p><h2 id="extracting-data"><a class="anchor" href="#extracting-data">#</a> Extracting data</h2><p>The best way to learn how to extract data with Scrapy is trying selectors using the Scrapy shell. Run:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>scrapy shell <span class="token string">'http://quotes.toscrape.com/page/1/'</span></pre></td></tr></table></figure><p><strong>注意</strong></p><p>Remember to always enclose urls in quotes when running Scrapy shell from command-line, otherwise urls containing arguments (ie. <code>&amp;</code> character) will not work.</p><p>On Windows, use double quotes instead:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>scrapy shell <span class="token string">"http://quotes.toscrape.com/page/1/"</span></pre></td></tr></table></figure><p>Using the shell, you can try selecting elements using CSS with the response object:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'title'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector <span class="token assign-left variable">xpath</span><span class="token operator">=</span><span class="token string">'descendant-or-self::title'</span> <span class="token assign-left variable">data</span><span class="token operator">=</span><span class="token string">'&lt;title>Quotes to Scrape&lt;/title>'</span><span class="token operator">></span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>上面的返回值中确实写的是 xpath，类型为 <code>scrapy.selector.unified.SelectorList</code></p><p>The result of running <code>response.css('title')</code> is a list-like object called <code>SelectorList</code> , which represents a list of <code>Selector</code> objects that wrap around XML/HTML elements and allow you to run further queries to fine-grain the selection or extract the data.</p><p>To extract the text from the title above, you can do:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span>.getall<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span><span class="token string">'Quotes to Scrape'</span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>There are two things to note here: one is that we’ve added <code>::text</code> to the CSS query, to mean we want to select only the text elements directly inside <code>&lt;title&gt;</code> element. If we don’t specify <code>::text</code> , we’d get the full title element, including its tags:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'title'</span><span class="token punctuation">)</span>.getall<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span><span class="token string">'&lt;title>Quotes to Scrape&lt;/title>'</span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>The other thing is that the result of calling <code>.getall()</code> is a list: it is possible that a selector returns more than one result, so we extract them all. When you know you just want the first result, as in this case, you can do:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'Quotes to Scrape'</span></pre></td></tr></table></figure><p>As an alternative, you could’ve written:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'Quotes to Scrape'</span></pre></td></tr></table></figure><p>However, using <code>.get()</code> directly on a SelectorList instance avoids an IndexError and returns None when it doesn’t find any element matching the selection.</p><p>Besides the <code>getall()</code> and <code>get()</code> methods, you can also use the <code>re()</code> method to extract using regular expressions:</p><h2 id="xpath-a-brief-intro"><a class="anchor" href="#xpath-a-brief-intro">#</a> XPath: a brief intro</h2><p>Besides CSS, Scrapy selectors also support using XPath expressions:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.xpath<span class="token punctuation">(</span><span class="token string">'//title'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector <span class="token assign-left variable">xpath</span><span class="token operator">=</span><span class="token string">'//title'</span> <span class="token assign-left variable">data</span><span class="token operator">=</span><span class="token string">'&lt;title>Quotes to Scrape&lt;/title>'</span><span class="token operator">></span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.xpath<span class="token punctuation">(</span><span class="token string">'//title/text()'</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token string">'Quotes to Scrape'</span></pre></td></tr></table></figure><p>XPath expressions are very powerful, and are the foundation of Scrapy Selectors. In fact, CSS selectors are converted to XPath under-the-hood.</p><p><img data-src="/./images/scrapy/1662133101979.png" alt="1662133101979"></p><h2 id="extracting-data-in-our-spider"><a class="anchor" href="#extracting-data-in-our-spider">#</a> Extracting data in our spider</h2><p>Let’s get back to our spider. Until now, it doesn’t extract any data in particular, just saves the whole HTML page to a local file. Let’s integrate the extraction logic above into our spider.</p><p>A Scrapy spider typically generates many dictionaries containing the data extracted from the page. To do that, we use the <code>yield</code> Python keyword in the callback, as you can see below:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> scrapy</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">"quotes"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/1/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/2/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token keyword">for</span> quote <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.quote'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            <span class="token keyword">yield</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                <span class="token string">'text'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'span.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                <span class="token string">'author'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'small.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                <span class="token string">'tags'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.tags a.tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            <span class="token punctuation">&#125;</span></pre></td></tr></table></figure><h2 id="storing-the-scraped-data"><a class="anchor" href="#storing-the-scraped-data">#</a> Storing the scraped data</h2><p>The simplest way to store the scraped data is by using Feed exports, with the following command:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>scrapy crawl quotes <span class="token parameter variable">-o</span> quotes.json</pre></td></tr></table></figure><p>That will generate an <code>quotes.json</code> file containing all scraped items, serialized in JSON.</p><p>For historic reasons, Scrapy appends to a given file instead of overwriting its contents. If you run this command twice without removing the file before the second time, you’ll end up with a broken JSON file.</p><p>In small projects (like the one in this tutorial), that should be enough. However, if you want to perform more complex things with the scraped items, you can write an Item Pipeline. A placeholder file for Item Pipelines has been set up for you when the project is created, in tutorial/pipelines.py. Though you don’t need to implement any item pipelines if you just want to store the scraped items.</p><h2 id="following-links"><a class="anchor" href="#following-links">#</a> Following links</h2><p>Let’s say, instead of just scraping the stuff from the first two pages from <span class="exturl" data-url="aHR0cDovL3F1b3Rlcy50b3NjcmFwZS5jb20=">http://quotes.toscrape.com</span>, you want quotes from all the pages in the website.</p><p>Now that you know how to extract data from pages, let’s see how to follow links from them.</p><p>First thing is to extract the link to the page we want to follow. Examining our page, we can see there is a link to the next page with the following markup:</p><figure class="highlight html"><figcaption data-lang="HTML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>pager<span class="token punctuation">"</span></span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>next<span class="token punctuation">"</span></span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/page/2/<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Next <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>span</span> <span class="token attr-name">aria-hidden</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token entity named-entity" title="&rarr;">&amp;rarr;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>span</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span></pre></td></tr></table></figure><p>We can try extracting it in the shell:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'li.next a'</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'&lt;a href="/page/2/">Next &lt;span aria-hidden="true">→&lt;/span>&lt;/a>'</span></pre></td></tr></table></figure><p>This gets the anchor element, but we want the attribute href. For that, Scrapy supports a CSS extension that lets you select the attribute contents, like this:</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'li.next a::attr(href)'</span><span class="token punctuation">)</span>.get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'/page/2/'</span></pre></td></tr></table></figure><p>There is also an attrib property available (see Selecting element attributes for more):</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">>></span><span class="token operator">></span> response.css<span class="token punctuation">(</span><span class="token string">'li.next a'</span><span class="token punctuation">)</span>.attrib<span class="token punctuation">[</span><span class="token string">'href'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token string">'/page/2'</span></pre></td></tr></table></figure><p>上面这种写法同样可以更换为 <code>xpath</code> 的形式。</p><p><img data-src="/./images/scrapy/1662131144026.png" alt="1662131144026"></p><p>从上面的例子中可以看出， <code>response.urljoin</code> 并不是直接将两个字符串拼接起来，而是针对 <code>response.url</code> 进行后面的替换。</p><p><img data-src="/./images/scrapy/1662131442743.png" alt="1662131442743"></p><p>当某个标签没有某个属性，用 xpath 获取时报错，但用 css 获取时返回 none</p><p>Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> scrapy</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">"quotes"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/1/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token keyword">for</span> quote <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.quote'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            <span class="token keyword">yield</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                <span class="token string">'text'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'span.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                <span class="token string">'author'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'small.author::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                <span class="token string">'tags'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.tags a.tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>        next_page <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'li.next a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">if</span> next_page <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            next_page <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>next_page<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_page<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr></table></figure><p>Now, after extracting the data, the <code>parse()</code> method looks for the link to the next page, builds a full absolute URL using the <code>urljoin()</code> method (since the links can be relative) and yields a new request to the next page, registering itself as callback to handle the data extraction for the next page and to keep the crawling going through all the pages.</p><h2 id="a-shortcut-for-creating-requests"><a class="anchor" href="#a-shortcut-for-creating-requests">#</a> A shortcut for creating Requests</h2><p>As a shortcut for creating Request objects you can use response.follow:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> scrapy</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">QuotesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">"quotes"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token string">'http://quotes.toscrape.com/page/1/'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">]</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token keyword">for</span> quote <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.quote'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            <span class="token keyword">yield</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                <span class="token string">'text'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'span.text::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                <span class="token string">'author'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'span small::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                <span class="token string">'tags'</span><span class="token punctuation">:</span> quote<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div.tags a.tag::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getall<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>        next_page <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'li.next a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">if</span> next_page <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            <span class="token keyword">yield</span> response<span class="token punctuation">.</span>follow<span class="token punctuation">(</span>next_page<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr></table></figure><p>Unlike <code>scrapy.Request</code> , <code>response.follow</code> supports relative URLs directly - no need to call <code>urljoin</code> . Note that <code>response.follow</code> just returns a Request instance; you still have to yield this Request.</p><p>You can also pass a selector to <code>response.follow</code> instead of a string; this selector should extract necessary attributes:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">for</span> href <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'li.next a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">yield</span> response<span class="token punctuation">.</span>follow<span class="token punctuation">(</span>href<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr></table></figure><p>For <code>&lt;a&gt;</code> elements there is a shortcut: <code>response.follow</code> uses their href attribute automatically. So the code can be shortened further:</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">for</span> a <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'li.next a'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">yield</span> response<span class="token punctuation">.</span>follow<span class="token punctuation">(</span>a<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr></table></figure><p><strong>注意</strong></p><p><code>response.follow(response.css('li.next a'))</code> is not valid because <code>response.css</code> returns a list-like object with selectors for all results, not a single selector. A <code>for</code> loop like in the example above, or <code>response.follow(response.css('li.next a')[0])</code> is fine.</p><h2 id="more-examples-and-patterns"><a class="anchor" href="#more-examples-and-patterns">#</a> More examples and patterns</h2><p>Here is another spider that illustrates callbacks and following links, this time for scraping author information:</p><p>import scrapy</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">AuthorSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    name <span class="token operator">=</span> <span class="token string">'author'</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://quotes.toscrape.com/'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token comment"># follow links to author pages</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token keyword">for</span> href <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'.author + a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>            <span class="token keyword">yield</span> response<span class="token punctuation">.</span>follow<span class="token punctuation">(</span>href<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse_author<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token comment"># follow pagination links</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token keyword">for</span> href <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'li.next a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            <span class="token keyword">yield</span> response<span class="token punctuation">.</span>follow<span class="token punctuation">(</span>href<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">parse_author</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token keyword">def</span> <span class="token function">extract_with_css</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            <span class="token keyword">return</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">yield</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="20"></td><td><pre>            <span class="token string">'name'</span><span class="token punctuation">:</span> extract_with_css<span class="token punctuation">(</span><span class="token string">'h3.author-title::text'</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            <span class="token string">'birthdate'</span><span class="token punctuation">:</span> extract_with_css<span class="token punctuation">(</span><span class="token string">'.author-born-date::text'</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            <span class="token string">'bio'</span><span class="token punctuation">:</span> extract_with_css<span class="token punctuation">(</span><span class="token string">'.author-description::text'</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>This spider will start from the main page, it will follow all the links to the authors pages calling the <code>parse_author</code> callback for each of them, and also the pagination links with the <code>parse</code> callback as we saw before.</p><div class="tags"><a href="/tags/scrapy/" rel="tag"><i class="ic i-tag"></i> scrapy</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-11-12 18:50:02" itemprop="dateModified" datetime="2022-11-12T18:50:02+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy/" title="scrapy">https://jyuanhust.github.io/2022/08/26/tools/爬虫/scrapy/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/xpath/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(35).webp" title="xpath"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 爬虫</span><h3>xpath</h3></a></div><div class="item right"><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy-Items/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(73).webp" title="scrapy-Items"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 爬虫</span><h3>scrapy-Items</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#creating-a-project"><span class="toc-number">1.</span> <span class="toc-text">Creating a project</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#our-first-spider"><span class="toc-number"></span> <span class="toc-text">Our first Spider</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#how-to-run-our-spider"><span class="toc-number"></span> <span class="toc-text">How to run our spider</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-just-happened-under-the-hood"><span class="toc-number"></span> <span class="toc-text">What just happened under the hood?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-shortcut-to-the-start_requests-method"><span class="toc-number"></span> <span class="toc-text">A shortcut to the start_requests method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#extracting-data"><span class="toc-number"></span> <span class="toc-text">Extracting data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xpath-a-brief-intro"><span class="toc-number"></span> <span class="toc-text">XPath: a brief intro</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#extracting-data-in-our-spider"><span class="toc-number"></span> <span class="toc-text">Extracting data in our spider</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#storing-the-scraped-data"><span class="toc-number"></span> <span class="toc-text">Storing the scraped data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#following-links"><span class="toc-number"></span> <span class="toc-text">Following links</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-shortcut-for-creating-requests"><span class="toc-number"></span> <span class="toc-text">A shortcut for creating Requests</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#more-examples-and-patterns"><span class="toc-number"></span> <span class="toc-text">More examples and patterns</span></a></li></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy-Items/" rel="bookmark" title="scrapy-Items">scrapy-Items</a></li><li class="active"><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy/" rel="bookmark" title="scrapy">scrapy</a></li><li><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/xpath/" rel="bookmark" title="xpath">xpath</a></li><li><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy-Item-%E5%8A%A0%E8%BD%BD%E5%99%A8/" rel="bookmark" title="scrapy-Item-加载器">scrapy-Item-加载器</a></li><li><a href="/2022/09/09/tools/%E7%88%AC%E8%99%AB/selenium/" rel="bookmark" title="selenium">selenium</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/xpath/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/08/26/tools/%E7%88%AC%E8%99%AB/scrapy-Items/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="分类于 pytorch">pytorch</a></div><span><a href="/2022/08/24/ai/pytorch/torch-matmul-%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D/" title="torch.matmul()用法介绍">torch.matmul()用法介绍</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 computer-science">computer-science</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/algorithm/" title="分类于 algorithm">algorithm</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/algorithm/leetCode/" title="分类于 leetCode">leetCode</a></div><span><a href="/2022/12/26/computer-science/algorithm/leetCode/11-%E5%A6%99%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="11-妙用数据结构">11-妙用数据结构</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/base/" title="分类于 base">base</a></div><span><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" title="pytorch中LSTM的output和hidden关系">pytorch中LSTM的output和hidden关系</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E4%BB%A3%E7%A0%81%E8%AF%84%E6%B3%A8/%E6%80%BB%E7%BB%93/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/Node-js/" title="分类于 Node.js">Node.js</a></div><span><a href="/2022/09/08/frontend/Node/Express/" title="Express">Express</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-linear-networks/" title="分类于 chapter_linear-networks">chapter_linear-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_linear-networks/softmax-regression/" title="softmax-regression">softmax-regression</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/python/" title="分类于 python">python</a></div><span><a href="/2022/08/24/language/python/re-sub-%E7%94%A8%E6%B3%95%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/" title="re.sub()用法的详细介绍">re.sub()用法的详细介绍</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-applications/" title="分类于 chapter_natural-language-processing-applications">chapter_natural-language-processing-applications</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset/" title="sentiment-analysis-and-dataset">sentiment-analysis-and-dataset</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computer-vision/" title="分类于 chapter_computer-vision">chapter_computer-vision</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/fcn/" title="fcn">fcn</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/08/26/tools/爬虫/scrapy/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>