<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="自然语言处理,循环神经网络"><link rel="canonical" href="https://jyuanhust.github.io/2022/08/05/ai/nlp/base/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/"><title>文本情感分类 - base - nlp - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">文本情感分类</h1><div class="meta"><span class="item" title="创建时间：2022-08-05 18:52:49"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-08-05T18:52:49+08:00">2022-08-05</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>9.9k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>9 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(65).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(37).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(26).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(33).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(85).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(39).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/" itemprop="item" rel="index" title="分类于 nlp"><span itemprop="name">nlp</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/nlp/base/" itemprop="item" rel="index" title="分类于 base"><span itemprop="name">base</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/08/05/ai/nlp/base/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="文本情感分类"><a class="anchor" href="#文本情感分类">#</a> 文本情感分类</h1><h2 id="目标"><a class="anchor" href="#目标">#</a> 目标</h2><ol><li>知道文本处理的基本方法</li><li>能够使用数据实现情感分类的</li></ol><h2 id="1-案例介绍"><a class="anchor" href="#1-案例介绍">#</a> 1. 案例介绍</h2><p>为了对前面的 word embedding 这种常用的文本向量化的方法进行巩固，这里我们会完成一个文本情感分类的案例</p><p>现在我们有一个经典的数据集 <code>IMDB</code> 数据集，地址： <code>http://ai.stanford.edu/~amaas/data/sentiment/</code> ，这是一份包含了 5 万条流行电影的评论数据，其中训练集 25000 条，测试集 25000 条。数据格式如下：</p><p>下图左边为名称，其中名称包含两部分，分别是序号和情感评分，（1-4 为 neg，5-10 为 pos），右边为评论内容</p><p><img data-src="/../images/1.3/%E6%A0%B7%E6%9C%AC%E5%90%8D%E7%A7%B0.png" alt></p><p>根据上述的样本，需要使用 pytorch 完成模型，实现对评论情感进行预测</p><h2 id="2-思路分析"><a class="anchor" href="#2-思路分析">#</a> 2. 思路分析</h2><p>首先可以把上述问题定义为分类问题，情感评分分为 1-10，10 个类别（也可以理解为回归问题，这里当做分类问题考虑）。那么根据之前的经验，我们的大致流程如下：</p><ol><li>准备数据集</li><li>构建模型</li><li>模型训练</li><li>模型评估</li></ol><p>知道思路之后，那么我们一步步来完成上述步骤</p><h2 id="3-准备数据集"><a class="anchor" href="#3-准备数据集">#</a> 3. 准备数据集</h2><p>准备数据集和之前的方法一样，实例化 dataset，准备 dataloader，最终我们的数据可以处理成如下格式：</p><p><img data-src="/../images/1.3/%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB-data%E5%8A%A0%E8%BD%BD1.png" alt></p><p>其中有两点需要注意：</p><ol><li>如何完成基础打 Dataset 的构建和 Dataloader 的准备</li><li>每个 batch 中文本的长度不一致的问题如何解决</li><li>每个 batch 中的文本如何转化为数字序列</li></ol><h3 id="31-基础dataset的准备"><a class="anchor" href="#31-基础dataset的准备">#</a> 3.1 基础 Dataset 的准备</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span>Dataset</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> os</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> re</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>data_base_path <span class="token operator">=</span> <span class="token string">r"data\aclImdb"</span>  <span class="token comment"># 字符串前加 r 表示 raw string，\ 不再表示转义</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment">#1. 定义 tokenize 的方法</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># fileters = '!"#$%&amp;()*+,-./:;&lt;=>?@[\\]^_`&#123;|&#125;~\t\n'</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    fileters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'!'</span><span class="token punctuation">,</span><span class="token string">'"'</span><span class="token punctuation">,</span><span class="token string">'#'</span><span class="token punctuation">,</span><span class="token string">'$'</span><span class="token punctuation">,</span><span class="token string">'%'</span><span class="token punctuation">,</span><span class="token string">'&amp;'</span><span class="token punctuation">,</span><span class="token string">'\('</span><span class="token punctuation">,</span><span class="token string">'\)'</span><span class="token punctuation">,</span><span class="token string">'\*'</span><span class="token punctuation">,</span><span class="token string">'\+'</span><span class="token punctuation">,</span><span class="token string">','</span><span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'\.'</span><span class="token punctuation">,</span><span class="token string">'/'</span><span class="token punctuation">,</span><span class="token string">':'</span><span class="token punctuation">,</span><span class="token string">';'</span><span class="token punctuation">,</span><span class="token string">'&lt;'</span><span class="token punctuation">,</span><span class="token string">'='</span><span class="token punctuation">,</span><span class="token string">'>'</span><span class="token punctuation">,</span><span class="token string">'\?'</span><span class="token punctuation">,</span><span class="token string">'@'</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token punctuation">,</span><span class="token string">'\['</span><span class="token punctuation">,</span><span class="token string">'\\'</span><span class="token punctuation">,</span><span class="token string">'\]'</span><span class="token punctuation">,</span><span class="token string">'^'</span><span class="token punctuation">,</span><span class="token string">'_'</span><span class="token punctuation">,</span><span class="token string">'`'</span><span class="token punctuation">,</span><span class="token string">'\&#123;'</span><span class="token punctuation">,</span><span class="token string">'\|'</span><span class="token punctuation">,</span><span class="token string">'\&#125;'</span><span class="token punctuation">,</span><span class="token string">'~'</span><span class="token punctuation">,</span><span class="token string">'\t'</span><span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">'\x97'</span><span class="token punctuation">,</span><span class="token string">'\x96'</span><span class="token punctuation">,</span><span class="token string">'”'</span><span class="token punctuation">,</span><span class="token string">'“'</span><span class="token punctuation">,</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"&lt;.*?>"</span><span class="token punctuation">,</span><span class="token string">" "</span><span class="token punctuation">,</span>text<span class="token punctuation">,</span>flags<span class="token operator">=</span>re<span class="token punctuation">.</span>S<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>fileters<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">" "</span><span class="token punctuation">,</span>text<span class="token punctuation">,</span>flags<span class="token operator">=</span>re<span class="token punctuation">.</span>S<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">return</span> <span class="token punctuation">[</span>i<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment">#2. 准备 dataset</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">ImdbDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>mode<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>ImdbDataset<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">"train"</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            text_path <span class="token operator">=</span> <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_base_path<span class="token punctuation">,</span>i<span class="token punctuation">)</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"train/neg"</span><span class="token punctuation">,</span><span class="token string">"train/pos"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="24"></td><td><pre>            text_path <span class="token operator">=</span>  <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_base_path<span class="token punctuation">,</span>i<span class="token punctuation">)</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"test/neg"</span><span class="token punctuation">,</span><span class="token string">"test/pos"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>        self<span class="token punctuation">.</span>total_file_path_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        <span class="token keyword">for</span> i <span class="token keyword">in</span> text_path<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="28"></td><td><pre>            self<span class="token punctuation">.</span>total_file_path_list<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>i<span class="token punctuation">,</span>j<span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        cur_path <span class="token operator">=</span> self<span class="token punctuation">.</span>total_file_path_list<span class="token punctuation">[</span>idx<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>        cur_filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>cur_path<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>cur_filename<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token comment">#处理标题，获取 label，转化为从 [0-9]</span></pre></td></tr><tr><td data-num="36"></td><td><pre>        text <span class="token operator">=</span> tokenize<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span>cur_path<span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#直接按照空格进行分词</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        <span class="token keyword">return</span> label<span class="token punctuation">,</span>text</pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>total_file_path_list<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>  </pre></td></tr><tr><td data-num="42"></td><td><pre> <span class="token comment"># 2. 实例化，准备 dataloader</span></pre></td></tr><tr><td data-num="43"></td><td><pre>dataset <span class="token operator">=</span> ImdbDataset<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre><span class="token comment">#3. 观察数据输出结果</span></pre></td></tr><tr><td data-num="47"></td><td><pre><span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span>text<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"idx："</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"table:"</span><span class="token punctuation">,</span>label<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"text:"</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token keyword">break</span></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx： <span class="token number">0</span></pre></td></tr><tr><td data-num="2"></td><td><pre>table<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>text<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'Want'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'thought'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'this'</span><span class="token punctuation">,</span> <span class="token string">'great'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'was'</span><span class="token punctuation">,</span> <span class="token string">'recipe'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'great'</span><span class="token punctuation">,</span> <span class="token string">'failure'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'idea'</span><span class="token punctuation">,</span> <span class="token string">'Take'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'but'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'boy'</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'was'</span><span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'it'</span><span class="token punctuation">,</span> <span class="token string">'plot'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'poorly'</span><span class="token punctuation">,</span> <span class="token string">'add'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'executed'</span><span class="token punctuation">,</span> <span class="token string">'in'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'We'</span><span class="token punctuation">,</span> <span class="token string">'some'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'do'</span><span class="token punctuation">,</span> <span class="token string">'weak'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'get'</span><span class="token punctuation">,</span> <span class="token string">'completely'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'undeveloped'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'broad'</span><span class="token punctuation">,</span> <span class="token string">'characters'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'sense'</span><span class="token punctuation">,</span> <span class="token string">'and'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'of'</span><span class="token punctuation">,</span> <span class="token string">'than'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'how'</span><span class="token punctuation">,</span> <span class="token string">'throw'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'complex'</span><span class="token punctuation">,</span> <span class="token string">'in'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'and'</span><span class="token punctuation">,</span> <span class="token string">'the'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'challenging'</span><span class="token punctuation">,</span> <span class="token string">'worst'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'the'</span><span class="token punctuation">,</span> <span class="token string">'special'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'backstage'</span><span class="token punctuation">,</span> <span class="token string">'effects'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'operations'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'of'</span><span class="token punctuation">,</span> <span class="token string">'horror'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'movie'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'show'</span><span class="token punctuation">,</span> <span class="token string">'has'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'are'</span><span class="token punctuation">,</span> <span class="token string">'known'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'but'</span><span class="token punctuation">,</span> <span class="token string">'Let'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'virtually'</span><span class="token punctuation">,</span> <span class="token string">'stew'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token string">'show'</span><span class="token punctuation">,</span> <span class="token string">'somehow'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'rather'</span><span class="token punctuation">,</span> <span class="token string">'destroy'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'than'</span><span class="token punctuation">,</span> <span class="token string">'every'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'anything'</span><span class="token punctuation">,</span> <span class="token string">'copy'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'worth'</span><span class="token punctuation">,</span> <span class="token string">'of'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'watching'</span><span class="token punctuation">,</span> <span class="token string">'this'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'for'</span><span class="token punctuation">,</span> <span class="token string">'film'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'its'</span><span class="token punctuation">,</span> <span class="token string">'so'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'own'</span><span class="token punctuation">,</span> <span class="token string">'it'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'merit'</span><span class="token punctuation">,</span> <span class="token string">'will'</span><span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr></table></figure><p>现在运行出现报错 <code>RuntimeError: each element in list of batch should be of equal size</code> ，应该是处理每个文件的文本后，得到的单词的数量不一致造成的。</p><p>明显，其中的 text 内容出现对应，和想象的不太相似，出现问题的原因在于 <code>Dataloader</code> 中的参数 <code>collate_fn</code></p><p><code>collate_fn</code> 的默认值为 torch 自定义的 <code>default_collate</code> , <code>collate_fn</code> 的作用就是对每个 batch 进行处理，而默认的 <code>default_collate</code> 处理出错。</p><p>解决问题的思路：</p><p>手段 1：考虑先把数据转化为数字序列，观察其结果是否符合要求，之前使用 DataLoader 并未出现类似错误</p><p>手段 2：考虑自定义一个 <code>collate_fn</code> ，观察结果</p><p>这里使用方式 2，自定义一个 <code>collate_fn</code> , 然后观察结果：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>	<span class="token comment">#batch 是 list，其中是一个一个元组，每个元组是 dataset 中__getitem__的结果</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    batch <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 将标签和单词列表分别放到一起</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    labes <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    texts <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">del</span> batch</pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">return</span> labes<span class="token punctuation">,</span>texts</pre></td></tr><tr><td data-num="8"></td><td><pre>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment">#此时输出正常</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span>text<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"idx："</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"table:"</span><span class="token punctuation">,</span>label<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"text:"</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token keyword">break</span></pre></td></tr></table></figure><h3 id="32-文本序列化"><a class="anchor" href="#32-文本序列化">#</a> 3.2 文本序列化</h3><blockquote><p>再介绍 word embedding 的时候，我们说过，不会直接把文本转化为向量，而是先转化为数字，再把数字转化为向量，那么这个过程该如何实现呢？</p></blockquote><p>这里我们可以考虑把文本中的每个<strong>词语和其对应的数字，使用字典保存</strong>，同时实现方法<strong>把句子通过字典映射为包含数字的列表</strong>。</p><p>实现文本序列化之前，考虑以下几点:</p><ol><li>如何使用字典把词语和数字进行对应</li><li>不同的词语出现的次数不尽相同，是否需要对高频或者低频词语进行过滤，以及总的词语数量是否需要进行限制</li><li>得到词典之后，如何把句子转化为数字序列，如何把数字序列转化为句子</li><li>不同句子长度不相同，每个 batch 的句子如何构造成相同的长度（可以对短句子进行填充，填充特殊字符）</li><li>对于新出现的词语在词典中没有出现怎么办（可以使用特殊字符代理）</li></ol><p>思路分析：</p><ol><li>对所有句子进行分词</li><li>词语存入字典，根据次数对词语进行过滤，并统计次数</li><li>实现文本转数字序列的方法</li><li>实现数字序列转文本方法</li></ol><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Word2Sequence</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    UNK_TAG <span class="token operator">=</span> <span class="token string">"UNK"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    PAD_TAG <span class="token operator">=</span> <span class="token string">"PAD"</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>    UNK <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 低频词或未在词表中的词</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    PAD <span class="token operator">=</span> <span class="token number">1</span>  <span class="token comment"># 补全字符</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        self<span class="token punctuation">.</span><span class="token builtin">dict</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            self<span class="token punctuation">.</span>UNK_TAG<span class="token punctuation">:</span> self<span class="token punctuation">.</span>UNK<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>            self<span class="token punctuation">.</span>PAD_TAG<span class="token punctuation">:</span> self<span class="token punctuation">.</span>PAD</pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        self<span class="token punctuation">.</span>fited <span class="token operator">=</span> <span class="token boolean">False</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">to_index</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token triple-quoted-string string">"""word -> index"""</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>fited <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">"必须先进行fit操作"</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> self<span class="token punctuation">.</span>UNK<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">to_word</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token triple-quoted-string string">"""index -> word"""</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>fited<span class="token punctuation">,</span> <span class="token string">"必须先进行fit操作"</span></pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token keyword">if</span> index <span class="token keyword">in</span> self<span class="token punctuation">.</span>inversed_dict<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>inversed_dict<span class="token punctuation">[</span>index<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>UNK_TAG</pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentences<span class="token punctuation">,</span> min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> max_count<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> max_feature<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        :param sentences:[[word1,word2,word3],[word1,word3,wordn..],...]</pre></td></tr><tr><td data-num="36"></td><td><pre>        :param min_count: 最小出现的次数</pre></td></tr><tr><td data-num="37"></td><td><pre>        :param max_count: 最大出现的次数</pre></td></tr><tr><td data-num="38"></td><td><pre>        :param max_feature: 总词语的最大数量</pre></td></tr><tr><td data-num="39"></td><td><pre>        :return:</pre></td></tr><tr><td data-num="40"></td><td><pre>        """</pre></td></tr><tr><td data-num="41"></td><td><pre>        count <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="43"></td><td><pre>            <span class="token keyword">for</span> a <span class="token keyword">in</span> sentence<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="44"></td><td><pre>                <span class="token keyword">if</span> a <span class="token keyword">not</span> <span class="token keyword">in</span> count<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>                    count<span class="token punctuation">[</span>a<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="46"></td><td><pre>                count<span class="token punctuation">[</span>a<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>        <span class="token comment"># 比最小的数量大和比最大的数量小的需要</span></pre></td></tr><tr><td data-num="49"></td><td><pre>        <span class="token keyword">if</span> min_count <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="50"></td><td><pre>            count <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> count<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> v <span class="token operator">>=</span> min_count<span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        <span class="token keyword">if</span> max_count <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="52"></td><td><pre>            count <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> count<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> v <span class="token operator">&lt;=</span> max_count<span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>        <span class="token comment"># 限制最大的数量</span></pre></td></tr><tr><td data-num="55"></td><td><pre>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>max_feature<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="56"></td><td><pre>            <span class="token comment"># 按照 value 值进行从小到大排序</span></pre></td></tr><tr><td data-num="57"></td><td><pre>            count <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="59"></td><td><pre>            <span class="token comment"># 如果超出，则只取频率高的</span></pre></td></tr><tr><td data-num="60"></td><td><pre>            <span class="token keyword">if</span> max_feature <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span> <span class="token operator">></span> max_feature<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="61"></td><td><pre>                count <span class="token operator">=</span> count<span class="token punctuation">[</span><span class="token operator">-</span><span class="token builtin">int</span><span class="token punctuation">(</span>max_feature<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="62"></td><td><pre>            <span class="token keyword">for</span> w<span class="token punctuation">,</span> _ <span class="token keyword">in</span> count<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="63"></td><td><pre>                self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="64"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="65"></td><td><pre>            <span class="token comment"># 没有超出，不用排序</span></pre></td></tr><tr><td data-num="66"></td><td><pre>            <span class="token keyword">for</span> w <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="67"></td><td><pre>                self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="68"></td><td><pre></pre></td></tr><tr><td data-num="69"></td><td><pre>        self<span class="token punctuation">.</span>fited <span class="token operator">=</span> <span class="token boolean">True</span></pre></td></tr><tr><td data-num="70"></td><td><pre>        <span class="token comment"># 准备一个 index->word 的字典</span></pre></td></tr><tr><td data-num="71"></td><td><pre>        self<span class="token punctuation">.</span>inversed_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="72"></td><td><pre></pre></td></tr><tr><td data-num="73"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> max_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="74"></td><td><pre>        <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="75"></td><td><pre>        实现吧句子转化为数组（向量）</pre></td></tr><tr><td data-num="76"></td><td><pre>        :param sentence:</pre></td></tr><tr><td data-num="77"></td><td><pre>        :param max_len:</pre></td></tr><tr><td data-num="78"></td><td><pre>        :return:</pre></td></tr><tr><td data-num="79"></td><td><pre>        """</pre></td></tr><tr><td data-num="80"></td><td><pre>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>fited<span class="token punctuation">,</span> <span class="token string">"必须先进行fit操作"</span></pre></td></tr><tr><td data-num="81"></td><td><pre>        <span class="token keyword">if</span> max_len <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="82"></td><td><pre>            r <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>PAD<span class="token punctuation">]</span> <span class="token operator">*</span> max_len</pre></td></tr><tr><td data-num="83"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="84"></td><td><pre>            r <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>PAD<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="85"></td><td><pre>        <span class="token comment"># 得到的 r 为相应长度的全为 1 的向量</span></pre></td></tr><tr><td data-num="86"></td><td><pre>      </pre></td></tr><tr><td data-num="87"></td><td><pre>        <span class="token comment"># 若句子过长，则只取前 max_len 个字符</span></pre></td></tr><tr><td data-num="88"></td><td><pre>        <span class="token keyword">if</span> max_len <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">></span> max_len<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="89"></td><td><pre>            sentence <span class="token operator">=</span> sentence<span class="token punctuation">[</span><span class="token punctuation">:</span>max_len<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="90"></td><td><pre>      </pre></td></tr><tr><td data-num="91"></td><td><pre>        <span class="token comment"># 将字符转换为数字</span></pre></td></tr><tr><td data-num="92"></td><td><pre>        <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="93"></td><td><pre>            r<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>to_index<span class="token punctuation">(</span>word<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="94"></td><td><pre>      </pre></td></tr><tr><td data-num="95"></td><td><pre>        <span class="token comment"># 将列表转换为向量</span></pre></td></tr><tr><td data-num="96"></td><td><pre>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>r<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="97"></td><td><pre></pre></td></tr><tr><td data-num="98"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">inverse_transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="99"></td><td><pre>        <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="100"></td><td><pre>        实现从数组 转化为文字</pre></td></tr><tr><td data-num="101"></td><td><pre>        :param indices: [1,2,3....]</pre></td></tr><tr><td data-num="102"></td><td><pre>        :return:[word1,word2.....]</pre></td></tr><tr><td data-num="103"></td><td><pre>        """</pre></td></tr><tr><td data-num="104"></td><td><pre>        sentence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="105"></td><td><pre>        <span class="token keyword">for</span> i <span class="token keyword">in</span> indices<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="106"></td><td><pre>            word <span class="token operator">=</span> self<span class="token punctuation">.</span>to_word<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="107"></td><td><pre>            sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="108"></td><td><pre>        <span class="token keyword">return</span> sentence</pre></td></tr><tr><td data-num="109"></td><td><pre></pre></td></tr><tr><td data-num="110"></td><td><pre></pre></td></tr><tr><td data-num="111"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="112"></td><td><pre>    w2s <span class="token operator">=</span> Word2Sequence<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="113"></td><td><pre></pre></td></tr><tr><td data-num="114"></td><td><pre>    w2s<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="115"></td><td><pre>        <span class="token punctuation">[</span><span class="token string">"你"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">,</span> <span class="token string">"么"</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="116"></td><td><pre>        <span class="token punctuation">[</span><span class="token string">"你"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">,</span> <span class="token string">"哦"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="117"></td><td><pre></pre></td></tr><tr><td data-num="118"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>w2s<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="119"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>w2s<span class="token punctuation">.</span>fited<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="120"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>w2s<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"你"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">,</span> <span class="token string">"嘛"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="121"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>w2s<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"你好嘛"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_len<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>完成了 <code>wordsequence</code> 之后，接下来就是保存现有样本中的数据字典，方便后续的使用。</p><p>实现对 IMDB 数据的处理和保存</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#1. 对 IMDB 的数据记性 fit 操作</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">def</span> <span class="token function">fit_save_word_sequence</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">from</span> wordSequence <span class="token keyword">import</span> Word2Sequence</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>    ws <span class="token operator">=</span> Word2Sequence<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    train_path <span class="token operator">=</span> <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_base_path<span class="token punctuation">,</span>i<span class="token punctuation">)</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"train/neg"</span><span class="token punctuation">,</span><span class="token string">"train/pos"</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    total_file_path_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> train_path<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        total_file_path_list<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j<span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">for</span> cur_path <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>total_file_path_list<span class="token punctuation">,</span><span class="token builtin">ascii</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>desc<span class="token operator">=</span><span class="token string">"fitting"</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        ws<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>tokenize<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span>cur_path<span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    ws<span class="token punctuation">.</span>build_vocab<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment"># 对 wordSequesnce 进行保存</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>ws<span class="token punctuation">,</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"./model/ws.pkl"</span><span class="token punctuation">,</span><span class="token string">"wb"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token comment">#2. 在 dataset 中使用 wordsequence</span></pre></td></tr><tr><td data-num="17"></td><td><pre>ws <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"./model/ws.pkl"</span><span class="token punctuation">,</span><span class="token string">"rb"</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    MAX_LEN <span class="token operator">=</span> <span class="token number">500</span> </pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token comment">#MAX_LEN = max ([len (i) for i in texts]) #取当前 batch 的最大值作为 batch 的最大长度</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    batch <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    labes <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>    texts <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment">#获取每个文本的长度</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    lengths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token operator">&lt;</span>MAX_LEN <span class="token keyword">else</span> MAX_LEN <span class="token keyword">for</span> i <span class="token keyword">in</span> texts<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    texts <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>ws<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>i<span class="token punctuation">,</span> MAX_LEN<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> texts<span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">del</span> batch</pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">return</span> labes<span class="token punctuation">,</span>texts<span class="token punctuation">,</span>lengths</pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre><span class="token comment">#3. 获取输出</span></pre></td></tr><tr><td data-num="34"></td><td><pre>dataset <span class="token operator">=</span> ImdbDataset<span class="token punctuation">(</span>ws<span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span>text<span class="token punctuation">,</span>length<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"idx："</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"table:"</span><span class="token punctuation">,</span>label<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"text:"</span><span class="token punctuation">,</span>text<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"length:"</span><span class="token punctuation">,</span>length<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token keyword">break</span></pre></td></tr></table></figure><p>输出如下</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>idx： <span class="token number">0</span></pre></td></tr><tr><td data-num="2"></td><td><pre>table<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>         <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>text<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">50983</span><span class="token punctuation">,</span>  <span class="token number">77480</span><span class="token punctuation">,</span>  <span class="token number">82366</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token punctuation">[</span> <span class="token number">54702</span><span class="token punctuation">,</span>  <span class="token number">57262</span><span class="token punctuation">,</span> <span class="token number">102035</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">80474</span><span class="token punctuation">,</span>  <span class="token number">56457</span><span class="token punctuation">,</span>  <span class="token number">63180</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token punctuation">[</span> <span class="token number">26991</span><span class="token punctuation">,</span>  <span class="token number">57693</span><span class="token punctuation">,</span>  <span class="token number">88450</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token punctuation">[</span> <span class="token number">51138</span><span class="token punctuation">,</span>  <span class="token number">73263</span><span class="token punctuation">,</span>  <span class="token number">80428</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token punctuation">[</span>  <span class="token number">7022</span><span class="token punctuation">,</span>  <span class="token number">78114</span><span class="token punctuation">,</span>  <span class="token number">83498</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token punctuation">[</span>  <span class="token number">5353</span><span class="token punctuation">,</span> <span class="token number">101803</span><span class="token punctuation">,</span>  <span class="token number">99148</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>length<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">296</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">132</span><span class="token punctuation">,</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">407</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">130</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">217</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">322</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">156</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">270</span><span class="token punctuation">,</span> <span class="token number">317</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">379</span><span class="token punctuation">]</span></pre></td></tr></table></figure><blockquote><p>思考：前面我们自定义了 MAX_LEN 作为句子的最大长度，如果我们需要把每个 batch 中的最长的句子长度作为当前 batch 的最大长度，该如何实现？</p></blockquote><h2 id="4-构建模型"><a class="anchor" href="#4-构建模型">#</a> 4. 构建模型</h2><p>这里我们只练习使用 word embedding，所以模型只有一层，即：</p><ol><li>数据经过 word embedding</li><li>数据通过全连接层返回结果，计算 <code>log_softmax</code></li></ol><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> optim</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> build_dataset <span class="token keyword">import</span> get_dataloader<span class="token punctuation">,</span>ws<span class="token punctuation">,</span>MAX_LEN</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">IMDBModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>max_len<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>IMDBModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ws<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span>padding_idx<span class="token operator">=</span>ws<span class="token punctuation">.</span>PAD<span class="token punctuation">)</span> <span class="token comment">#[N,300]</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>max_len<span class="token operator">*</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment">#[max_len*300,10]</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment">#[batch_size,max_len,300]</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        embed <span class="token operator">=</span> embed<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>embed<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="5-模型的训练和评估"><a class="anchor" href="#5-模型的训练和评估">#</a> 5. 模型的训练和评估</h2><p>训练流程和之前相同</p><ol><li>实例化模型，损失函数，优化器</li><li>遍历 dataset_loader，梯度置为 0，进行向前计算</li><li>计算损失，反向传播优化损失，更新参数</li></ol><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>train_batch_size <span class="token operator">=</span> <span class="token number">128</span></pre></td></tr><tr><td data-num="2"></td><td><pre>test_batch_size <span class="token operator">=</span> <span class="token number">1000</span></pre></td></tr><tr><td data-num="3"></td><td><pre>imdb_model <span class="token operator">=</span> IMDBModel<span class="token punctuation">(</span>MAX_LEN<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>imdb_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    mode <span class="token operator">=</span> <span class="token boolean">True</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    imdb_model<span class="token punctuation">.</span>train<span class="token punctuation">(</span>mode<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    train_dataloader <span class="token operator">=</span>get_dataloader<span class="token punctuation">(</span>mode<span class="token punctuation">,</span>train_batch_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>target<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">,</span>input_lenght<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        output <span class="token operator">=</span> imdb_model<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span> <span class="token comment">#traget 需要是 [0,9]，不能是 [1-10]</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        <span class="token keyword">if</span> idx <span class="token operator">%</span><span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="18"></td><td><pre>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                epoch<span class="token punctuation">,</span> idx <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="20"></td><td><pre>                       <span class="token number">100.</span> <span class="token operator">*</span> idx <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>imdb_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"model/mnist_net.pkl"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model/mnist_optimizer.pkl'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>          </pre></td></tr><tr><td data-num="25"></td><td><pre> <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    test_loss <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    correct <span class="token operator">=</span> <span class="token number">0</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    mode <span class="token operator">=</span> <span class="token boolean">False</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    imdb_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    test_dataloader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>mode<span class="token punctuation">,</span> test_batch_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token keyword">for</span> target<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> input_lenght <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="33"></td><td><pre>            output <span class="token operator">=</span> imdb_model<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>            test_loss  <span class="token operator">+=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">,</span>reduction<span class="token operator">=</span><span class="token string">"sum"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>            pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="36"></td><td><pre>            correct <span class="token operator">=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        test_loss <span class="token operator">=</span> test_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="39"></td><td><pre>            test_loss<span class="token punctuation">,</span> correct<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="40"></td><td><pre>            <span class="token number">100.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre></pre></td></tr><tr><td data-num="42"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    test<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        train<span class="token punctuation">(</span>i<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        test<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>这里我们仅仅使用了一层全连接层，其分类效果不会很好，这里重点是理解常见的模型流程和 word embedding 的使用方法</p><div class="tags"><a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" rel="tag"><i class="ic i-tag"></i> 自然语言处理</a> <a href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="ic i-tag"></i> 循环神经网络</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-11-12 18:52:57" itemprop="dateModified" datetime="2022-11-12T18:52:57+08:00">2022-11-12</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/08/05/ai/nlp/base/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" title="文本情感分类">https://jyuanhust.github.io/2022/08/05/ai/nlp/base/文本情感分类/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/08/05/frontend/vue/vue%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80-%E4%B8%8B/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(65).webp" title="vue组件基础(下)"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> vue</span><h3>vue组件基础(下)</h3></a></div><div class="item right"><a href="/2022/08/05/ai/nlp/base/Summarization-huggingface/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(16).webp" title="Summarization - huggingface"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> nlp</span><h3>Summarization - huggingface</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">文本情感分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87"><span class="toc-number">1.1.</span> <span class="toc-text">目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A1%88%E4%BE%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">1. 案例介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%80%9D%E8%B7%AF%E5%88%86%E6%9E%90"><span class="toc-number">1.3.</span> <span class="toc-text">2. 思路分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.4.</span> <span class="toc-text">3. 准备数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E5%9F%BA%E7%A1%80dataset%E7%9A%84%E5%87%86%E5%A4%87"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 基础 Dataset 的准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E6%96%87%E6%9C%AC%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 文本序列化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.</span> <span class="toc-text">4. 构建模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0"><span class="toc-number">1.6.</span> <span class="toc-text">5. 模型的训练和评估</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/07/25/ai/nlp/base/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" rel="bookmark" title="循环神经网络基础">循环神经网络基础</a></li><li class="active"><a href="/2022/08/05/ai/nlp/base/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" rel="bookmark" title="文本情感分类">文本情感分类</a></li><li><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" rel="bookmark" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系">PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系</a></li><li><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" rel="bookmark" title="pytorch中LSTM的output和hidden关系">pytorch中LSTM的output和hidden关系</a></li><li><a href="/2022/08/25/ai/nlp/base/transformer/" rel="bookmark" title="transformer">transformer</a></li><li><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" rel="bookmark" title="Subword算法">Subword算法</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/08/05/frontend/vue/vue%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80-%E4%B8%8B/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/08/05/ai/nlp/base/Summarization-huggingface/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/django/" title="分类于 django">django</a></div><span><a href="/2022/08/25/backend/django/%E5%91%98%E5%B7%A5%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F-django/" title="员工管理系统-django">员工管理系统-django</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-optimization/" title="分类于 chapter_optimization">chapter_optimization</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_optimization/adadelta/" title="adadelta">adadelta</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AE%9E%E8%B7%B5MySQL/%E5%AE%9E%E8%AE%AD13-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/" title="分类于 huggingface">huggingface</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81nlp%E4%BB%BB%E5%8A%A1/" title="分类于 主要nlp任务">主要nlp任务</a></div><span><a href="/2022/11/12/ai/nlp/huggingface/%E4%B8%BB%E8%A6%81%E7%9A%84%20NLP%20%E4%BB%BB%E5%8A%A1/%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%8E%A9%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" title="微调一个掩码语言模型">微调一个掩码语言模型</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/django/" title="分类于 django">django</a></div><span><a href="/2022/07/24/backend/django/django/" title="初识django">初识django</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/08/26/frontend/vue/vuex/" title="vuex">vuex</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/09/11/frontend/vue/Less/" title="Less">Less</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E5%A7%BF%E6%80%81%E6%A3%80%E6%B5%8B/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-recurrent-neural-networks/" title="分类于 chapter_recurrent-neural-networks">chapter_recurrent-neural-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_recurrent-neural-networks/sequence/" title="sequence">sequence</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/08/05/ai/nlp/base/文本情感分类/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>