<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="计算机视觉"><link rel="canonical" href="https://jyuanhust.github.io/2022/08/25/ai/cv/MobileNet/"><title>MobileNet - cv - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">MobileNet</h1><div class="meta"><span class="item" title="创建时间：2022-08-25 12:02:08"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-08-25T12:02:08+08:00">2022-08-25</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>2.6k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>2 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(86).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(60).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(85).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(53).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(68).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(97).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="分类于 ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/cv/" itemprop="item" rel="index" title="分类于 cv"><span itemprop="name">cv</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://jyuanhust.github.io/2022/08/25/ai/cv/MobileNet/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h2 id="各层位置关系"><a class="anchor" href="#各层位置关系">#</a> 各层位置关系</h2><p><img data-src="/./images/cv/1660045681034.png" alt="1660045681034"></p><p>卷积核可以表示成一种特殊的多元线性回归的权重矩阵；由于权重矩阵有大量的参数是一样的，且有大量的 <strong>0</strong> ，所以可以把权重矩阵的系数都压缩到一个卷积核中又不损失信息。卷积的这种数学操作的特点又保留了图片的空间信息，所以卷积是一种开销小于全连接层，但效果较好的操作。</p><p><strong>所以在神经网络学习参数中，可以把对卷积核的拟合视为一种对神经元权重的拟合，只是神经元之间会以某种方式连接并且共享大量参数。</strong></p><p>也可以很自然的推导出，如果没有<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3NlYXJjaD9xPSVFNiVCMSVBMCVFNSU4QyU5NiVFNSVCMSU4MiZhbXA7c2VhcmNoX3NvdXJjZT1FbnRpdHkmYW1wO2h5YnJpZF9zZWFyY2hfc291cmNlPUVudGl0eSZhbXA7aHlicmlkX3NlYXJjaF9leHRyYT0lN0IlMjJzb3VyY2VUeXBlJTIyJTNBJTIyYW5zd2VyJTIyJTJDJTIyc291cmNlSWQlMjIlM0EyMTU4ODA2MjkwJTdE">池化层</span>等非线性操作， <strong>那么多层卷积就等同于一层卷积</strong> ，只靠卷积操作无法拟合任意函数</p><h2 id="softmax"><a class="anchor" href="#softmax">#</a> softmax</h2><p><img data-src="/./images/cv/1660098073731.png" alt="1660098073731"></p><p><img data-src="/./images/cv/1660098331823.png" alt="1660098331823"></p><p><img data-src="/./images/cv/1660098649824.png" alt="1660098649824"></p><p><img data-src="/./images/cv/1660098696108.png" alt="1660098696108"></p><p><img data-src="/./images/cv/1660098731893.png" alt="1660098731893"></p><p>交叉熵：计算出来的概率和标签中的值进行交叉熵运算，数值越大代表两种概率模型的相差大</p><p><img data-src="/./images/cv/1660099048865.png" alt="1660099048865"></p><h2 id="交叉熵"><a class="anchor" href="#交叉熵">#</a> 交叉熵</h2><p><img data-src="/./images/cv/1660099705213.png" alt="1660099705213"></p><p><img data-src="/./images/cv/1660099734716.png" alt="1660099734716"></p><p>如果某个类别的预测概率为 1，则由对数函数可知，loss 得到的结果为 0</p><p><strong>回顾极大似然估计</strong></p><p><img data-src="/./images/cv/1660099879880.png" alt="1660099879880"></p><p><img data-src="/./images/cv/1660099929311.png" alt="1660099929311"></p><p>在样本上预测正确的概率，n 为样本量，因为是独立抽样，使用乘积</p><p><img data-src="/./images/cv/1660100071771.png" alt="1660100071771"></p><p>取对数加负号得到交叉熵损失函数</p><p><img data-src="/./images/cv/1660100159232.png" alt="1660100159232"></p><p>一个系统的信息熵是对这个系统平均编码的最小长度</p><h2 id="信息量和信息熵"><a class="anchor" href="#信息量和信息熵">#</a> 信息量和信息熵</h2><p>信息的作用是消除不确定性</p><p>信息量：字字珠玑，废话连篇</p><p>信息量和它能消除的不确定性有关</p><h2 id="resnet"><a class="anchor" href="#resnet">#</a> ResNet</h2><p>每次更复杂的模型都是包含前面的小模型的</p><p><img data-src="/./images/cv/1660038487976.png" alt="1660038487976"></p><p>通过相加的形式来增加层数</p><p><img data-src="/./images/cv/1660039171985.png" alt="1660039171985"></p><p>Weight layer 为卷积层</p><p><img data-src="/./images/cv/1660041646946.png" alt="1660041646946"></p><p>右边的加入 <code>1x1</code> 的卷积层是要将 x 变为合适的通道数才能加得上去。</p><p><img data-src="/./images/cv/1660041986597.png" alt="1660041986597"></p><p>ResNet 最核心的是横着加过去的部分</p><p><img data-src="/./images/cv/1660042373930.png" alt="1660042373930"></p><p><img data-src="/./images/cv/1660042402196.png" alt="1660042402196"></p><h1 id="使用torchvisionmodels"><a class="anchor" href="#使用torchvisionmodels">#</a> 使用 torchvision.models</h1><h3 id="分类模型"><a class="anchor" href="#分类模型">#</a> 分类模型</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>io <span class="token keyword">import</span> read_image</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">import</span> resnet50<span class="token punctuation">,</span> ResNet50_Weights</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># img 即为 tensor 类型了，torch.Size ([3, 1440, 1920])，但是数据的大小是图片自身的，没有归一到 [0,1] 上</span></pre></td></tr><tr><td data-num="5"></td><td><pre>img <span class="token operator">=</span> read_image<span class="token punctuation">(</span><span class="token string">r"D:\Projects\pytorch-learn\Test6_mobilenet\images\falari.jpg"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># Step 1: Initialize model with the best available weights</span></pre></td></tr><tr><td data-num="9"></td><td><pre>weights <span class="token operator">=</span> ResNet50_Weights<span class="token punctuation">.</span>DEFAULT  <span class="token comment"># 使用最佳权重</span></pre></td></tr><tr><td data-num="10"></td><td><pre>model <span class="token operator">=</span> resnet50<span class="token punctuation">(</span>weights<span class="token operator">=</span>weights<span class="token punctuation">)</span>  <span class="token comment"># 实例化模型，并使用预训练的参数</span></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 设置模型的预测模式，输入数据计算时不会改变梯度等参数</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment"># Step 2: Initialize the inference transforms</span></pre></td></tr><tr><td data-num="15"></td><td><pre>preprocess <span class="token operator">=</span> weights<span class="token punctuation">.</span>transforms<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 实例化推理变换</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># Step 3: Apply inference preprocessing transforms</span></pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token comment"># preprocess (img) # 对图片的 w 和 h 进行变换，使得能够输入网络中进行处理</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment"># unsqueeze (0), 在第一维度处插入一维，因为要向网络中插入 4 维的</span></pre></td></tr><tr><td data-num="20"></td><td><pre>batch <span class="token operator">=</span> preprocess<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment"># Step 4: Use the model and print the predicted category</span></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token comment"># model (batch)  得到 torch.Size ([1, 1000])</span></pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token comment"># squeeze (0) 去掉第一维</span></pre></td></tr><tr><td data-num="25"></td><td><pre>prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>class_id <span class="token operator">=</span> prediction<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># argmax () 返回的是 Tensor，使用 item () 取出其中的值</span></pre></td></tr><tr><td data-num="28"></td><td><pre>score <span class="token operator">=</span> prediction<span class="token punctuation">[</span>class_id<span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>category_name <span class="token operator">=</span> weights<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">"categories"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>class_id<span class="token punctuation">]</span>  <span class="token comment"># 获得分类的名字</span></pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>category_name<span class="token punctuation">&#125;</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token number">100</span> <span class="token operator">*</span> score<span class="token punctuation">:</span><span class="token format-spec">.1f</span><span class="token punctuation">&#125;</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><h1 id="mobilenet-v1"><a class="anchor" href="#mobilenet-v1">#</a> MobileNet v1</h1><h2 id="传统卷积"><a class="anchor" href="#传统卷积">#</a> 传统卷积</h2><p>传统的卷积：一个卷积核生成一个 feature map（二维），</p><p>卷积核的深度和图像的通道数相同，相乘再相加。</p><p><img data-src="/./images/cv/1660042906334.png" alt="1660042906334"></p><p><img data-src="/./images/cv/1660043015623.png" alt="1660043015623"></p><h2 id="深度可分离卷积"><a class="anchor" href="#深度可分离卷积">#</a> 深度可分离卷积</h2><p><img data-src="/./images/cv/1660043121106.png" alt="1660043121106"></p><p>每一个通道用单独的卷积核（二维）进行处理，此时无法再捕捉跨通道的信息了。所以再使用 <code>1x1</code> 的卷积核处理跨通道的信息。</p><p>DW：处理长宽方向的信息</p><p>PW：处理跨通道的信息</p><p><img data-src="/./images/cv/1660043892060.png" alt="1660043892060"></p><p><img data-src="/./images/cv/1660044046477.png" alt="1660044046477"></p><p><img data-src="/./images/cv/1660044105829.png" alt="1660044105829"></p><p><img data-src="/./images/cv/1660044388159.png" alt="1660044388159"></p><h2 id="mobile-net-v2"><a class="anchor" href="#mobile-net-v2">#</a> Mobile Net v2</h2><p><img data-src="/./images/cv/1660044593712.png" alt="1660044593712"></p><p><img data-src="/./images/cv/1660045025103.png" alt="1660045025103">short cut 连接为残差连接，左边连接的是两个低维的</p><p>因为使用了下采样，导致，所以不用残差连接了</p><p><img data-src="/./images/cv/1660048881841.png" alt="1660048881841"></p><p><img data-src="/./images/cv/1660046371150.png" alt="1660046371150"></p><p>在降维时用的线性激活函数</p><p><img data-src="/./images/cv/1660046644022.png" alt="1660046644022"></p><p><img data-src="/./images/cv/1660046713820.png" alt="1660046713820"></p><p><img data-src="/./images/cv/1660047018815.png" alt="1660047018815"></p><p><img data-src="/./images/cv/1660047037900.png" alt="1660047037900"></p><p><img data-src="/./images/cv/1660047264047.png" alt="1660047264047"></p><p><img data-src="/./images/cv/1660047592878.png" alt="1660047592878"></p><p><img data-src="/./images/cv/1660047605836.png" alt="1660047605836"></p><h3 id="升维的数学原理"><a class="anchor" href="#升维的数学原理">#</a> 升维的数学原理</h3><p><img data-src="/./images/cv/1660047986833.png" alt="1660047986833"></p><p><img data-src="/./images/cv/1660048059298.png" alt="1660048059298"></p><p><img data-src="/./images/cv/1660048095748.png" alt="1660048095748"></p><h2 id="yolov1"><a class="anchor" href="#yolov1">#</a> yolov1</h2><h3 id="预测阶段"><a class="anchor" href="#预测阶段">#</a> 预测阶段</h3><p><img data-src="/./images/cv/1660219334005.png" alt="1660219334005"></p><p><img data-src="/./images/cv/1660217214003.png" alt="1660217214003"></p><p>最后的 7x7x30 的张量中，包含了所有预测框的坐标，置信度和类别结果。只要解析这个张量就可以获得结果了。</p><p><img data-src="/./images/cv/1660217325716.png" alt="1660217325716"></p><p>在 yolov1 中 s=7，bounding box 为预测框，只要预测框的中心点落在 grid cell 里，那么久说明这个 bounding box 是有这个 grid cell 生成的。</p><p>每个 bounding box 的置信度 * 类别的条件概率就能获得 bounding box 各类别的概率。</p><p><img data-src="/./images/cv/1660218218001.png" alt="1660218218001"></p><p>在假设包含猫的时候是猫的概率... 所以是条件概率，所以每个 bounding box 的置信度 * 类别的条件概率就能获得 bounding box 各类别的概率。</p><p><img data-src="/./images/cv/1660218407522.png" alt="1660218407522"></p><p><img data-src="/./images/cv/1660218771008.png" alt="1660218771008"></p><p><img data-src="/./images/cv/1660218893783.png" alt="1660218893783"></p><p><img data-src="/./images/cv/1660218904347.png" alt="1660218904347"></p><p><img data-src="/./images/cv/1660218986180.png" alt="1660218986180"></p><p>上图中的下面的两个框的置信度就比较低</p><p>下面展示了条件概率最高的那些类别所占有的框</p><p><img data-src="/./images/cv/1660219072051.png" alt="1660219072051"></p><p>选择概率高的，每个 grid cell 只能有一个类别，即只能预测出一个物体。这也是 yolov1 小目标和密集目标识别性能差的原因。</p><p><img data-src="/./images/cv/1660219237845.png" alt="1660219237845"></p><p><img data-src="/./images/cv/1660219286666.png" alt="1660219286666"></p><h3 id="预测阶段-后处理"><a class="anchor" href="#预测阶段-后处理">#</a> 预测阶段 后处理</h3><p><img data-src="/./images/cv/1660219423729.png" alt="1660219423729"></p><p>把预测框筛选、过滤，把重复的预测框只保留一个，过滤掉低置信度的框，</p><p><img data-src="/./images/cv/1660219643385.png" alt="1660219643385"></p><p><img data-src="/./images/cv/1660219661036.png" alt="1660219661036"></p><p><img data-src="/./images/cv/1660219690669.png" alt="1660219690669"></p><p><img data-src="/./images/cv/1660219728520.png" alt="1660219728520"></p><p><img data-src="/./images/cv/1660219753235.png" alt="1660219753235"></p><p><img data-src="/./images/cv/1660219776433.png" alt="1660219776433"></p><p><img data-src="/./images/cv/1660219861031.png" alt="1660219861031"></p><p>先按置信度大小进行排序</p><p><img data-src="/./images/cv/1660219998825.png" alt="1660219998825"></p><p><img data-src="/./images/cv/1660220016203.png" alt="1660220016203"></p><p><img data-src="/./images/cv/1660220037518.png" alt="1660220037518"></p><p>交并比大于一定的阈值，认为是在识别同一个物体。</p><p><img data-src="/./images/cv/1660220080842.png" alt="1660220080842"></p><p><img data-src="/./images/cv/1660220100506.png" alt="1660220100506"></p><p><img data-src="/./images/cv/1660220208626.png" alt="1660220208626"></p><p><img data-src="/./images/cv/1660220228650.png" alt="1660220228650"></p><p><img data-src="/./images/cv/1660220243937.png" alt="1660220243937"></p><p><img data-src="/./images/cv/1660220296801.png" alt="1660220296801"></p><p><img data-src="/./images/cv/1660220304301.png" alt="1660220304301"></p><p><img data-src="/./images/cv/1660220311777.png" alt="1660220311777"></p><p><img data-src="/./images/cv/1660220329609.png" alt="1660220329609"></p><p><img data-src="/./images/cv/1660220352990.png" alt="1660220352990"></p><p>注意：后处理只是针对预测阶段，在训练阶段是不需要进行 nms 的，因为每个框都要在损失函数中占据一席之地</p><h3 id="训练阶段反向传播"><a class="anchor" href="#训练阶段反向传播">#</a> 训练阶段（反向传播）</h3><p><img data-src="/./images/cv/1660220529417.png" alt="1660220529417"></p><p>在训练集上，已经标注出绿框，而算法就是让预测结果尽量拟合绿框，使得损失函数最小化。而绿框的中心点落在哪个 grid cell 中，就应该由这个 grid cell 预测出来的 bounding box 拟合这个绿框，且类别也要相同（预测的概率最大）。</p><p><img data-src="/./images/cv/1660220725776.png" alt="1660220725776"></p><p>每个 grid cell 都预测出两个 bounding box，由和绿框 IOU 较大的负责拟合。另外的框就打入冷宫了。</p><p>损失函数的设计是让负责拟合物体的预测框和物体真正的框尽可能重合。</p><p><img data-src="/./images/cv/1660220952006.png" alt="1660220952006"></p><p><img data-src="/./images/cv/1660220968311.png" alt="1660220968311"></p><p>如果没有中心点落入 grid cell 中，则它预测出的两个框都被打入冷宫。让它们的置信度越小越好。</p><p><img data-src="/./images/cv/1660221122631.png" alt="1660221122631"></p><p>把目标检测问题当做回归问题解决。</p><pre><code class="language-python">
</code></pre><div class="tags"><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="ic i-tag"></i> 计算机视觉</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-08-30 09:32:52" itemprop="dateModified" datetime="2022-08-30T09:32:52+08:00">2022-08-30</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="yuan 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="yuan 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>本文链接：</strong> <a href="https://jyuanhust.github.io/2022/08/25/ai/cv/MobileNet/" title="MobileNet">https://jyuanhust.github.io/2022/08/25/ai/cv/MobileNet/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/08/25/ai/rl/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(73).webp" title="强化学习"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>强化学习</h3></a></div><div class="item right"><a href="/2022/08/25/ai/nlp/base/transformer/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(11).webp" title="transformer"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> base</span><h3>transformer</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E5%B1%82%E4%BD%8D%E7%BD%AE%E5%85%B3%E7%B3%BB"><span class="toc-number">1.</span> <span class="toc-text">各层位置关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax"><span class="toc-number">2.</span> <span class="toc-text">softmax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="toc-number">3.</span> <span class="toc-text">交叉熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E9%87%8F%E5%92%8C%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="toc-number">4.</span> <span class="toc-text">信息量和信息熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#resnet"><span class="toc-number">5.</span> <span class="toc-text">ResNet</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8torchvisionmodels"><span class="toc-number"></span> <span class="toc-text">使用 torchvision.models</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">0.1.</span> <span class="toc-text">分类模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#mobilenet-v1"><span class="toc-number"></span> <span class="toc-text">MobileNet v1</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.</span> <span class="toc-text">传统卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.</span> <span class="toc-text">深度可分离卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mobile-net-v2"><span class="toc-number">3.</span> <span class="toc-text">Mobile Net v2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%87%E7%BB%B4%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">升维的数学原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#yolov1"><span class="toc-number">4.</span> <span class="toc-text">yolov1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E9%98%B6%E6%AE%B5"><span class="toc-number">4.1.</span> <span class="toc-text">预测阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E9%98%B6%E6%AE%B5-%E5%90%8E%E5%A4%84%E7%90%86"><span class="toc-number">4.2.</span> <span class="toc-text">预测阶段 后处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">4.3.</span> <span class="toc-text">训练阶段（反向传播）</span></a></li></ol></li></ol></li></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2022/07/21/ai/cv/OpenCV%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B/" rel="bookmark" title="OpenCV轮廓检测">OpenCV轮廓检测</a></li><li><a href="/2022/07/21/ai/cv/ncnn%E5%9C%A8window%EF%BC%8Cvs2019%EF%BC%8Ccmake-3-16-5-win64-x64%E7%BC%96%E8%AF%91/" rel="bookmark" title="ncnn在window，vs2019，cmake-3.16.5-win64-x64编译">ncnn在window，vs2019，cmake-3.16.5-win64-x64编译</a></li><li><a href="/2022/07/21/ai/cv/OpenCV%E6%95%99%E7%A8%8B/" rel="bookmark" title="OpenCV教程">OpenCV教程</a></li><li><a href="/2022/07/22/ai/cv/ncnn%E5%92%8Copencv%E5%9C%A8vs2022%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B/" rel="bookmark" title="ncnn和opencv在vs2022上创建工程推理示例">ncnn和opencv在vs2022上创建工程推理示例</a></li><li><a href="/2022/08/24/ai/cv/face-alignment%EF%BC%9Aface-alignment%E5%BA%93%E7%9A%84%E7%AE%80%E4%BB%8B%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" rel="bookmark" title="face_alignment：face_alignment库的简介、安装、使用方法">face_alignment：face_alignment库的简介、安装、使用方法</a></li><li><a href="/2022/08/24/ai/cv/%E7%AE%80%E5%8D%95%E8%AE%A1%E7%AE%97%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE/" rel="bookmark" title="简单计算图片数据集的均值和方差">简单计算图片数据集的均值和方差</a></li><li><a href="/2022/08/25/ai/cv/GAN/" rel="bookmark" title="GAN">GAN</a></li><li class="active"><a href="/2022/08/25/ai/cv/MobileNet/" rel="bookmark" title="MobileNet">MobileNet</a></li><li><a href="/2022/08/25/ai/cv/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" rel="bookmark" title="语义分割">语义分割</a></li><li><a href="/2022/09/07/ai/cv/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" rel="bookmark" title="图像分类">图像分类</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/08/25/ai/rl/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/08/25/ai/nlp/base/transformer/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/algorithm/leetCode/3-%E7%8E%A9%E8%BD%AC%E5%8F%8C%E6%8C%87%E9%92%88/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" title="分类于 chapter_deep-learning-computation">chapter_deep-learning-computation</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/model-construction/" title="model-construction">model-construction</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-applications/" title="分类于 chapter_natural-language-processing-applications">chapter_natural-language-processing-applications</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-applications/natural-language-inference-attention/" title="natural-language-inference-attention">natural-language-inference-attention</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-appendix-tools-for-deep-learning/" title="分类于 chapter_appendix-tools-for-deep-learning">chapter_appendix-tools-for-deep-learning</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_appendix-tools-for-deep-learning/index/" title="index">index</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2024/01/16/computer-science/algorithm/hot100/%E5%8F%8C%E6%8C%87%E9%92%88/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tools/" title="分类于 tools">tools</a></div><span><a href="/2022/07/26/tools/%E9%85%B7%E7%8B%97%E9%9F%B3%E4%B9%90kgm%E6%A0%BC%E5%BC%8F%E8%BD%ACmp3%E6%A0%BC%E5%BC%8F/" title="酷狗音乐kgm格式转mp3格式">酷狗音乐kgm格式转mp3格式</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="分类于 cv">cv</a></div><span><a href="/2022/07/21/ai/cv/ncnn%E5%9C%A8window%EF%BC%8Cvs2019%EF%BC%8Ccmake-3-16-5-win64-x64%E7%BC%96%E8%AF%91/" title="ncnn在window，vs2019，cmake-3.16.5-win64-x64编译">ncnn在window，vs2019，cmake-3.16.5-win64-x64编译</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-recurrent-neural-networks/" title="分类于 chapter_recurrent-neural-networks">chapter_recurrent-neural-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_recurrent-neural-networks/index/" title="index">index</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computational-performance/" title="分类于 chapter_computational-performance">chapter_computational-performance</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/multiple-gpus/" title="multiple-gpus">multiple-gpus</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/08/25/ai/cv/MobileNet/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>