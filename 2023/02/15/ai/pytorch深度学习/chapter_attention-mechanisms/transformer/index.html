<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://huang-junyuan.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://huang-junyuan.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://huang-junyuan.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="chapter_attention-mechanisms"><link rel="canonical" href="https://huang-junyuan.github.io/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/transformer/"><title>transformer - chapter_attention-mechanisms - pytorchæ·±åº¦å­¦ä¹  - ai | Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">transformer</h1><div class="meta"><span class="item" title="åˆ›å»ºæ—¶é—´ï¼š2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">å‘è¡¨äº</span> <time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="æœ¬æ–‡å­—æ•°"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">æœ¬æ–‡å­—æ•°</span> <span>13k</span> <span class="text">å­—</span> </span><span class="item" title="é˜…è¯»æ—¶é•¿"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">é˜…è¯»æ—¶é•¿</span> <span>12 åˆ†é’Ÿ</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="åˆ‡æ¢å¯¼èˆªæ "><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(93).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(69).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(85).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(82).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(26).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(95).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">é¦–é¡µ</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/" itemprop="item" rel="index" title="åˆ†ç±»äº ai"><span itemprop="name">ai</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="item" rel="index" title="åˆ†ç±»äº pytorchæ·±åº¦å­¦ä¹ "><span itemprop="name">pytorchæ·±åº¦å­¦ä¹ </span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-attention-mechanisms/" itemprop="item" rel="index" title="åˆ†ç±»äº chapter_attention-mechanisms"><span itemprop="name">chapter_attention-mechanisms</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://huang-junyuan.github.io/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/transformer/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="yuan"><meta itemprop="description" content="Whatever is worth doing at all is worth doing well, "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="yuan"></span><div class="body md" itemprop="articleBody"><h1 id="transformer"><a class="anchor" href="#transformer">#</a> Transformer</h1><p>ğŸ· <code>sec_transformer</code></p><p>:numref: <code>subsec_cnn-rnn-self-attention</code> ä¸­æ¯”è¾ƒäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œè‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè‡ªæ³¨æ„åŠ›åŒæ—¶å…·æœ‰å¹¶è¡Œè®¡ç®—å’Œæœ€çŸ­çš„æœ€å¤§è·¯å¾„é•¿åº¦è¿™ä¸¤ä¸ªä¼˜åŠ¿ã€‚å› æ­¤ï¼Œä½¿ç”¨è‡ªæ³¨æ„åŠ›æ¥è®¾è®¡æ·±åº¦æ¶æ„æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ã€‚å¯¹æ¯”ä¹‹å‰ä»ç„¶ä¾èµ–å¾ªç¯ç¥ç»ç½‘ç»œå®ç°è¾“å…¥è¡¨ç¤ºçš„è‡ªæ³¨æ„åŠ›æ¨¡å‹ :cite: <code>Cheng.Dong.Lapata.2016,Lin.Feng.Santos.ea.2017,Paulus.Xiong.Socher.2017</code> ï¼ŒTransformer æ¨¡å‹å®Œå…¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ²¡æœ‰ä»»ä½•å·ç§¯å±‚æˆ–å¾ªç¯ç¥ç»ç½‘ç»œå±‚ :cite: <code>Vaswani.Shazeer.Parmar.ea.2017</code> ã€‚å°½ç®¡ Transformer æœ€åˆæ˜¯åº”ç”¨äºåœ¨æ–‡æœ¬æ•°æ®ä¸Šçš„åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼Œä½†ç°åœ¨å·²ç»æ¨å¹¿åˆ°å„ç§ç°ä»£çš„æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¾‹å¦‚è¯­è¨€ã€è§†è§‰ã€è¯­éŸ³å’Œå¼ºåŒ–å­¦ä¹ é¢†åŸŸã€‚</p><h2 id="æ¨¡å‹"><a class="anchor" href="#æ¨¡å‹">#</a> æ¨¡å‹</h2><p>Transformer ä½œä¸ºç¼–ç å™¨ï¼è§£ç å™¨æ¶æ„çš„ä¸€ä¸ªå®ä¾‹ï¼Œå…¶æ•´ä½“æ¶æ„å›¾åœ¨ :numref: <code>fig_transformer</code> ä¸­å±•ç¤ºã€‚æ­£å¦‚æ‰€è§åˆ°çš„ï¼ŒTransformer æ˜¯ç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆçš„ã€‚ä¸ :numref: <code>fig_s2s_attention_details</code> ä¸­åŸºäº Bahdanau æ³¨æ„åŠ›å®ç°çš„åºåˆ—åˆ°åºåˆ—çš„å­¦ä¹ ç›¸æ¯”ï¼ŒTransformer çš„ç¼–ç å™¨å’Œè§£ç å™¨æ˜¯åŸºäºè‡ªæ³¨æ„åŠ›çš„æ¨¡å—å åŠ è€Œæˆçš„ï¼Œæºï¼ˆè¾“å…¥ï¼‰åºåˆ—å’Œç›®æ ‡ï¼ˆè¾“å‡ºï¼‰åºåˆ—çš„<em>åµŒå…¥</em>ï¼ˆembeddingï¼‰è¡¨ç¤ºå°†åŠ ä¸Š<em>ä½ç½®ç¼–ç </em>ï¼ˆpositional encodingï¼‰ï¼Œå†åˆ†åˆ«è¾“å…¥åˆ°ç¼–ç å™¨å’Œè§£ç å™¨ä¸­ã€‚</p><p><img data-src="/./images/transformer.svg" alt="transformeræ¶æ„"><br>:width: <code>500px</code><br>ğŸ· <code>fig_transformer</code></p><p>å›¾ :numref: <code>fig_transformer</code> ä¸­æ¦‚è¿°äº† Transformer çš„æ¶æ„ã€‚ä»å®è§‚è§’åº¦æ¥çœ‹ï¼ŒTransformer çš„ç¼–ç å™¨æ˜¯ç”±å¤šä¸ªç›¸åŒçš„å±‚å åŠ è€Œæˆçš„ï¼Œæ¯ä¸ªå±‚éƒ½æœ‰ä¸¤ä¸ªå­å±‚ï¼ˆå­å±‚è¡¨ç¤ºä¸º<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><annotation encoding="application/x-tex">\mathrm{sublayer}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm">u</span><span class="mord mathrm">b</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span></span></span></span></span>ï¼‰ã€‚ç¬¬ä¸€ä¸ªå­å±‚æ˜¯<em>å¤šå¤´è‡ªæ³¨æ„åŠ›</em>ï¼ˆmulti-head self-attentionï¼‰æ±‡èšï¼›ç¬¬äºŒä¸ªå­å±‚æ˜¯<em>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</em>ï¼ˆpositionwise feed-forward networkï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨è®¡ç®—ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›æ—¶ï¼ŒæŸ¥è¯¢ã€é”®å’Œå€¼éƒ½æ¥è‡ªå‰ä¸€ä¸ªç¼–ç å™¨å±‚çš„è¾“å‡ºã€‚å— :numref: <code>sec_resnet</code> ä¸­æ®‹å·®ç½‘ç»œçš„å¯å‘ï¼Œæ¯ä¸ªå­å±‚éƒ½é‡‡ç”¨äº†<em>æ®‹å·®è¿æ¥</em>ï¼ˆresidual connectionï¼‰ã€‚åœ¨ Transformer ä¸­ï¼Œå¯¹äºåºåˆ—ä¸­ä»»ä½•ä½ç½®çš„ä»»ä½•è¾“å…¥<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi><mo>âˆˆ</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{x} \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5782em;vertical-align:-.0391em"></span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>ï¼Œéƒ½è¦æ±‚æ»¡è¶³<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>âˆˆ</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathrm{sublayer}(\mathbf{x}) \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm">u</span><span class="mord mathrm">b</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>ï¼Œä»¥ä¾¿æ®‹å·®è¿æ¥æ»¡è¶³<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi><mo>+</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>âˆˆ</mo><msup><mi mathvariant="double-struck">R</mi><mi>d</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{x} + \mathrm{sublayer}(\mathbf{x}) \in \mathbb{R}^d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathrm">s</span><span class="mord mathrm">u</span><span class="mord mathrm">b</span><span class="mord mathrm">l</span><span class="mord mathrm">a</span><span class="mord mathrm" style="margin-right:.01389em">y</span><span class="mord mathrm">e</span><span class="mord mathrm">r</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span>ã€‚åœ¨æ®‹å·®è¿æ¥çš„åŠ æ³•è®¡ç®—ä¹‹åï¼Œç´§æ¥ç€åº”ç”¨<em>å±‚è§„èŒƒåŒ–</em>ï¼ˆlayer normalizationï¼‰ :cite: <code>Ba.Kiros.Hinton.2016</code> ã€‚å› æ­¤ï¼Œè¾“å…¥åºåˆ—å¯¹åº”çš„æ¯ä¸ªä½ç½®ï¼ŒTransformer ç¼–ç å™¨éƒ½å°†è¾“å‡ºä¸€ä¸ª<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">d</span></span></span></span> ç»´è¡¨ç¤ºå‘é‡ã€‚</p><p>Transformer è§£ç å™¨ä¹Ÿæ˜¯ç”±å¤šä¸ªç›¸åŒçš„å±‚å åŠ è€Œæˆçš„ï¼Œå¹¶ä¸”å±‚ä¸­ä½¿ç”¨äº†æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–ã€‚é™¤äº†ç¼–ç å™¨ä¸­æè¿°çš„ä¸¤ä¸ªå­å±‚ä¹‹å¤–ï¼Œè§£ç å™¨è¿˜åœ¨è¿™ä¸¤ä¸ªå­å±‚ä¹‹é—´æ’å…¥äº†ç¬¬ä¸‰ä¸ªå­å±‚ï¼Œç§°ä¸º<em>ç¼–ç å™¨ï¼è§£ç å™¨æ³¨æ„åŠ›</em>ï¼ˆencoder-decoder attentionï¼‰å±‚ã€‚åœ¨ç¼–ç å™¨ï¼è§£ç å™¨æ³¨æ„åŠ›ä¸­ï¼ŒæŸ¥è¯¢æ¥è‡ªå‰ä¸€ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºï¼Œè€Œé”®å’Œå€¼æ¥è‡ªæ•´ä¸ªç¼–ç å™¨çš„è¾“å‡ºã€‚åœ¨è§£ç å™¨è‡ªæ³¨æ„åŠ›ä¸­ï¼ŒæŸ¥è¯¢ã€é”®å’Œå€¼éƒ½æ¥è‡ªä¸Šä¸€ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºã€‚ä½†æ˜¯ï¼Œè§£ç å™¨ä¸­çš„æ¯ä¸ªä½ç½®åªèƒ½è€ƒè™‘è¯¥ä½ç½®ä¹‹å‰çš„æ‰€æœ‰ä½ç½®ã€‚è¿™ç§<em>æ©è”½</em>ï¼ˆmaskedï¼‰æ³¨æ„åŠ›ä¿ç•™äº†<em>è‡ªå›å½’</em>ï¼ˆauto-regressiveï¼‰å±æ€§ï¼Œç¡®ä¿é¢„æµ‹ä»…ä¾èµ–äºå·²ç”Ÿæˆçš„è¾“å‡ºè¯å…ƒã€‚</p><p>åœ¨æ­¤ä¹‹å‰å·²ç»æè¿°å¹¶å®ç°äº†åŸºäºç¼©æ”¾ç‚¹ç§¯å¤šå¤´æ³¨æ„åŠ› :numref: <code>sec_multihead-attention</code> å’Œä½ç½®ç¼–ç  :numref: <code>subsec_positional-encoding</code> ã€‚æ¥ä¸‹æ¥å°†å®ç° Transformer æ¨¡å‹çš„å‰©ä½™éƒ¨åˆ†ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> math</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> torch</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">from</span> d2l <span class="token keyword">import</span> torch <span class="token keyword">as</span> d2l</pre></td></tr></table></figure><h2 id="åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"><a class="anchor" href="#åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ">#</a> [<strong>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</strong>]</h2><p>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œå¯¹åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®çš„è¡¨ç¤ºè¿›è¡Œå˜æ¢æ—¶ä½¿ç”¨çš„æ˜¯åŒä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œè¿™å°±æ˜¯ç§°å‰é¦ˆç½‘ç»œæ˜¯<em>åŸºäºä½ç½®çš„</em>ï¼ˆpositionwiseï¼‰çš„åŸå› ã€‚åœ¨ä¸‹é¢çš„å®ç°ä¸­ï¼Œè¾“å…¥ <code>X</code> çš„å½¢çŠ¶ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°æˆ–åºåˆ—é•¿åº¦ï¼Œéšå•å…ƒæ•°æˆ–ç‰¹å¾ç»´åº¦ï¼‰å°†è¢«ä¸€ä¸ªä¸¤å±‚çš„æ„ŸçŸ¥æœºè½¬æ¢æˆå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°ï¼Œ <code>ffn_num_outputs</code> ï¼‰çš„è¾“å‡ºå¼ é‡ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#@save</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">PositionWiseFFN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token triple-quoted-string string">"""åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"""</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> ffn_num_outputs<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>PositionWiseFFN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        self<span class="token punctuation">.</span>dense1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        self<span class="token punctuation">.</span>dense2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>ffn_num_hiddens<span class="token punctuation">,</span> ffn_num_outputs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dense2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dense1<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>ä¸‹é¢çš„ä¾‹å­æ˜¾ç¤ºï¼Œ[<strong>æ”¹å˜å¼ é‡çš„æœ€é‡Œå±‚ç»´åº¦çš„å°ºå¯¸</strong>]ï¼Œä¼šæ”¹å˜æˆåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œçš„è¾“å‡ºå°ºå¯¸ã€‚å› ä¸ºç”¨åŒä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºå¯¹æ‰€æœ‰ä½ç½®ä¸Šçš„è¾“å…¥è¿›è¡Œå˜æ¢ï¼Œæ‰€ä»¥å½“æ‰€æœ‰è¿™äº›ä½ç½®çš„è¾“å…¥ç›¸åŒæ—¶ï¼Œå®ƒä»¬çš„è¾“å‡ºä¹Ÿæ˜¯ç›¸åŒçš„ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>ffn <span class="token operator">=</span> PositionWiseFFN<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>ffn<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>ffn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></pre></td></tr></table></figure><pre><code>tensor([[ 0.3407, -0.0869, -0.3967,  0.7588,  0.3862,  0.2616,  0.1842, -0.0328],
        [ 0.3407, -0.0869, -0.3967,  0.7588,  0.3862,  0.2616,  0.1842, -0.0328],
        [ 0.3407, -0.0869, -0.3967,  0.7588,  0.3862,  0.2616,  0.1842, -0.0328]],
       grad_fn=&lt;SelectBackward0&gt;)
</code></pre><h2 id="æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–"><a class="anchor" href="#æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–">#</a> æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–</h2><p>ç°åœ¨è®©æˆ‘ä»¬å…³æ³¨ :numref: <code>fig_transformer</code> ä¸­çš„<em>åŠ æ³•å’Œè§„èŒƒåŒ–</em>ï¼ˆadd&amp;normï¼‰ç»„ä»¶ã€‚æ­£å¦‚åœ¨æœ¬èŠ‚å¼€å¤´æ‰€è¿°ï¼Œè¿™æ˜¯ç”±æ®‹å·®è¿æ¥å’Œç´§éšå…¶åçš„å±‚è§„èŒƒåŒ–ç»„æˆçš„ã€‚ä¸¤è€…éƒ½æ˜¯æ„å»ºæœ‰æ•ˆçš„æ·±åº¦æ¶æ„çš„å…³é”®ã€‚</p><p>:numref: <code>sec_batch_norm</code> ä¸­è§£é‡Šäº†åœ¨ä¸€ä¸ªå°æ‰¹é‡çš„æ ·æœ¬å†…åŸºäºæ‰¹é‡è§„èŒƒåŒ–å¯¹æ•°æ®è¿›è¡Œé‡æ–°ä¸­å¿ƒåŒ–å’Œé‡æ–°ç¼©æ”¾çš„è°ƒæ•´ã€‚å±‚è§„èŒƒåŒ–å’Œæ‰¹é‡è§„èŒƒåŒ–çš„ç›®æ ‡ç›¸åŒï¼Œä½†å±‚è§„èŒƒåŒ–æ˜¯åŸºäºç‰¹å¾ç»´åº¦è¿›è¡Œè§„èŒƒåŒ–ã€‚å°½ç®¡æ‰¹é‡è§„èŒƒåŒ–åœ¨è®¡ç®—æœºè§†è§‰ä¸­è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼ˆè¾“å…¥é€šå¸¸æ˜¯å˜é•¿åºåˆ—ï¼‰æ‰¹é‡è§„èŒƒåŒ–é€šå¸¸ä¸å¦‚å±‚è§„èŒƒåŒ–çš„æ•ˆæœå¥½ã€‚</p><p>ä»¥ä¸‹ä»£ç  [<strong>å¯¹æ¯”ä¸åŒç»´åº¦çš„å±‚è§„èŒƒåŒ–å’Œæ‰¹é‡è§„èŒƒåŒ–çš„æ•ˆæœ</strong>]ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>ln <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è®¡ç®— X çš„å‡å€¼å’Œæ–¹å·®</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'layer norm:'</span><span class="token punctuation">,</span> ln<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'\nbatch norm:'</span><span class="token punctuation">,</span> bn<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><pre><code>layer norm: tensor([[-1.0000,  1.0000],
        [-1.0000,  1.0000]], grad_fn=&lt;NativeLayerNormBackward0&gt;) 
batch norm: tensor([[-1.0000, -1.0000],
        [ 1.0000,  1.0000]], grad_fn=&lt;NativeBatchNormBackward0&gt;)
</code></pre><p>ç°åœ¨å¯ä»¥ [<strong>ä½¿ç”¨æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–</strong>] æ¥å®ç° <code>AddNorm</code> ç±»ã€‚æš‚é€€æ³•ä¹Ÿè¢«ä½œä¸ºæ­£åˆ™åŒ–æ–¹æ³•ä½¿ç”¨ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#@save</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">AddNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token triple-quoted-string string">"""æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–"""</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> normalized_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>AddNorm<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        self<span class="token punctuation">.</span>ln <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>normalized_shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>ln<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>Y<span class="token punctuation">)</span> <span class="token operator">+</span> X<span class="token punctuation">)</span></pre></td></tr></table></figure><p>æ®‹å·®è¿æ¥è¦æ±‚ä¸¤ä¸ªè¾“å…¥çš„å½¢çŠ¶ç›¸åŒï¼Œä»¥ä¾¿ [<strong>åŠ æ³•æ“ä½œåè¾“å‡ºå¼ é‡çš„å½¢çŠ¶ç›¸åŒ</strong>]ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>add_norm <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>add_norm<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>add_norm<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>torch.Size([2, 3, 4])
</code></pre><h2 id="ç¼–ç å™¨"><a class="anchor" href="#ç¼–ç å™¨">#</a> ç¼–ç å™¨</h2><p>æœ‰äº†ç»„æˆ Transformer ç¼–ç å™¨çš„åŸºç¡€ç»„ä»¶ï¼Œç°åœ¨å¯ä»¥å…ˆ [<strong>å®ç°ç¼–ç å™¨ä¸­çš„ä¸€ä¸ªå±‚</strong>]ã€‚ä¸‹é¢çš„ <code>EncoderBlock</code> ç±»åŒ…å«ä¸¤ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ›å’ŒåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼Œè¿™ä¸¤ä¸ªå­å±‚éƒ½ä½¿ç”¨äº†æ®‹å·®è¿æ¥å’Œç´§éšçš„å±‚è§„èŒƒåŒ–ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#@save</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">EncoderBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token triple-quoted-string string">"""Transformerç¼–ç å™¨å—"""</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                 norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>                 dropout<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>EncoderBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="9"></td><td><pre>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="10"></td><td><pre>            use_bias<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>addnorm1 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionWiseFFN<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        self<span class="token punctuation">.</span>addnorm2 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>X<span class="token punctuation">,</span> X<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>addnorm2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>æ­£å¦‚ä»ä»£ç ä¸­æ‰€çœ‹åˆ°çš„ï¼Œ[<strong>Transformer ç¼–ç å™¨ä¸­çš„ä»»ä½•å±‚éƒ½ä¸ä¼šæ”¹å˜å…¶è¾“å…¥çš„å½¢çŠ¶</strong>]ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>encoder_blk <span class="token operator">=</span> EncoderBlock<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>encoder_blk<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>encoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>torch.Size([2, 100, 24])
</code></pre><p>ä¸‹é¢å®ç°çš„ [<strong>Transformer ç¼–ç å™¨</strong>] çš„ä»£ç ä¸­ï¼Œå †å äº† <code>num_layers</code> ä¸ª <code>EncoderBlock</code> ç±»çš„å®ä¾‹ã€‚ç”±äºè¿™é‡Œä½¿ç”¨çš„æ˜¯å€¼èŒƒå›´åœ¨<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>âˆ’</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">âˆ’</span><span class="mord">1</span></span></span></span> å’Œ<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> ä¹‹é—´çš„å›ºå®šä½ç½®ç¼–ç ï¼Œå› æ­¤é€šè¿‡å­¦ä¹ å¾—åˆ°çš„è¾“å…¥çš„åµŒå…¥è¡¨ç¤ºçš„å€¼éœ€è¦å…ˆä¹˜ä»¥åµŒå…¥ç»´åº¦çš„å¹³æ–¹æ ¹è¿›è¡Œé‡æ–°ç¼©æ”¾ï¼Œç„¶åå†ä¸ä½ç½®ç¼–ç ç›¸åŠ ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">#@save</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">TransformerEncoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>Encoder<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token triple-quoted-string string">"""Transformerç¼–ç å™¨"""</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                 num_hiddens<span class="token punctuation">,</span> norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>                 num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>TransformerEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>num_hiddens <span class="token operator">=</span> num_hiddens</pre></td></tr><tr><td data-num="9"></td><td><pre>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>pos_encoding <span class="token operator">=</span> d2l<span class="token punctuation">.</span>PositionalEncoding<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>blks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            self<span class="token punctuation">.</span>blks<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"block"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                EncoderBlock<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                             norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                             num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> use_bias<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token comment"># å› ä¸ºä½ç½®ç¼–ç å€¼åœ¨ - 1 å’Œ 1 ä¹‹é—´ï¼Œ</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token comment"># å› æ­¤åµŒå…¥å€¼ä¹˜ä»¥åµŒå…¥ç»´åº¦çš„å¹³æ–¹æ ¹è¿›è¡Œç¼©æ”¾ï¼Œ</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token comment"># ç„¶åå†ä¸ä½ç½®ç¼–ç ç›¸åŠ ã€‚</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        self<span class="token punctuation">.</span>attention_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> blk <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            X <span class="token operator">=</span> blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">[</span></pre></td></tr><tr><td data-num="27"></td><td><pre>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights</pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token keyword">return</span> X</pre></td></tr></table></figure><p>ä¸‹é¢æˆ‘ä»¬æŒ‡å®šäº†è¶…å‚æ•°æ¥ [<strong>åˆ›å»ºä¸€ä¸ªä¸¤å±‚çš„ Transformer ç¼–ç å™¨</strong>]ã€‚<br>Transformer ç¼–ç å™¨è¾“å‡ºçš„å½¢çŠ¶æ˜¯ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°ç›®ï¼Œ <code>num_hiddens</code> ï¼‰ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>encoder <span class="token operator">=</span> TransformerEncoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>encoder<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>encoder<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>torch.Size([2, 100, 24])
</code></pre><h2 id="è§£ç å™¨"><a class="anchor" href="#è§£ç å™¨">#</a> è§£ç å™¨</h2><p>å¦‚ :numref: <code>fig_transformer</code> æ‰€ç¤ºï¼Œ[<strong>Transformer è§£ç å™¨ä¹Ÿæ˜¯ç”±å¤šä¸ªç›¸åŒçš„å±‚ç»„æˆ</strong>]ã€‚åœ¨ <code>DecoderBlock</code> ç±»ä¸­å®ç°çš„æ¯ä¸ªå±‚åŒ…å«äº†ä¸‰ä¸ªå­å±‚ï¼šè§£ç å™¨è‡ªæ³¨æ„åŠ›ã€â€œç¼–ç å™¨ - è§£ç å™¨â€ æ³¨æ„åŠ›å’ŒåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œã€‚è¿™äº›å­å±‚ä¹Ÿéƒ½è¢«æ®‹å·®è¿æ¥å’Œç´§éšçš„å±‚è§„èŒƒåŒ–å›´ç»•ã€‚</p><p>æ­£å¦‚åœ¨æœ¬èŠ‚å‰é¢æ‰€è¿°ï¼Œåœ¨æ©è”½å¤šå¤´è§£ç å™¨è‡ªæ³¨æ„åŠ›å±‚ï¼ˆç¬¬ä¸€ä¸ªå­å±‚ï¼‰ä¸­ï¼ŒæŸ¥è¯¢ã€é”®å’Œå€¼éƒ½æ¥è‡ªä¸Šä¸€ä¸ªè§£ç å™¨å±‚çš„è¾“å‡ºã€‚å…³äº<em>åºåˆ—åˆ°åºåˆ—æ¨¡å‹</em>ï¼ˆsequence-to-sequence modelï¼‰ï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œå…¶è¾“å‡ºåºåˆ—çš„æ‰€æœ‰ä½ç½®ï¼ˆæ—¶é—´æ­¥ï¼‰çš„è¯å…ƒéƒ½æ˜¯å·²çŸ¥çš„ï¼›ç„¶è€Œï¼Œåœ¨é¢„æµ‹é˜¶æ®µï¼Œå…¶è¾“å‡ºåºåˆ—çš„è¯å…ƒæ˜¯é€ä¸ªç”Ÿæˆçš„ã€‚å› æ­¤ï¼Œåœ¨ä»»ä½•è§£ç å™¨æ—¶é—´æ­¥ä¸­ï¼Œåªæœ‰ç”Ÿæˆçš„è¯å…ƒæ‰èƒ½ç”¨äºè§£ç å™¨çš„è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸­ã€‚ä¸ºäº†åœ¨è§£ç å™¨ä¸­ä¿ç•™è‡ªå›å½’çš„å±æ€§ï¼Œå…¶æ©è”½è‡ªæ³¨æ„åŠ›è®¾å®šäº†å‚æ•° <code>dec_valid_lens</code> ï¼Œä»¥ä¾¿ä»»ä½•æŸ¥è¯¢éƒ½åªä¼šä¸è§£ç å™¨ä¸­æ‰€æœ‰å·²ç»ç”Ÿæˆè¯å…ƒçš„ä½ç½®ï¼ˆå³ç›´åˆ°è¯¥æŸ¥è¯¢ä½ç½®ä¸ºæ­¢ï¼‰è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">DecoderBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token triple-quoted-string string">"""è§£ç å™¨ä¸­ç¬¬iä¸ªå—"""</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>                 norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>                 dropout<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>DecoderBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        self<span class="token punctuation">.</span>i <span class="token operator">=</span> i</pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>attention1 <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="9"></td><td><pre>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>addnorm1 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>attention2 <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        self<span class="token punctuation">.</span>addnorm2 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionWiseFFN<span class="token punctuation">(</span>ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                                   num_hiddens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        self<span class="token punctuation">.</span>addnorm3 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        enc_outputs<span class="token punctuation">,</span> enc_valid_lens <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> state<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token comment"># è®­ç»ƒé˜¶æ®µï¼Œè¾“å‡ºåºåˆ—çš„æ‰€æœ‰è¯å…ƒéƒ½åœ¨åŒä¸€æ—¶é—´å¤„ç†ï¼Œ</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token comment"># å› æ­¤ state [2][self.i] åˆå§‹åŒ–ä¸º Noneã€‚</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token comment"># é¢„æµ‹é˜¶æ®µï¼Œè¾“å‡ºåºåˆ—æ˜¯é€šè¿‡è¯å…ƒä¸€ä¸ªæ¥ç€ä¸€ä¸ªè§£ç çš„ï¼Œ</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token comment"># å› æ­¤ state [2][self.i] åŒ…å«ç€ç›´åˆ°å½“å‰æ—¶é—´æ­¥ç¬¬ i ä¸ªå—è§£ç çš„è¾“å‡ºè¡¨ç¤º</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token keyword">if</span> state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            key_values <span class="token operator">=</span> X</pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="27"></td><td><pre>            key_values <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> key_values</pre></td></tr><tr><td data-num="29"></td><td><pre>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="30"></td><td><pre>            batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> _ <span class="token operator">=</span> X<span class="token punctuation">.</span>shape</pre></td></tr><tr><td data-num="31"></td><td><pre>            <span class="token comment"># dec_valid_lens çš„å¼€å¤´ï¼š(batch_size,num_steps),</span></pre></td></tr><tr><td data-num="32"></td><td><pre>            <span class="token comment"># å…¶ä¸­æ¯ä¸€è¡Œæ˜¯ [1,2,...,num_steps]</span></pre></td></tr><tr><td data-num="33"></td><td><pre>            dec_valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="34"></td><td><pre>                <span class="token number">1</span><span class="token punctuation">,</span> num_steps <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>X<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        <span class="token keyword">else</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre>            dec_valid_lens <span class="token operator">=</span> <span class="token boolean">None</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>        <span class="token comment"># è‡ªæ³¨æ„åŠ›</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        X2 <span class="token operator">=</span> self<span class="token punctuation">.</span>attention1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> key_values<span class="token punctuation">,</span> key_values<span class="token punctuation">,</span> dec_valid_lens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> X2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token comment"># ç¼–ç å™¨ï¼è§£ç å™¨æ³¨æ„åŠ›ã€‚</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        <span class="token comment"># enc_outputs çš„å¼€å¤´ï¼š(batch_size,num_steps,num_hiddens)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        Y2 <span class="token operator">=</span> self<span class="token punctuation">.</span>attention2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        Z <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> Y2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>addnorm3<span class="token punctuation">(</span>Z<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> state</pre></td></tr></table></figure><p>ä¸ºäº†ä¾¿äºåœ¨ â€œç¼–ç å™¨ï¼è§£ç å™¨â€ æ³¨æ„åŠ›ä¸­è¿›è¡Œç¼©æ”¾ç‚¹ç§¯è®¡ç®—å’Œæ®‹å·®è¿æ¥ä¸­è¿›è¡ŒåŠ æ³•è®¡ç®—ï¼Œ[<strong>ç¼–ç å™¨å’Œè§£ç å™¨çš„ç‰¹å¾ç»´åº¦éƒ½æ˜¯ <code>num_hiddens</code> ã€‚</strong>]</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>decoder_blk <span class="token operator">=</span> DecoderBlock<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>decoder_blk<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>state <span class="token operator">=</span> <span class="token punctuation">[</span>encoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_lens<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="5"></td><td><pre>decoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>torch.Size([2, 100, 24])
</code></pre><p>ç°åœ¨æˆ‘ä»¬æ„å»ºäº†ç”± <code>num_layers</code> ä¸ª <code>DecoderBlock</code> å®ä¾‹ç»„æˆçš„å®Œæ•´çš„ [<strong>Transformer è§£ç å™¨</strong>]ã€‚æœ€åï¼Œé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚è®¡ç®—æ‰€æœ‰ <code>vocab_size</code> ä¸ªå¯èƒ½çš„è¾“å‡ºè¯å…ƒçš„é¢„æµ‹å€¼ã€‚è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œç¼–ç å™¨è§£ç å™¨æ³¨æ„åŠ›æƒé‡éƒ½è¢«å­˜å‚¨ä¸‹æ¥ï¼Œæ–¹ä¾¿æ—¥åå¯è§†åŒ–çš„éœ€è¦ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">TransformerDecoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>AttentionDecoder<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>                 num_hiddens<span class="token punctuation">,</span> norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>                 num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>TransformerDecoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        self<span class="token punctuation">.</span>num_hiddens <span class="token operator">=</span> num_hiddens</pre></td></tr><tr><td data-num="7"></td><td><pre>        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers</pre></td></tr><tr><td data-num="8"></td><td><pre>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        self<span class="token punctuation">.</span>pos_encoding <span class="token operator">=</span> d2l<span class="token punctuation">.</span>PositionalEncoding<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        self<span class="token punctuation">.</span>blks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            self<span class="token punctuation">.</span>blks<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"block"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                DecoderBlock<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                             norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                             num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token keyword">return</span> <span class="token punctuation">[</span>enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        self<span class="token punctuation">.</span>_attention_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> blk <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            X<span class="token punctuation">,</span> state <span class="token operator">=</span> blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            <span class="token comment"># è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡</span></pre></td></tr><tr><td data-num="27"></td><td><pre>            self<span class="token punctuation">.</span>_attention_weights<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="28"></td><td><pre>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention1<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights</pre></td></tr><tr><td data-num="29"></td><td><pre>            <span class="token comment"># â€œç¼–ç å™¨ï¼è§£ç å™¨â€ è‡ªæ³¨æ„åŠ›æƒé‡</span></pre></td></tr><tr><td data-num="30"></td><td><pre>            self<span class="token punctuation">.</span>_attention_weights<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="31"></td><td><pre>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention2<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights</pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> state</pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token decorator annotation punctuation">@property</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">attention_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_attention_weights</pre></td></tr></table></figure><h2 id="è®­ç»ƒ"><a class="anchor" href="#è®­ç»ƒ">#</a> [<strong>è®­ç»ƒ</strong>]</h2><p>ä¾ç…§ Transformer æ¶æ„æ¥å®ä¾‹åŒ–ç¼–ç å™¨ï¼è§£ç å™¨æ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼ŒæŒ‡å®š Transformer çš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ½æ˜¯ 2 å±‚ï¼Œéƒ½ä½¿ç”¨ 4 å¤´æ³¨æ„åŠ›ã€‚ä¸ :numref: <code>sec_seq2seq_training</code> ç±»ä¼¼ï¼Œä¸ºäº†è¿›è¡Œåºåˆ—åˆ°åºåˆ—çš„å­¦ä¹ ï¼Œä¸‹é¢åœ¨ â€œè‹±è¯­ï¼æ³•è¯­â€ æœºå™¨ç¿»è¯‘æ•°æ®é›†ä¸Šè®­ç»ƒ Transformer æ¨¡å‹ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span></pre></td></tr><tr><td data-num="2"></td><td><pre>lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> device <span class="token operator">=</span> <span class="token number">0.005</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> d2l<span class="token punctuation">.</span>try_gpu<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">4</span></pre></td></tr><tr><td data-num="4"></td><td><pre>key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span></pre></td></tr><tr><td data-num="5"></td><td><pre>norm_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>train_iter<span class="token punctuation">,</span> src_vocab<span class="token punctuation">,</span> tgt_vocab <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_nmt<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>encoder <span class="token operator">=</span> TransformerEncoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token builtin">len</span><span class="token punctuation">(</span>src_vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>decoder <span class="token operator">=</span> TransformerDecoder<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token builtin">len</span><span class="token punctuation">(</span>tgt_vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>net <span class="token operator">=</span> d2l<span class="token punctuation">.</span>EncoderDecoder<span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>d2l<span class="token punctuation">.</span>train_seq2seq<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> tgt_vocab<span class="token punctuation">,</span> device<span class="token punctuation">)</span></pre></td></tr></table></figure><pre><code>loss 0.032, 5679.3 tokens/sec on cuda:0
</code></pre><p><img data-src="/transformer_files/transformer_27_1.svg" alt="svg"></p><p>è®­ç»ƒç»“æŸåï¼Œä½¿ç”¨ Transformer æ¨¡å‹ [<strong>å°†ä¸€äº›è‹±è¯­å¥å­ç¿»è¯‘æˆæ³•è¯­</strong>]ï¼Œå¹¶ä¸”è®¡ç®—å®ƒä»¬çš„ BLEU åˆ†æ•°ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>engs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'go .'</span><span class="token punctuation">,</span> <span class="token string">"i lost ."</span><span class="token punctuation">,</span> <span class="token string">'he\'s calm .'</span><span class="token punctuation">,</span> <span class="token string">'i\'m home .'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>fras <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'va !'</span><span class="token punctuation">,</span> <span class="token string">'j\'ai perdu .'</span><span class="token punctuation">,</span> <span class="token string">'il est calme .'</span><span class="token punctuation">,</span> <span class="token string">'je suis chez moi .'</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">for</span> eng<span class="token punctuation">,</span> fra <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>engs<span class="token punctuation">,</span> fras<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    translation<span class="token punctuation">,</span> dec_attention_weight_seq <span class="token operator">=</span> d2l<span class="token punctuation">.</span>predict_seq2seq<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        net<span class="token punctuation">,</span> eng<span class="token punctuation">,</span> src_vocab<span class="token punctuation">,</span> tgt_vocab<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> device<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>eng<span class="token punctuation">&#125;</span></span><span class="token string"> => </span><span class="token interpolation"><span class="token punctuation">&#123;</span>translation<span class="token punctuation">&#125;</span></span><span class="token string">, '</span></span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>          <span class="token string-interpolation"><span class="token string">f'bleu </span><span class="token interpolation"><span class="token punctuation">&#123;</span>d2l<span class="token punctuation">.</span>bleu<span class="token punctuation">(</span>translation<span class="token punctuation">,</span> fra<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></pre></td></tr></table></figure><pre><code>go . =&gt; va !,  bleu 1.000
i lost . =&gt; j'ai perdu .,  bleu 1.000
he's calm . =&gt; il est calme .,  bleu 1.000
i'm home . =&gt; je suis chez moi .,  bleu 1.000
</code></pre><p>å½“è¿›è¡Œæœ€åä¸€ä¸ªè‹±è¯­åˆ°æ³•è¯­çš„å¥å­ç¿»è¯‘å·¥ä½œæ—¶ï¼Œè®©æˆ‘ä»¬ [<strong>å¯è§†åŒ– Transformer çš„æ³¨æ„åŠ›æƒé‡</strong>]ã€‚ç¼–ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶ä¸ºï¼ˆç¼–ç å™¨å±‚æ•°ï¼Œæ³¨æ„åŠ›å¤´æ•°ï¼Œ <code>num_steps</code> æˆ–æŸ¥è¯¢çš„æ•°ç›®ï¼Œ <code>num_steps</code> æˆ– â€œé”®ï¼å€¼â€ å¯¹çš„æ•°ç›®ï¼‰ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>enc_attention_weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>net<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>attention_weights<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>enc_attention_weights<span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>torch.Size([2, 4, 10, 10])
</code></pre><p>åœ¨ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›ä¸­ï¼ŒæŸ¥è¯¢å’Œé”®éƒ½æ¥è‡ªç›¸åŒçš„è¾“å…¥åºåˆ—ã€‚å› ä¸ºå¡«å……è¯å…ƒæ˜¯ä¸æºå¸¦ä¿¡æ¯çš„ï¼Œå› æ­¤é€šè¿‡æŒ‡å®šè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦å¯ä»¥é¿å…æŸ¥è¯¢ä¸ä½¿ç”¨å¡«å……è¯å…ƒçš„ä½ç½®è®¡ç®—æ³¨æ„åŠ›ã€‚æ¥ä¸‹æ¥ï¼Œå°†é€è¡Œå‘ˆç°ä¸¤å±‚å¤šå¤´æ³¨æ„åŠ›çš„æƒé‡ã€‚æ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½æ ¹æ®æŸ¥è¯¢ã€é”®å’Œå€¼çš„ä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´æ¥è¡¨ç¤ºä¸åŒçš„æ³¨æ„åŠ›ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>d2l<span class="token punctuation">.</span>show_heatmaps<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    enc_attention_weights<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xlabel<span class="token operator">=</span><span class="token string">'Key positions'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    ylabel<span class="token operator">=</span><span class="token string">'Query positions'</span><span class="token punctuation">,</span> titles<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Head %d'</span> <span class="token operator">%</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/transformer_files/transformer_33_0.svg" alt="svg"></p><p>[<strong>ä¸ºäº†å¯è§†åŒ–è§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œ â€œç¼–ç å™¨ï¼è§£ç å™¨â€ çš„æ³¨æ„åŠ›æƒé‡ï¼Œæˆ‘ä»¬éœ€è¦å®Œæˆæ›´å¤šçš„æ•°æ®æ“ä½œå·¥ä½œã€‚</strong>] ä¾‹å¦‚ç”¨é›¶å¡«å……è¢«æ©è”½ä½çš„æ³¨æ„åŠ›æƒé‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè§£ç å™¨çš„è‡ªæ³¨æ„åŠ›æƒé‡å’Œ â€œç¼–ç å™¨ï¼è§£ç å™¨â€ çš„æ³¨æ„åŠ›æƒé‡éƒ½æœ‰ç›¸åŒçš„æŸ¥è¯¢ï¼šå³ä»¥<em>åºåˆ—å¼€å§‹è¯å…ƒ</em>ï¼ˆbeginning-of-sequence,BOSï¼‰æ‰“å¤´ï¼Œå†ä¸åç»­è¾“å‡ºçš„è¯å…ƒå…±åŒç»„æˆåºåˆ—ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>dec_attention_weights_2d <span class="token operator">=</span> <span class="token punctuation">[</span>head<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>                            <span class="token keyword">for</span> step <span class="token keyword">in</span> dec_attention_weight_seq</pre></td></tr><tr><td data-num="3"></td><td><pre>                            <span class="token keyword">for</span> attn <span class="token keyword">in</span> step <span class="token keyword">for</span> blk <span class="token keyword">in</span> attn <span class="token keyword">for</span> head <span class="token keyword">in</span> blk<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre>dec_attention_weights_filled <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>dec_attention_weights_2d<span class="token punctuation">)</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>dec_attention_weights <span class="token operator">=</span> dec_attention_weights_filled<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>dec_self_attention_weights<span class="token punctuation">,</span> dec_inter_attention_weights <span class="token operator">=</span> \</pre></td></tr><tr><td data-num="8"></td><td><pre>    dec_attention_weights<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>dec_self_attention_weights<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> dec_inter_attention_weights<span class="token punctuation">.</span>shape</pre></td></tr></table></figure><pre><code>(torch.Size([2, 4, 6, 10]), torch.Size([2, 4, 6, 10]))
</code></pre><p>ç”±äºè§£ç å™¨è‡ªæ³¨æ„åŠ›çš„è‡ªå›å½’å±æ€§ï¼ŒæŸ¥è¯¢ä¸ä¼šå¯¹å½“å‰ä½ç½®ä¹‹åçš„ â€œé”®ï¼å€¼â€ å¯¹è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># Plusonetoincludethebeginning-of-sequencetoken</span></pre></td></tr><tr><td data-num="2"></td><td><pre>d2l<span class="token punctuation">.</span>show_heatmaps<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    dec_self_attention_weights<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>translation<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    xlabel<span class="token operator">=</span><span class="token string">'Key positions'</span><span class="token punctuation">,</span> ylabel<span class="token operator">=</span><span class="token string">'Query positions'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    titles<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Head %d'</span> <span class="token operator">%</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/transformer_files/transformer_37_0.svg" alt="svg"></p><p>ä¸ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›çš„æƒ…å†µç±»ä¼¼ï¼Œé€šè¿‡æŒ‡å®šè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ï¼Œ[<strong>è¾“å‡ºåºåˆ—çš„æŸ¥è¯¢ä¸ä¼šä¸è¾“å…¥åºåˆ—ä¸­å¡«å……ä½ç½®çš„è¯å…ƒè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—</strong>]ã€‚</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>d2l<span class="token punctuation">.</span>show_heatmaps<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    dec_inter_attention_weights<span class="token punctuation">,</span> xlabel<span class="token operator">=</span><span class="token string">'Key positions'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    ylabel<span class="token operator">=</span><span class="token string">'Query positions'</span><span class="token punctuation">,</span> titles<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Head %d'</span> <span class="token operator">%</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><img data-src="/transformer_files/transformer_39_0.svg" alt="svg"></p><p>å°½ç®¡ Transformer æ¶æ„æ˜¯ä¸ºäº†<em>åºåˆ—åˆ°åºåˆ—</em>çš„å­¦ä¹ è€Œæå‡ºçš„ï¼Œä½†æ­£å¦‚æœ¬ä¹¦åé¢å°†æåŠçš„é‚£æ ·ï¼ŒTransformer ç¼–ç å™¨æˆ– Transformer è§£ç å™¨é€šå¸¸è¢«å•ç‹¬ç”¨äºä¸åŒçš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ã€‚</p><h2 id="å°ç»“"><a class="anchor" href="#å°ç»“">#</a> å°ç»“</h2><ul><li>Transformer æ˜¯ç¼–ç å™¨ï¼è§£ç å™¨æ¶æ„çš„ä¸€ä¸ªå®è·µï¼Œå°½ç®¡åœ¨å®é™…æƒ…å†µä¸­ç¼–ç å™¨æˆ–è§£ç å™¨å¯ä»¥å•ç‹¬ä½¿ç”¨ã€‚</li><li>åœ¨ Transformer ä¸­ï¼Œå¤šå¤´è‡ªæ³¨æ„åŠ›ç”¨äºè¡¨ç¤ºè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—ï¼Œä¸è¿‡è§£ç å™¨å¿…é¡»é€šè¿‡æ©è”½æœºåˆ¶æ¥ä¿ç•™è‡ªå›å½’å±æ€§ã€‚</li><li>Transformer ä¸­çš„æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–æ˜¯è®­ç»ƒéå¸¸æ·±åº¦æ¨¡å‹çš„é‡è¦å·¥å…·ã€‚</li><li>Transformer æ¨¡å‹ä¸­åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œä½¿ç”¨åŒä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼Œä½œç”¨æ˜¯å¯¹æ‰€æœ‰åºåˆ—ä½ç½®çš„è¡¨ç¤ºè¿›è¡Œè½¬æ¢ã€‚</li></ul><h2 id="ç»ƒä¹ "><a class="anchor" href="#ç»ƒä¹ ">#</a> ç»ƒä¹ </h2><ol><li>åœ¨å®éªŒä¸­è®­ç»ƒæ›´æ·±çš„ Transformer å°†å¦‚ä½•å½±å“è®­ç»ƒé€Ÿåº¦å’Œç¿»è¯‘æ•ˆæœï¼Ÿ</li><li>åœ¨ Transformer ä¸­ä½¿ç”¨åŠ æ€§æ³¨æ„åŠ›å–ä»£ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æ˜¯ä¸æ˜¯ä¸ªå¥½åŠæ³•ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ</li><li>å¯¹äºè¯­è¨€æ¨¡å‹ï¼Œåº”è¯¥ä½¿ç”¨ Transformer çš„ç¼–ç å™¨è¿˜æ˜¯è§£ç å™¨ï¼Œæˆ–è€…ä¸¤è€…éƒ½ç”¨ï¼Ÿå¦‚ä½•è®¾è®¡ï¼Ÿ</li><li>å¦‚æœè¾“å…¥åºåˆ—å¾ˆé•¿ï¼ŒTransformer ä¼šé¢ä¸´ä»€ä¹ˆæŒ‘æˆ˜ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ</li><li>å¦‚ä½•æé«˜ Transformer çš„è®¡ç®—é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨æ•ˆç‡ï¼Ÿæç¤ºï¼šå¯ä»¥å‚è€ƒè®ºæ–‡ :cite: <code>Tay.Dehghani.Bahri.ea.2020</code> ã€‚</li><li>å¦‚æœä¸ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¦‚ä½•è®¾è®¡åŸºäº Transformer æ¨¡å‹çš„å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Ÿæç¤ºï¼šå¯ä»¥å‚è€ƒ Vision Transformer :cite: <code>Dosovitskiy.Beyer.Kolesnikov.ea.2021</code> ã€‚</li></ol><p><span class="exturl" data-url="aHR0cHM6Ly9kaXNjdXNzLmQybC5haS90LzU3NTY=">Discussions</span></p><div class="tags"><a href="/tags/chapter-attention-mechanisms/" rel="tag"><i class="ic i-tag"></i> chapter_attention-mechanisms</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">æ›´æ–°äº</span> <time title="ä¿®æ”¹æ—¶é—´ï¼š2023-03-04 13:38:25" itemprop="dateModified" datetime="2023-03-04T13:38:25+08:00">2023-03-04</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> èµèµ</button><p>è¯·æˆ‘å–[èŒ¶]~(ï¿£â–½ï¿£)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="yuan å¾®ä¿¡æ”¯ä»˜"><p>å¾®ä¿¡æ”¯ä»˜</p></div><div><img data-src="/images/alipay.png" alt="yuan æ”¯ä»˜å®"><p>æ”¯ä»˜å®</p></div><div><img data-src="/images/paypal.png" alt="yuan è´å®"><p>è´å®</p></div></div></div><div id="copyright"><ul><li class="author"><strong>æœ¬æ–‡ä½œè€…ï¼š </strong>yuan <i class="ic i-at"><em>@</em></i>yuan</li><li class="link"><strong>æœ¬æ–‡é“¾æ¥ï¼š</strong> <a href="https://huang-junyuan.github.io/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/transformer/" title="transformer">https://huang-junyuan.github.io/2023/02/15/ai/pytorchæ·±åº¦å­¦ä¹ /chapter_attention-mechanisms/transformer/</a></li><li class="license"><strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬ç«™æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/self-attention-and-positional-encoding/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(96).webp" title="self-attention-and-positional-encoding"><span class="type">ä¸Šä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> chapter_attention-mechanisms</span><h3>self-attention-and-positional-encoding</h3></a></div><div class="item right"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/auto-parallelism/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;gitee.com&#x2F;zkz0&#x2F;image&#x2F;raw&#x2F;master&#x2F;img&#x2F;img(27).webp" title="auto-parallelism"><span class="type">ä¸‹ä¸€ç¯‡</span> <span class="category"><i class="ic i-flag"></i> chapter_computational-performance</span><h3>auto-parallelism</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="æ–‡ç« ç›®å½•"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#transformer"><span class="toc-number">1.</span> <span class="toc-text">Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">æ¨¡å‹</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.</span> <span class="toc-text">[åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%B1%82%E8%A7%84%E8%8C%83%E5%8C%96"><span class="toc-number">1.3.</span> <span class="toc-text">æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.4.</span> <span class="toc-text">ç¼–ç å™¨</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-number">1.5.</span> <span class="toc-text">è§£ç å™¨</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.6.</span> <span class="toc-text">[è®­ç»ƒ]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.7.</span> <span class="toc-text">å°ç»“</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0"><span class="toc-number">1.8.</span> <span class="toc-text">ç»ƒä¹ </span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="ç³»åˆ—æ–‡ç« "><ul><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/attention-cues/" rel="bookmark" title="attention-cues">attention-cues</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/bahdanau-attention/" rel="bookmark" title="bahdanau-attention">bahdanau-attention</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/index/" rel="bookmark" title="index">index</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/multihead-attention/" rel="bookmark" title="multihead-attention">multihead-attention</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/attention-scoring-functions/" rel="bookmark" title="attention-scoring-functions">attention-scoring-functions</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/nadaraya-waston/" rel="bookmark" title="nadaraya-waston">nadaraya-waston</a></li><li class="active"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/transformer/" rel="bookmark" title="transformer">transformer</a></li><li><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/self-attention-and-positional-encoding/" rel="bookmark" title="self-attention-and-positional-encoding">self-attention-and-positional-encoding</a></li></ul></div><div class="overview panel" data-title="ç«™ç‚¹æ¦‚è§ˆ"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">363</span> <span class="name">æ–‡ç« </span></a></div><div class="item categories"><a href="/categories/"><span class="count">68</span> <span class="name">åˆ†ç±»</span></a></div><div class="item tags"><a href="/tags/"><span class="count">59</span> <span class="name">æ ‡ç­¾</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>é¦–é¡µ</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>å…³äº</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>æ–‡ç« </a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>å½’æ¡£</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>åˆ†ç±»</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>æ ‡ç­¾</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>å‹é”</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>é“¾æ¥</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/self-attention-and-positional-encoding/" rel="prev" title="ä¸Šä¸€ç¯‡"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/auto-parallelism/" rel="next" title="ä¸‹ä¸€ç¯‡"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>éšæœºæ–‡ç« </h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="åˆ†ç±»äº computer-science">computer-science</a></div><span><a href="/2023/03/03/computer-science/%E5%A4%A7%E5%94%90%E6%9D%AF/note/" title="å¤§å”æ¯">å¤§å”æ¯</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="åˆ†ç±»äº pytorchæ·±åº¦å­¦ä¹ ">pytorchæ·±åº¦å­¦ä¹ </a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-linear-networks/" title="åˆ†ç±»äº chapter_linear-networks">chapter_linear-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_linear-networks/softmax-regression-scratch/" title="softmax-regression-scratch">softmax-regression-scratch</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" title="åˆ†ç±»äº æ•°æ®åº“">æ•°æ®åº“</a></div><span><a href="/2022/07/26/database/Python%E6%93%8D%E4%BD%9CMongoDB/" title="Pythonæ“ä½œMongoDB">Pythonæ“ä½œMongoDB</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="åˆ†ç±»äº åç«¯">åç«¯</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/MyBatisPlus/" title="åˆ†ç±»äº MyBatisPlus">MyBatisPlus</a></div><span><a href="/2022/11/12/backend/Mybatisplus/MyBatisPlus/" title="MyBatisPlus">MyBatisPlus</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="åˆ†ç±»äº pytorchæ·±åº¦å­¦ä¹ ">pytorchæ·±åº¦å­¦ä¹ </a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-optimization/" title="åˆ†ç±»äº chapter_optimization">chapter_optimization</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_optimization/optimization-intro/" title="optimization-intro">optimization-intro</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="åˆ†ç±»äº pytorchæ·±åº¦å­¦ä¹ ">pytorchæ·±åº¦å­¦ä¹ </a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-linear-networks/" title="åˆ†ç±»äº chapter_linear-networks">chapter_linear-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_linear-networks/index/" title="index">index</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/08/25/language/vbs/vbs/" title="vbs">vbs</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="åˆ†ç±»äº ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="åˆ†ç±»äº pytorchæ·±åº¦å­¦ä¹ ">pytorchæ·±åº¦å­¦ä¹ </a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-convolutional-neural-networks/" title="åˆ†ç±»äº chapter_convolutional-neural-networks">chapter_convolutional-neural-networks</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_convolutional-neural-networks/why-conv/" title="why-conv">why-conv</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="åˆ†ç±»äº computer-science">computer-science</a></div><span><a href="/2023/03/01/computer-science/%E4%BF%9D%E7%A0%94/note/" title="ä¿ç ”å¤ä»¤è¥èµ„æ–™æ”¶é›†">ä¿ç ”å¤ä»¤è¥èµ„æ–™æ”¶é›†</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="åˆ†ç±»äº åç«¯">åç«¯</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/spring/" title="åˆ†ç±»äº spring">spring</a></div><span><a href="/2022/11/12/backend/Spring/spring_day01/Spring_day01/" title="Spring_day01">Spring_day01</a></span></li></ul></div><div><h2>æœ€æ–°è¯„è®º</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 â€“ <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="ç«™ç‚¹æ€»å­—æ•°">2.4m å­—</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">35:46</span></div><div class="powered-by">åŸºäº <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2023/02/15/ai/pytorchæ·±åº¦å­¦ä¹ /chapter_attention-mechanisms/transformer/",favicon:{show:"ï¼ˆâ—Â´3ï½€â—ï¼‰ã‚„ã‚Œã‚„ã‚Œã ãœ",hide:"(Â´Ğ”ï½€)å¤§å¤‰ã ï¼"},search:{placeholder:"æ–‡ç« æœç´¢",empty:"å…³äº ã€Œ ${query} ã€ï¼Œä»€ä¹ˆä¹Ÿæ²¡æœåˆ°",stats:"${time} ms å†…æ‰¾åˆ° ${hits} æ¡ç»“æœ"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'å¤åˆ¶æˆåŠŸï¼Œè½¬è½½è¯·éµå®ˆ <i class="ic i-creative-commons"></i>BY-NC-SA åè®®ã€‚',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>