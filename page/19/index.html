<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://jyuanhust.github.io/page/19/"><title>Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Mi Manchi</p><h1 itemprop="name headline" class="title">yuan</h1></a><p class="meta" itemprop="description">= Whatever is worth doing at all is worth doing well =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(53).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(48).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(59).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(56).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(25).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(75).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><div class="segments posts"><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/neural-style/" itemprop="url" title="neural-style"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(77).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>8.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>7 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/neural-style/" itemprop="url" title="neural-style">neural-style</a></h3><div class="excerpt"># 风格迁移 摄影爱好者也许接触过滤波器。它能改变照片的颜色风格，从而使风景照更加锐利或者令人像更加美白。但一个滤波器通常只能改变照片的某个方面。如果要照片达到理想中的风格，可能需要尝试大量不同的组合。这个过程的复杂程度不亚于模型调参。 本节将介绍如何使用卷积神经网络，自动将一个图像中的风格应用在另一图像之上，即风格迁移（style transfer） :cite: Gatys.Ecker.Bethge.2016 。 这里我们需要两张输入图像：一张是内容图像，另一张是风格图像。 我们将使用神经网络修改内容图像，使其在风格上接近风格图像。 例如， :numref:...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computer-vision/" itemprop="url" title="chapter_computer-vision"><i class="ic i-flag"></i>chapter_computer-vision</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/neural-style/" itemprop="url" title="neural-style" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/rcnn/" itemprop="url" title="rcnn"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(82).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>4.5k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/rcnn/" itemprop="url" title="rcnn">rcnn</a></h3><div class="excerpt"># 区域卷积神经网络（R-CNN）系列 🏷 sec_rcnn 除了 :numref: sec_ssd 中描述的单发多框检测之外， 区域卷积神经网络（region-based CNN 或 regions with CNN features，R-CNN） :cite: Girshick.Donahue.Darrell.ea.2014 也是将深度模型应用于目标检测的开创性工作之一。 本节将介绍 R-CNN 及其一系列改进方法：快速的 R-CNN（Fast R-CNN） :cite: Girshick.2015 、更快的 R-CNN（Faster R-CNN） :cite:...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computer-vision/" itemprop="url" title="chapter_computer-vision"><i class="ic i-flag"></i>chapter_computer-vision</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/rcnn/" itemprop="url" title="rcnn" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/custom-layer/" itemprop="url" title="custom-layer"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(7).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>2 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/custom-layer/" itemprop="url" title="custom-layer">custom-layer</a></h3><div class="excerpt"># 自定义层 深度学习成功背后的一个因素是神经网络的灵活性： 我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。 例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。 有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。 在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。 # 不带参数的层 首先，我们 (构造一个没有任何参数的自定义层)。 回忆一下在 :numref: sec_model_construction 对块的介绍， 这应该看起来很眼熟。 下面的 CenteredLayer...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/custom-layer/" itemprop="url" title="custom-layer" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/ssd/" itemprop="url" title="ssd"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(89).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>12k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>11 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/ssd/" itemprop="url" title="ssd">ssd</a></h3><div class="excerpt"># 单发多框检测（SSD） 🏷 sec_ssd 在 :numref: sec_bbox — :numref: sec_object-detection-dataset 中，我们分别介绍了边界框、锚框、多尺度目标检测和用于目标检测的数据集。 现在我们已经准备好使用这样的背景知识来设计一个目标检测模型：单发多框检测（SSD） :cite: Liu.Anguelov.Erhan.ea.2016 。 该模型简单、快速且被广泛使用。尽管这只是其中一种目标检测模型，但本节中的一些设计原则和实现细节也适用于其他模型。 # 模型 :numref: fig_ssd...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computer-vision/" itemprop="url" title="chapter_computer-vision"><i class="ic i-flag"></i>chapter_computer-vision</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/ssd/" itemprop="url" title="ssd" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/deferred-init/" itemprop="url" title="deferred-init"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(18).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>782</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/deferred-init/" itemprop="url" title="deferred-init">deferred-init</a></h3><div class="excerpt"># 延后初始化 🏷 sec_deferred_init 到目前为止，我们忽略了建立网络时需要做的以下这些事情： 我们定义了网络架构，但没有指定输入维度。 我们添加层时没有指定前一层的输出维度。 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数。 有些读者可能会对我们的代码能运行感到惊讶。 毕竟，深度学习框架无法判断网络的输入维度是什么。 这里的诀窍是框架的延后初始化（defers...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/deferred-init/" itemprop="url" title="deferred-init" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/index/" itemprop="url" title="index"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(36).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>627</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/index/" itemprop="url" title="index">index</a></h3><div class="excerpt"># 深度学习计算 🏷 chap_computation 除了庞大的数据集和强大的硬件， 优秀的软件工具在深度学习的快速发展中发挥了不可或缺的作用。 从 2007 年发布的开创性的 Theano...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/index/" itemprop="url" title="index" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/transposed-conv/" itemprop="url" title="transposed-conv"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(45).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>4.4k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/transposed-conv/" itemprop="url" title="transposed-conv">transposed-conv</a></h3><div class="excerpt"># 转置卷积 🏷 sec_transposed_conv 到目前为止，我们所见到的卷积神经网络层，例如卷积层（ :numref: sec_conv_layer ）和汇聚层（ :numref: sec_pooling ），通常会减少下采样输入图像的空间维度（高和宽）。 然而如果输入和输出图像的空间维度相同，在以像素级分类的语义分割中将会很方便。 例如，输出像素所处的通道维可以保有输入像素在同一位置上的分类结果。 为了实现这一点，尤其是在空间维度被卷积神经网络层缩小后，我们可以使用另一种类型的卷积神经网络层，它可以增加上采样中间层特征图的空间维度。 本节将介绍 转置卷积（transposed...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computer-vision/" itemprop="url" title="chapter_computer-vision"><i class="ic i-flag"></i>chapter_computer-vision</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computer-vision/transposed-conv/" itemprop="url" title="transposed-conv" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/model-construction/" itemprop="url" title="model-construction"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(48).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>6.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>6 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/model-construction/" itemprop="url" title="model-construction">model-construction</a></h3><div class="excerpt"># 层和块 🏷 sec_model_construction 之前首次介绍神经网络时，我们关注的是具有单一输出的线性模型。 在这里，整个模型只有一个输出。 注意，单个神经网络 （1）接受一些输入； （2）生成相应的标量输出； （3）具有一组相关 参数（parameters），更新这些参数可以优化某目标函数。 然后，当考虑具有多个输出的网络时， 我们利用矢量化算法来描述整层神经元。 像单个神经元一样，层（1）接受一组输入， （2）生成相应的输出， （3）由一组可调整参数描述。 当我们使用 softmax...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/model-construction/" itemprop="url" title="model-construction" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/use-gpu/" itemprop="url" title="use-gpu"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(98).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>5.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>5 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/use-gpu/" itemprop="url" title="use-gpu">use-gpu</a></h3><div class="excerpt"># GPU 🏷 sec_use_gpu 在 :numref: tab_intro_decade 中， 我们回顾了过去 20 年计算能力的快速增长。 简而言之，自 2000 年以来，GPU 性能每十年增长 1000 倍。 本节，我们将讨论如何利用这种计算性能进行研究。 首先是如何使用单个 GPU，然后是如何使用多个 GPU 和多个服务器（具有多个 GPU）。 我们先看看如何使用单个 NVIDIA GPU 进行计算。 首先，确保至少安装了一个 NVIDIA GPU。 然后，下载 NVIDIA 驱动和 CUDA 并按照提示设置适当的路径。 当这些准备工作完成，就可以使用 nvidia-smi...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/use-gpu/" itemprop="url" title="use-gpu" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/parameters/" itemprop="url" title="parameters"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(21).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2023-02-15 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2023-02-15T00:00:00+08:00">2023-02-15</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>5.7k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>5 分钟</span></span></div><h3><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/parameters/" itemprop="url" title="parameters">parameters</a></h3><div class="excerpt"># 参数管理 在选择了架构并设置了超参数后，我们就进入了训练阶段。 此时，我们的目标是找到使损失函数最小化的模型参数值。 经过训练后，我们将需要使用这些参数来做出未来的预测。 此外，有时我们希望提取参数，以便在其他环境中复用它们， 将模型保存下来，以便它可以在其他软件中执行， 或者为了获得科学的理解而进行检查。 之前的介绍中，我们只依靠深度学习框架来完成训练的工作， 而忽略了操作参数的具体细节。 本节，我们将介绍以下内容： 访问参数，用于调试、诊断和可视化； 参数初始化； 在不同模型组件间共享参数。 (我们首先看一下具有单隐藏层的多层感知机。) import torchfrom torch...</div><div class="meta footer"><span><a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-deep-learning-computation/" itemprop="url" title="chapter_deep-learning-computation"><i class="ic i-flag"></i>chapter_deep-learning-computation</a></span></div><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_deep-learning-computation/parameters/" itemprop="url" title="parameters" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><a class="extend prev" rel="prev" href="/page/18/"><i class="ic i-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><span class="page-number current">19</span><a class="page-number" href="/page/20/">20</a><span class="space">&hellip;</span><a class="page-number" href="/page/43/">43</a><a class="extend next" rel="next" href="/page/20/"><i class="ic i-angle-right" aria-label="下一页"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/page/18/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/20/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/base/" title="分类于 base">base</a></div><span><a href="/2022/08/25/ai/nlp/base/transformer/" title="transformer">transformer</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="分类于 pytorch">pytorch</a></div><span><a href="/2022/07/25/ai/pytorch/argmax-torch/" title="argmax-torch">argmax-torch</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/24/language/Go/note/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/base/" title="分类于 base">base</a></div><span><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" title="Subword算法">Subword算法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/" title="分类于 huggingface">huggingface</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/huggingface/DATASETS%E5%BA%93/" title="分类于 DATASETS库">DATASETS库</a></div><span><a href="/2022/09/21/ai/nlp/huggingface/DATASETS%E5%BA%93/%E5%88%87%E7%89%87/" title="datasets 切片">datasets 切片</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/08/26/frontend/vue/vue3%E6%96%B0%E7%89%B9%E6%80%A7/" title="VUE3新特性">VUE3新特性</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/24/language/python/%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/backend/" title="分类于 后端">后端</a> <i class="ic i-angle-right"></i> <a href="/categories/backend/spring/" title="分类于 spring">spring</a></div><span><a href="/2022/11/12/backend/Spring/spring_day02/Spring_day02/" title="Spring_day02">Spring_day02</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-multilayer-perceptrons/" title="分类于 chapter_multilayer-perceptrons">chapter_multilayer-perceptrons</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_multilayer-perceptrons/index/" title="index">index</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"page/19/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>