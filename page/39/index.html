<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://jyuanhust.github.io/page/39/"><title>Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Mi Manchi</p><h1 itemprop="name headline" class="title">yuan</h1></a><p class="meta" itemprop="description">= Whatever is worth doing at all is worth doing well =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(37).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(24).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(21).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(32).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(71).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(38).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><div class="segments posts"><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(52).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:49"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:49+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练">Pytorch通过requires_grad固定部分参数进行网络训练</a></h3><div class="excerpt"># 1. 只训练部分层 class RESNET_attention(nn.Module): def __init__(self, model, pretrained): super(RESNET_attetnion, self).__init__() self.resnet = model(pretrained) for p in self.parameters(): p.requires_grad = False self.f = nn.Conv2d(2048, 512, 1) self.g = nn.Conv2d(2048, 512, 1) self.h =...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(76).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:48"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:48+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.8k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）">Pytorch的data.norm（几种范数(norm)的详细介绍）</a></h3><div class="excerpt"># 范数（norm） 几种范数的简单介绍 &amp;amp; data.norm（）使用 1. 范数 (norm) 的简单介绍 1.1 L-P 范数 1.2 L0 范数 1.3 L1 范数 1.4 L2 范数 1.5 ∞- 范数 2. 矩阵范数 2.1 1 - 范数 2.2 2 - 范数 2.3 ∞- 范数 2.4 F - 范数 2.6 核范数 3. pytorch 中 x.norm (p=2,dim=1,keepdim=True) 的理解 3.1 方法介绍 3.2 函数参数 3.3 实例演示 3.3.1 dim 参数 3.3.2 keepdim 参数 #...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(20).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:47"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:47+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>954</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现">pytorch固定随机种子-训练稳定复现</a></h3><div class="excerpt">import torchimport randomimport numpy as npimport osdef set_seed(seed=1): # seed 的数值可以随意设置，本人不清楚有没有推荐数值 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) #根据文档，torch.manual_seed (seed) 应该已经为所有设备设置 seed #但是 torch.cuda.manual_seed (seed) 在没有 gpu 时也可调用，这样写没什么坏处 torch.cuda.manual_seed(seed)...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(27).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:46"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:46+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()">PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()</a></h3><div class="excerpt">注：训练过程常会出现上述方法，本文只是简单介绍他们的含义和作用，深层理解请跳至文档，或者 GIthub 查看源码，又或者网盘 ，提取码：pjrs，把下载好的 PyTorch 文档导入，则可以离线查看文档了，希望能帮到你。步入正文： PyTorch 深度学习框架在训练时，大多都是利用 GPU 来提高训练速度，怎么用 GPU（方法：.cuda ()）： import DataSetfrom model.MyNet import MyNetfrom torch.utils.data import DataLoadertrain_dataset = DataSet() #...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(76).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:46"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:46+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.3k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解">Pytorch函数expand()详解</a></h3><div class="excerpt"># Pytorch 函数 .expand ( ) 其将单个维度扩大成更大维度，返回一个新的 tensor，具体看下例： import torcha = torch.Tensor([[1], [2], [3],[4]])# 未使用 expand（）函数前的 aprint(&#39;a.size: &#39;, a.size())print(&#39;a: &#39;, a)b = a.expand(4, 2)# 使用 expand（）函数后的输出print(&#39;a.size: &#39;, a.size())print(&#39;a: &#39;, a)print(&#39;b.size:...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(10).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:45"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:45+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）">pytorch中的transpose方法（函数）</a></h3><div class="excerpt">pytorch 中的 transpose 方法的作用是交换矩阵的两个维度，transpose (dim0, dim1) → Tensor，其和 torch.transpose () 函数作用一样。 torch.transpose (): torch.transpose(input, dim0, dim1) → TensorReturns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped. The resulting out tensor shares...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(34).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:44"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:44+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>3.4k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作">Pytorch中transforms.RandomResizedCrop()等图像操作</a></h3><div class="excerpt">先看代码： transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])具体是对图像进行各种转换操作，并用函数 compose 将这些转换操作组合起来； 接下来看实例： 先读取一张图片： from PIL import Imageimg =...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(34).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:43"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:43+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>979</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系">pytorch中LSTM的output和hidden关系</a></h3><div class="excerpt"># pytorch LSTM 中 output 和 hidden 关系 1.LSTM 模型简介 2.pytorch 中的 LSTM 3. 关于 h 和 output 之间的关系进行实验 # 1.LSTM 模型简介 能点进来的相信大家也都清楚 LSTM 是个什么东西，我在这里就不加赘述了。具体介绍模型结构的也有不少。 如何简单的理解 LSTM—— 其实没有那么复杂 人人都能看懂的 LSTM # 2.pytorch 中的 LSTM 这里附上一张 pytorch 官方文档的截图，h_n 和 c_n 我都理解分别是上图中横向箭头中的下方箭头和上方的箭头，那 output 是干什么用的？在学习...</div><div class="meta footer"><span><a href="/categories/ai/nlp/base/" itemprop="url" title="base"><i class="ic i-flag"></i>base</a></span></div><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(8).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:42"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:42+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>2 分钟</span></span></div><h3><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系">PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系</a></h3><div class="excerpt">还有一个问题，output 的其他的值是怎么得到的呢？第二维度表示的 sel_len，即句子含有的单词数量，在下面的解析中使用的 - 1 代表了什么具体含义呢？仅仅使用了最后一步的输出作为作为最后一个最后一句的结果么？ LSTM 定义的是网络，一个神经元接受的不是一个数，而是一个向量，所以在构造函数中有 input_size，即说明了向量的大小情况。但是神经元输出的是一个数，最后的结果是最后一层神经元输出的数组成的向量。 # LSTM...</div><div class="meta footer"><span><a href="/categories/ai/nlp/base/" itemprop="url" title="base"><i class="ic i-flag"></i>base</a></span></div><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97os-system/" itemprop="url" title="Python模块os.system()"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(63).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:41"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:41+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97os-system/" itemprop="url" title="Python模块os.system()">Python模块os.system()</a></h3><div class="excerpt">os.system () 此模块提供对操作系统功能的访问 1、通过 os.system () 直接调用系统功能 import osos.system(&quot;calc&quot;) # 调用操作系统的计算器os.system(&quot;cmd&quot;) # 调用操作系统的 cmdos.system(&#39;mstsc&#39;) # 调用远程桌面连接2、通过 cmd 命令调用系统功能 1、调用操作系统的cmd面板os.system(&quot;cmd&quot;)2、在cmd面板输入相关功能命令3、常用命令如下，更多可百度...calc # 调用操作系统的计算器mstsc #...</div><div class="meta footer"><span><a href="/categories/Python/" itemprop="url" title="Python"><i class="ic i-flag"></i>Python</a></span></div><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97os-system/" itemprop="url" title="Python模块os.system()" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><a class="extend prev" rel="prev" href="/page/38/"><i class="ic i-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/38/">38</a><span class="page-number current">39</span><a class="page-number" href="/page/40/">40</a><span class="space">&hellip;</span><a class="page-number" href="/page/43/">43</a><a class="extend next" rel="next" href="/page/40/"><i class="ic i-angle-right" aria-label="下一页"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/page/38/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/40/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" title="分类于 数据库">数据库</a></div><span><a href="/2022/07/24/database/MongoDB/" title="MongoDB">MongoDB</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%B7%A5%E5%85%B7/" title="分类于 工具">工具</a> <i class="ic i-angle-right"></i> <a href="/categories/%E5%B7%A5%E5%85%B7/%E7%88%AC%E8%99%AB/" title="分类于 爬虫">爬虫</a> <i class="ic i-angle-right"></i> <a href="/categories/%E5%B7%A5%E5%85%B7/%E7%88%AC%E8%99%AB/ai/" title="分类于 ai">ai</a></div><span><a href="/2022/08/26/language/python/pandas%E7%94%A8%E6%B3%95/" title="pandas用法">pandas用法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 computer-science">computer-science</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/algorithm/" title="分类于 algorithm">algorithm</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/algorithm/leetCode/" title="分类于 leetCode">leetCode</a></div><span><a href="/2022/12/26/computer-science/algorithm/leetCode/7-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" title="7-深入浅出动态规划">7-深入浅出动态规划</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="分类于 pytorch">pytorch</a></div><span><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" title="pytorch中的transpose方法（函数）">pytorch中的transpose方法（函数）</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/09/07/computer-science/algorithm/%E5%8D%8E%E7%A7%91%E6%9C%BA%E8%AF%95/note/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-convolutional-modern/" title="分类于 chapter_convolutional-modern">chapter_convolutional-modern</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_convolutional-modern/densenet/" title="densenet">densenet</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tools/" title="分类于 tools">tools</a></div><span><a href="/2022/07/26/tools/vscode%E6%8A%80%E5%B7%A7/" title="vscode技巧">vscode技巧</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-natural-language-processing-applications/" title="分类于 chapter_natural-language-processing-applications">chapter_natural-language-processing-applications</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_natural-language-processing-applications/natural-language-inference-attention/" title="natural-language-inference-attention">natural-language-inference-attention</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/03/03/ai/nlp/base/Transformer%E5%92%8CBERT%E5%85%A5%E9%97%A8.pptx/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/24/frontend/base/async_%E4%B8%8E_await_%E7%9A%84%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3/" title="未命名">未命名</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"page/39/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>