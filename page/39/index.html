<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://jyuanhust.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://jyuanhust.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://jyuanhust.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://jyuanhust.github.io/page/39/"><title>Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Mi Manchi</p><h1 itemprop="name headline" class="title">yuan</h1></a><p class="meta" itemprop="description">= Whatever is worth doing at all is worth doing well =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(43).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(32).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(88).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(49).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(6).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(38).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><div class="segments posts"><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(29).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:49"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:49+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练">Pytorch通过requires_grad固定部分参数进行网络训练</a></h3><div class="excerpt"># 1. 只训练部分层 class RESNET_attention(nn.Module): def __init__(self, model, pretrained): super(RESNET_attetnion, self).__init__() self.resnet = model(pretrained) for p in self.parameters(): p.requires_grad = False self.f = nn.Conv2d(2048, 512, 1) self.g = nn.Conv2d(2048, 512, 1) self.h =...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" itemprop="url" title="Pytorch通过requires_grad固定部分参数进行网络训练" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(44).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:48"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:48+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.8k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）">Pytorch的data.norm（几种范数(norm)的详细介绍）</a></h3><div class="excerpt"># 范数（norm） 几种范数的简单介绍 &amp;amp; data.norm（）使用 1. 范数 (norm) 的简单介绍 1.1 L-P 范数 1.2 L0 范数 1.3 L1 范数 1.4 L2 范数 1.5 ∞- 范数 2. 矩阵范数 2.1 1 - 范数 2.2 2 - 范数 2.3 ∞- 范数 2.4 F - 范数 2.6 核范数 3. pytorch 中 x.norm (p=2,dim=1,keepdim=True) 的理解 3.1 方法介绍 3.2 函数参数 3.3 实例演示 3.3.1 dim 参数 3.3.2 keepdim 参数 #...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E7%9A%84data-norm%EF%BC%88%E5%87%A0%E7%A7%8D%E8%8C%83%E6%95%B0-norm-%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%EF%BC%89/" itemprop="url" title="Pytorch的data.norm（几种范数(norm)的详细介绍）" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(82).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:47"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:47+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>954</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现">pytorch固定随机种子-训练稳定复现</a></h3><div class="excerpt">import torchimport randomimport numpy as npimport osdef set_seed(seed=1): # seed 的数值可以随意设置，本人不清楚有没有推荐数值 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) #根据文档，torch.manual_seed (seed) 应该已经为所有设备设置 seed #但是 torch.cuda.manual_seed (seed) 在没有 gpu 时也可调用，这样写没什么坏处 torch.cuda.manual_seed(seed)...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/pytorch%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-%E8%AE%AD%E7%BB%83%E7%A8%B3%E5%AE%9A%E5%A4%8D%E7%8E%B0/" itemprop="url" title="pytorch固定随机种子-训练稳定复现" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(28).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:46"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:46+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()">PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()</a></h3><div class="excerpt">注：训练过程常会出现上述方法，本文只是简单介绍他们的含义和作用，深层理解请跳至文档，或者 GIthub 查看源码，又或者网盘 ，提取码：pjrs，把下载好的 PyTorch 文档导入，则可以离线查看文档了，希望能帮到你。步入正文： PyTorch 深度学习框架在训练时，大多都是利用 GPU 来提高训练速度，怎么用 GPU（方法：.cuda ()）： import DataSetfrom model.MyNet import MyNetfrom torch.utils.data import DataLoadertrain_dataset = DataSet() #...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/PyTorch%E5%85%B3%E4%BA%8E%E4%BB%A5%E4%B8%8B%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%9Adetach-cpu-numpy-%E4%BB%A5%E5%8F%8Aitem/" itemprop="url" title="PyTorch关于以下方法使用：detach()_cpu()_numpy()_以及item()" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(68).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:46"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:46+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.3k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解">Pytorch函数expand()详解</a></h3><div class="excerpt"># Pytorch 函数 .expand ( ) 其将单个维度扩大成更大维度，返回一个新的 tensor，具体看下例： import torcha = torch.Tensor([[1], [2], [3],[4]])# 未使用 expand（）函数前的 aprint(&#39;a.size: &#39;, a.size())print(&#39;a: &#39;, a)b = a.expand(4, 2)# 使用 expand（）函数后的输出print(&#39;a.size: &#39;, a.size())print(&#39;a: &#39;, a)print(&#39;b.size:...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E5%87%BD%E6%95%B0expand-%E8%AF%A6%E8%A7%A3/" itemprop="url" title="Pytorch函数expand()详解" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(31).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:45"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:45+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>1.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）">pytorch中的transpose方法（函数）</a></h3><div class="excerpt">pytorch 中的 transpose 方法的作用是交换矩阵的两个维度，transpose (dim0, dim1) → Tensor，其和 torch.transpose () 函数作用一样。 torch.transpose (): torch.transpose(input, dim0, dim1) → TensorReturns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped. The resulting out tensor shares...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/pytorch%E4%B8%AD%E7%9A%84transpose%E6%96%B9%E6%B3%95%EF%BC%88%E5%87%BD%E6%95%B0%EF%BC%89/" itemprop="url" title="pytorch中的transpose方法（函数）" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(78).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:44"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:44+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>3.4k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作">Pytorch中transforms.RandomResizedCrop()等图像操作</a></h3><div class="excerpt">先看代码： transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])具体是对图像进行各种转换操作，并用函数 compose 将这些转换操作组合起来； 接下来看实例： 先读取一张图片： from PIL import Imageimg =...</div><div class="meta footer"><span><a href="/categories/ai/pytorch/" itemprop="url" title="pytorch"><i class="ic i-flag"></i>pytorch</a></span></div><a href="/2022/08/24/ai/pytorch/Pytorch%E4%B8%ADtransforms-RandomResizedCrop-%E7%AD%89%E5%9B%BE%E5%83%8F%E6%93%8D%E4%BD%9C/" itemprop="url" title="Pytorch中transforms.RandomResizedCrop()等图像操作" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(35).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:43"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:43+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>979</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系">pytorch中LSTM的output和hidden关系</a></h3><div class="excerpt"># pytorch LSTM 中 output 和 hidden 关系 1.LSTM 模型简介 2.pytorch 中的 LSTM 3. 关于 h 和 output 之间的关系进行实验 # 1.LSTM 模型简介 能点进来的相信大家也都清楚 LSTM 是个什么东西，我在这里就不加赘述了。具体介绍模型结构的也有不少。 如何简单的理解 LSTM—— 其实没有那么复杂 人人都能看懂的 LSTM # 2.pytorch 中的 LSTM 这里附上一张 pytorch 官方文档的截图，h_n 和 c_n 我都理解分别是上图中横向箭头中的下方箭头和上方的箭头，那 output 是干什么用的？在学习...</div><div class="meta footer"><span><a href="/categories/ai/nlp/base/" itemprop="url" title="base"><i class="ic i-flag"></i>base</a></span></div><a href="/2022/08/24/ai/nlp/base/pytorch%E4%B8%ADLSTM%E7%9A%84output%E5%92%8Chidden%E5%85%B3%E7%B3%BB/" itemprop="url" title="pytorch中LSTM的output和hidden关系" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(26).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:42"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:42+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>2 分钟</span></span></div><h3><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系">PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系</a></h3><div class="excerpt">还有一个问题，output 的其他的值是怎么得到的呢？第二维度表示的 sel_len，即句子含有的单词数量，在下面的解析中使用的 - 1 代表了什么具体含义呢？仅仅使用了最后一步的输出作为作为最后一个最后一句的结果么？ LSTM 定义的是网络，一个神经元接受的不是一个数，而是一个向量，所以在构造函数中有 input_size，即说明了向量的大小情况。但是神经元输出的是一个数，最后的结果是最后一层神经元输出的数组成的向量。 # LSTM...</div><div class="meta footer"><span><a href="/categories/ai/nlp/base/" itemprop="url" title="base"><i class="ic i-flag"></i>base</a></span></div><a href="/2022/08/24/ai/nlp/base/PyTorch-%E4%B8%AD-LSTM-%E7%9A%84-output%E3%80%81h-n-%E5%92%8C-c-n-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/" itemprop="url" title="PyTorch_中_LSTM_的_output、h_n_和_c_n_之间的关系" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97-shutil%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/" itemprop="url" title="shutil模块详解-Python模块"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(56).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-08-24 22:05:41"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-08-24T22:05:41+08:00">2022-08-24</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>3.2k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97-shutil%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/" itemprop="url" title="shutil模块详解-Python模块">shutil模块详解-Python模块</a></h3><div class="excerpt"># 本文大纲 os 模块是 Python 标准库中一个重要的模块，里面提供了对目录和文件的一般常用操作。而 Python 另外一个标准库 ——shutil 库，它作为 os 模块的补充，提供了复制、移动、删除、压缩、解压等操作，这些 os 模块中一般是没有提供的。但是需要注意的是：shutil 模块对压缩包的处理是调用 ZipFile 和 TarFile 这两个模块来进行的。 # 知识串讲 本文所使用的素材，都是基于以下 2 个文件夹，其中一个文件夹为空。 # 1）模块导入 import shutil# 2）复制文件 函数：shutil.copy...</div><div class="meta footer"><span><a href="/categories/Python/" itemprop="url" title="Python"><i class="ic i-flag"></i>Python</a></span></div><a href="/2022/08/24/language/python/Python%E6%A8%A1%E5%9D%97-shutil%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/" itemprop="url" title="shutil模块详解-Python模块" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><a class="extend prev" rel="prev" href="/page/38/"><i class="ic i-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/38/">38</a><span class="page-number current">39</span><a class="page-number" href="/page/40/">40</a><span class="space">&hellip;</span><a class="page-number" href="/page/43/">43</a><a class="extend next" rel="next" href="/page/40/"><i class="ic i-angle-right" aria-label="下一页"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">429</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/page/38/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/40/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/08/26/frontend/vue/vue%E7%9A%84%E6%89%A9%E5%B1%95%E8%BF%90%E7%AE%97%E7%AC%A6/" title="vue的扩展运算符">vue的扩展运算符</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E8%93%9D%E6%A1%A5%E6%9D%AF/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/jQuery/%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%E7%82%B92/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-attention-mechanisms/" title="分类于 chapter_attention-mechanisms">chapter_attention-mechanisms</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/self-attention-and-positional-encoding/" title="self-attention-and-positional-encoding">self-attention-and-positional-encoding</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-computational-performance/" title="分类于 chapter_computational-performance">chapter_computational-performance</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_computational-performance/parameterserver/" title="parameterserver">parameterserver</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="分类于 cv">cv</a></div><span><a href="/2022/08/25/ai/cv/MobileNet/" title="MobileNet">MobileNet</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/08/24/frontend/vue/vue%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8-1/" title="vue基础入门_">vue基础入门_</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/vue/" title="分类于 vue">vue</a></div><span><a href="/2022/09/12/frontend/vue/vue%E9%85%8D%E7%BD%AE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/" title="vue配置跨域请求">vue配置跨域请求</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E9%AB%98%E7%BA%A7%E8%BD%AF%E8%80%83/%E9%80%89%E6%8B%A9%E9%A2%98/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/24/tools/VS%E6%8A%80%E5%B7%A7/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="分类于 pytorch">pytorch</a></div><span><a href="/2022/08/24/ai/pytorch/Pytorch%E9%80%9A%E8%BF%87requires-grad%E5%9B%BA%E5%AE%9A%E9%83%A8%E5%88%86%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/" title="Pytorch通过requires_grad固定部分参数进行网络训练">Pytorch通过requires_grad固定部分参数进行网络训练</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">44:38</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"page/39/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>