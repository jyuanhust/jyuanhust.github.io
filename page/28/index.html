<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="yuan" href="https://huang-junyuan.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="yuan" href="https://huang-junyuan.github.io/atom.xml"><link rel="alternate" type="application/json" title="yuan" href="https://huang-junyuan.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://huang-junyuan.github.io/page/28/"><title>Mi Manchi = yuan = Whatever is worth doing at all is worth doing well</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><a href="/" class="logo" rel="start"><p class="artboard">Mi Manchi</p><h1 itemprop="name headline" class="title">yuan</h1></a><p class="meta" itemprop="description">= Whatever is worth doing at all is worth doing well =</p></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Mi Manchi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(44).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(56).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(28).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(24).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(6).webp"></li><li class="item" data-background-image="https://gitee.com/zkz0/image/raw/master/img/img(52).webp"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="index wrap"><div class="segments posts"><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/BPE/" itemprop="url" title="Byte-Pair Encoding tokenization"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(23).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>7.3k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>7 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/BPE/" itemprop="url" title="Byte-Pair Encoding tokenization">Byte-Pair Encoding tokenization</a></h3><div class="excerpt"># Byte-Pair Encoding tokenization 字节对编码 (BPE) 最初被开发为一种压缩文本的算法，然后在预训练 GPT 模型时被 OpenAI 用于标记化。许多 Transformer 模型都使用它，包括 GPT、GPT-2、RoBERTa、BART 和 DeBERTa。 # 训练算法 BPE 训练首先计算语料库中使用的唯一单词集 (在完成标准化和预标记化步骤之后), 然后通过获取用于编写这些单词的所有符号来构建词汇表。一个非常简单的例子，假设我们的语料库使用了这五个词: &quot;hug&quot;, &quot;pug&quot;,...</div><div class="meta footer"><span><a href="/categories/ai/nlp/huggingface/Tokenizer%E5%BA%93/" itemprop="url" title="Tokenizer库"><i class="ic i-flag"></i>Tokenizer库</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/BPE/" itemprop="url" title="Byte-Pair Encoding tokenization" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/%E6%A0%B9%E6%8D%AE%E5%B7%B2%E6%9C%89%E7%9A%84tokenizer%E8%AE%AD%E7%BB%83%E6%96%B0%E7%9A%84tokenizer/" itemprop="url" title="根据已有的tokenizer训练新的tokenizer"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(80).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>975</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/%E6%A0%B9%E6%8D%AE%E5%B7%B2%E6%9C%89%E7%9A%84tokenizer%E8%AE%AD%E7%BB%83%E6%96%B0%E7%9A%84tokenizer/" itemprop="url" title="根据已有的tokenizer训练新的tokenizer">根据已有的tokenizer训练新的tokenizer</a></h3><div class="excerpt"># 根据已有的 tokenizer 训练新的 tokenizer 如果您感兴趣的语言中没有可用的语言模型，或者如果您的语料库与您的语言模型所训练的语料库有很大不同，您很可能希望从适合您的数据的标记器从头开始重新训练模型。这将需要在您的数据集上训练一个新的标记器。 但这究竟是什么意思？ 当我们在 第二章 中第一次查看标记器时，我们看到大多数 Transformer 模型使用子词分词算法。 为了识别哪些子词是感兴趣的并且在手头的语料库中最常出现，标记器需要仔细查看语料库中的所有文本 —— 我们称之为 training 的过程。...</div><div class="meta footer"><span><a href="/categories/ai/nlp/huggingface/Tokenizer%E5%BA%93/" itemprop="url" title="Tokenizer库"><i class="ic i-flag"></i>Tokenizer库</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/%E6%A0%B9%E6%8D%AE%E5%B7%B2%E6%9C%89%E7%9A%84tokenizer%E8%AE%AD%E7%BB%83%E6%96%B0%E7%9A%84tokenizer/" itemprop="url" title="根据已有的tokenizer训练新的tokenizer" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/WordPiece/" itemprop="url" title="WordPiece"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(15).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-11-12 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-11-12T12:04:17+08:00">2022-11-12</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>848</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/WordPiece/" itemprop="url" title="WordPiece">WordPiece</a></h3><div class="excerpt"># WordPiece 标记化 WordPiece 是 Google 为预训练 BERT 而开发的标记化算法。此后，它在不少基于 BERT 的 Transformer 模型中得到重用，例如 DistilBERT、MobileBERT、Funnel Transformers 和 MPNET。它在训练方面与 BPE 非常相似，但实际标记化的方式不同。 # 训练算法 Google 从未开源 WordPiece 训练算法的实现，因此以下是我们基于已发表文献的最佳猜测。它可能不是 100% 准确的。 与 BPE 一样，WordPiece...</div><div class="meta footer"><span><a href="/categories/ai/nlp/huggingface/Tokenizer%E5%BA%93/" itemprop="url" title="Tokenizer库"><i class="ic i-flag"></i>Tokenizer库</a></span></div><a href="/2022/11/12/ai/nlp/huggingface/Tokenizers%E5%BA%93/WordPiece/" itemprop="url" title="WordPiece" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/23/language/python/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/" itemprop="url" title="程序执行流程-python"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(2).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-23 22:05:41"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-23T22:05:41+08:00">2022-09-23</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>0</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/09/23/language/python/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/" itemprop="url" title="程序执行流程-python">程序执行流程-python</a></h3><div class="excerpt"></div><div class="meta footer"><span><a href="/categories/Python/" itemprop="url" title="Python"><i class="ic i-flag"></i>Python</a></span></div><a href="/2022/09/23/language/python/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/" itemprop="url" title="程序执行流程-python" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" itemprop="url" title="Subword算法"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(29).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-22 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-22T12:04:17+08:00">2022-09-22</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>119</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" itemprop="url" title="Subword算法">Subword算法</a></h3><div class="excerpt"># BPE BPE 首先将词分成单个字符，然后依次用另一个字符替换频率最高的一对字符 ，直到循环次数结束。 是仅仅将这一个单词进行拆分么？还是整个句子的单词都拆分成单个字母 https://zhuanlan.zhihu.com/p/448147465</div><div class="meta footer"><span><a href="/categories/ai/nlp/base/" itemprop="url" title="base"><i class="ic i-flag"></i>base</a></span></div><a href="/2022/09/22/ai/nlp/base/Subword%E7%AE%97%E6%B3%95/" itemprop="url" title="Subword算法" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/21/ai/nlp/base/nlp-transformer%E6%A6%82%E8%BF%B0/" itemprop="url" title="NLP和transformer大类概述"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(92).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-21 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-21T12:04:17+08:00">2022-09-21</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>4.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>4 分钟</span></span></div><h3><a href="/2022/09/21/ai/nlp/base/nlp-transformer%E6%A6%82%E8%BF%B0/" itemprop="url" title="NLP和transformer大类概述">NLP和transformer大类概述</a></h3><div class="excerpt"># Natural Language Processing 自然语言处理 # 什么是自然语言处理 NLP 是语言学和机器学习的一个领域，专注于理解与人类语言相关的所有内容。NLP 任务的目的不仅是单独理解单个单词，而且能够理解这些单词的上下文。 以下是常见 NLP 任务的列表，以及每个任务的一些示例 Classifying whole sentences 对整个句子进行分类：获取评论的情绪，检测电子邮件是否为垃圾邮件，确定句子在语法上是否正确或两个句子在逻辑上是否相关 Classifying each word in a sentence...</div><div class="meta footer"><span><a href="/categories/ai/nlp/" itemprop="url" title="nlp"><i class="ic i-flag"></i>nlp</a></span></div><a href="/2022/09/21/ai/nlp/base/nlp-transformer%E6%A6%82%E8%BF%B0/" itemprop="url" title="NLP和transformer大类概述" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/21/ai/nlp/huggingface/DATASETS%E5%BA%93/%E5%88%87%E7%89%87/" itemprop="url" title="datasets 切片"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(18).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-21 12:04:17"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-21T12:04:17+08:00">2022-09-21</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>67</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/09/21/ai/nlp/huggingface/DATASETS%E5%BA%93/%E5%88%87%E7%89%87/" itemprop="url" title="datasets 切片">datasets 切片</a></h3><div class="excerpt"># 切片 大多数情况下，您使用的数据都需根据模型所要求的输入进行清洗。在本节中，我们将探索 Datasets 提供的用于数据集清洗的各种功能。</div><div class="meta footer"><span><a href="/categories/ai/nlp/huggingface/DATASETS%E5%BA%93/" itemprop="url" title="DATASETS库"><i class="ic i-flag"></i>DATASETS库</a></span></div><a href="/2022/09/21/ai/nlp/huggingface/DATASETS%E5%BA%93/%E5%88%87%E7%89%87/" itemprop="url" title="datasets 切片" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/21/frontend/mediapine-vue/%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB/" itemprop="url" title="手势识别"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(92).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-21 11:40:52"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-21T11:40:52+08:00">2022-09-21</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>285</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>1 分钟</span></span></div><h3><a href="/2022/09/21/frontend/mediapine-vue/%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB/" itemprop="url" title="手势识别">手势识别</a></h3><div class="excerpt"># 在 ts 中的测试 # 问题描述与解决 因为这里是针对每帧图片就做一个手势识别，然后如果我识别到这个手势的话，我就会触发一个动作，加入帧率很高的话，那么这个触发动作就会不可控 实现单次手势识别，先设置一个 boolean 型的变量 preDetect，首次识别到该手势的时候，将 preDetect 设置为 true；当下一次再检测到手势时，如果仍检测到该手势，检查 preDetect 的值，如果为 true，则不触发动作，如果为 false，则触发动作。当 preDetect 为 true 且检测到其他手势的时候，将 preDetect 设置为...</div><div class="meta footer"><span><a href="/categories/frontend/vue/mediapipe-vue/" itemprop="url" title="mediapipe-vue"><i class="ic i-flag"></i>mediapipe-vue</a></span></div><a href="/2022/09/21/frontend/mediapine-vue/%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB/" itemprop="url" title="手势识别" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/19/computer-science/base/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1/" itemprop="url" title="整体设计--软工"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(11).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-19 22:28:22"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-19T22:28:22+08:00">2022-09-19</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>18k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>16 分钟</span></span></div><h3><a href="/2022/09/19/computer-science/base/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1/" itemprop="url" title="整体设计--软工">整体设计--软工</a></h3><div class="excerpt">下面仅进行功能性介绍，具体设计待与团队成员商讨 # 用户的数据结构 id（数据库自动生成，注册时不需要用户填写） 用户名 密码 邮箱 # 登录界面 # 功能 提供账号和密码登录和人脸登录两种，其中人脸登录仅在用户事先注册并录入人脸后后才能使用 提供注册 记录全局用户信息，其中 id 作为主要标识，当要向后端请求数据的使用 id，其他信息肯定也会在某些地方用得到 注册成功不用生成 token，登录才用 # 登录界面 sign-up-form 和 sign-in-form 是在子组件的登录和注册表单中定义的类名，但是样式却是在使用它们的父组件中才定义 在 vue...</div><div class="meta footer"><span><a href="/categories/%E8%BD%AF%E5%B7%A5/" itemprop="url" title="软工"><i class="ic i-flag"></i>软工</a></span></div><a href="/2022/09/19/computer-science/base/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1/" itemprop="url" title="整体设计--软工" class="btn">more...</a></div></article><article class="item"><div class="cover"><a href="/2022/09/18/frontend/mediapine-vue/%E5%A7%BF%E6%80%81%E6%A3%80%E6%B5%8B/" itemprop="url" title="姿态检测"><img data-src="https://gitee.com/zkz0/image/raw/master/img/img(5).webp"></a></div><div class="info"><div class="meta"><span class="item" title="创建时间：2022-09-18 11:40:52"><span class="icon"><i class="ic i-calendar"></i> </span><time itemprop="dateCreated datePublished" datetime="2022-09-18T11:40:52+08:00">2022-09-18</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span>2.8k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span>3 分钟</span></span></div><h3><a href="/2022/09/18/frontend/mediapine-vue/%E5%A7%BF%E6%80%81%E6%A3%80%E6%B5%8B/" itemprop="url" title="姿态检测">姿态检测</a></h3><div class="excerpt">原版 html 代码 &amp;lt;!DOCTYPE html&gt;&amp;lt;html&gt;&amp;lt;head&gt; &amp;lt;meta charset=&quot;utf-8&quot;&gt; &amp;lt;script src=&quot;https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js&quot; crossorigin=&quot;anonymous&quot;&gt;&amp;lt;/script&gt; &amp;lt;script...</div><div class="meta footer"><span><a href="/categories/frontend/vue/mediapipe-vue/" itemprop="url" title="mediapipe-vue"><i class="ic i-flag"></i>mediapipe-vue</a></span></div><a href="/2022/09/18/frontend/mediapine-vue/%E5%A7%BF%E6%80%81%E6%A3%80%E6%B5%8B/" itemprop="url" title="姿态检测" class="btn">more...</a></div></article></div></div><nav class="pagination"><div class="inner"><a class="extend prev" rel="prev" href="/page/27/"><i class="ic i-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><span class="page-number current">28</span><a class="page-number" href="/page/29/">29</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><a class="extend next" rel="next" href="/page/29/"><i class="ic i-angle-right" aria-label="下一页"></i></a></div></nav></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="yuan" data-src="/images/avatar.jpg"><p class="name" itemprop="name">yuan</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">410</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">72</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">61</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item email" data-url="bWFpbHRvOjIwODM2MzU1MjVAcXEuY29t" title="mailto:2083635525@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/page/27/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/page/29/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="分类于 cv">cv</a></div><span><a href="/2022/09/07/ai/cv/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="图像分类">图像分类</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" title="分类于 pytorch深度学习">pytorch深度学习</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter-attention-mechanisms/" title="分类于 chapter_attention-mechanisms">chapter_attention-mechanisms</a></div><span><a href="/2023/02/15/ai/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapter_attention-mechanisms/self-attention-and-positional-encoding/" title="self-attention-and-positional-encoding">self-attention-and-positional-encoding</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/frontend/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/frontend/css/" title="分类于 css">css</a></div><span><a href="/2022/09/09/frontend/CSS/CSS3%E6%8F%90%E9%AB%98/" title="CSS提高">CSS提高</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/%E6%AF%94%E8%B5%9B/%E8%93%9D%E6%A1%A5%E6%9D%AF/%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%AD%94%E6%A1%88%E4%BB%A3%E7%A0%81/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2022/07/24/computer-science/base/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C/828/lab1-Xv6andUnixutilities/" title="Xv6 and Unix utilities">Xv6 and Unix utilities</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/06/25/computer-science/base/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%BD%91%E6%80%BB%E5%A4%8D%E4%B9%A0-%E6%9C%B1%E4%BD%AC/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/pytorch/" title="分类于 pytorch">pytorch</a></div><span><a href="/2022/08/24/ai/pytorch/torch-matmul-%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D/" title="torch.matmul()用法介绍">torch.matmul()用法介绍</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tools/" title="分类于 tools">tools</a></div><span><a href="/2022/07/26/tools/vscode%E6%8A%80%E5%B7%A7/" title="vscode技巧">vscode技巧</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/" title="分类于 nlp">nlp</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/nlp/base/" title="分类于 base">base</a></div><span><a href="/2022/08/25/ai/nlp/base/transformer/" title="transformer">transformer</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ai/" title="分类于 ai">ai</a> <i class="ic i-angle-right"></i> <a href="/categories/ai/cv/" title="分类于 cv">cv</a></div><span><a href="/2022/08/24/ai/cv/face-alignment%EF%BC%9Aface-alignment%E5%BA%93%E7%9A%84%E7%AE%80%E4%BB%8B%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" title="face_alignment：face_alignment库的简介、安装、使用方法">face_alignment：face_alignment库的简介、安装、使用方法</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">yuan @ Mi Manchi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">2.9m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">43:49</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"page/28/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>